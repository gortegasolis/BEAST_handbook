[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "BEAST database",
    "section": "",
    "text": "0.1 Index",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Index</span>"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "2  Summary",
    "section": "",
    "text": "2.1 Objective\nWe face an unprecedented threat from global alteration of nature and biodiversity, but we still lack rigorous estimates of how fast, where, and at which scales biodiversity changes. Studies report fragmented and seemingly contradictory results, suffer from mismatches in biodiversity metrics, mismatches in temporal and spatial grains, and are constrained by huge data gaps. Moreover, local loss and gain of biodiversity is decoupled from changes in countries or continents, with opposing directions at different scales being plausible. A quantitative synthesis that connects all this, and bridges the gaps, is needed. The objective of BEAST is to map and interpolate temporal biodiversity change in Europe, the US, and the world, across continuous space, time, and their grains, from locations as small as 1 m, to countries and continents, over the last ca 40 years, for birds, plants, and butterflies. To do this we will combine data from local time series with high-quality gridded atlas data from countries and continents. We will use a new cross-scale model to interpolate biodiversity change jointly across space and time, and across the data gaps. We will test if temporal change of diversity, distributions, and turnover can be estimated from: (i) static patterns of diversity and distributions, (ii) from data lacking temporal replication, (iii) from space-for-time substitution of spatial vs temporal species turnover, (iii) from spaceborne remotely sensed spectral diversity and turnover. These methods will enable integration of heterogeneous and messy biodiversity data, and they will improve estimates of change in data-poor regions of the global South. BEAST will deliver the first integrative statistical model revealing, for the first time, how multiple facets of biodiversity change across scales. It will show which regions, habitats, and biomes undergo the most pronounced change, which is critical for informed large-scale conservation policy.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Summary</span>"
    ]
  },
  {
    "objectID": "summary.html#funding",
    "href": "summary.html#funding",
    "title": "2  Summary",
    "section": "2.2 Funding",
    "text": "2.2 Funding\nHORIZON.1.1 - European Research Council (ERC) Main Programme\nERC-2021-COG - ERC CONSOLIDATOR GRANTS",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Summary</span>"
    ]
  },
  {
    "objectID": "summary.html#regions-covered",
    "href": "summary.html#regions-covered",
    "title": "2  Summary",
    "section": "2.3 Regions covered",
    "text": "2.3 Regions covered",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Summary</span>"
    ]
  },
  {
    "objectID": "Creating_database.html",
    "href": "Creating_database.html",
    "title": "3  Creating database",
    "section": "",
    "text": "3.1 Purpose\nDesign a database for species occurrence and probability records extracted from atlases. The database should be reasonably small, compatible with multiple software, able to store spatial data, and flexible to accommodate different types of sampling efforts and methodologies. We chose PostgreSQL with PostGIS extension because it is open source, free, and it has extensive documentation.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Creating database</span>"
    ]
  },
  {
    "objectID": "Creating_database.html#postgresql-installation",
    "href": "Creating_database.html#postgresql-installation",
    "title": "3  Creating database",
    "section": "3.2 PostgreSQL installation",
    "text": "3.2 PostgreSQL installation\nEnable PostgreSQL repository for Ubuntu. It is neccesary to first install postgresql-common and then run the bash script it brings.\nsudo apt install -y postgresql-common\nsudo /usr/share/postgresql-common/pgdg/apt.postgresql.org.sh\nInstall packages postgresql, postgis and pgloader.\nsudo apt install postgresql postgis postgresql-postgis* pgloader\nIt could be useful to also install pgAdmin. Instructions can be found here.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Creating database</span>"
    ]
  },
  {
    "objectID": "Creating_database.html#create-database-and-user-roles",
    "href": "Creating_database.html#create-database-and-user-roles",
    "title": "3  Creating database",
    "section": "3.3 Create database and user roles",
    "text": "3.3 Create database and user roles\nIdentify as postgres (default user)\nsudo -i -u postgres\nCreate a database that can be managed by the user atlasadmin.\ncreateuser atlasadmin\ncreatedb MOBI_atlases_v1 -O atlasadmin\nConnect to the database.\npsql -d MOBI_atlases_v1\nAdd a password for the user atlasadmin.\nALTER USER atlasadmin PASSWORD 'myPassword';\nEnable PostGIS.\nCREATE EXTENSION postgis;\nCheck PostGIS version\nSELECT PostGIS_version();\nCreate a readonly role for users.\nCREATE ROLE readonly WITH\n  NOLOGIN\n  NOSUPERUSER\n  INHERIT\n  NOCREATEDB\n  NOCREATEROLE\n  NOREPLICATION\n  NOBYPASSRLS;\nExit database.\n\\q\nExit postgres user.\nexit",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Creating database</span>"
    ]
  },
  {
    "objectID": "Creating_database.html#libraries",
    "href": "Creating_database.html#libraries",
    "title": "3  Creating database",
    "section": "3.4 Libraries",
    "text": "3.4 Libraries\nLoad libraries to connect to the database.\n\npacman::p_load(RPostgres, DBI, askpass)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Creating database</span>"
    ]
  },
  {
    "objectID": "Creating_database.html#connect-r-to-database",
    "href": "Creating_database.html#connect-r-to-database",
    "title": "3  Creating database",
    "section": "3.5 Connect R to database",
    "text": "3.5 Connect R to database\nOpen an SSH tunnel. The following command works on Linux to open a tunnel in the background. The latter section of the code is the port redirection in the for localport:localhost:remoteport. Normally you would use 5432:localhost:5432 which redirects the remote port 5432 to the same port number in your personal computer. However, the remote 5432 can be redirected to any local port available (5434 here).\n\nscreen -dmS postgresql_tunnel ssh ortega@srv-asus-fzp.science.fzp.czu.cz -L 5434:localhost:5432\n\nCreate an R object that will store the SQL connection.\n\ncon &lt;- dbConnect(Postgres(),\n  dbname = \"MOBI_atlases_v1\",\n  host = \"localhost\",\n  port = 5434,\n  user = \"atlasadmin\",\n  password = askpass()\n)\n\nSet the default SQL connection to “con” for every SQL cell.\n\nknitr::opts_chunk$set(connection = con)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Creating database</span>"
    ]
  },
  {
    "objectID": "Creating_database.html#tables",
    "href": "Creating_database.html#tables",
    "title": "3  Creating database",
    "section": "3.6 Tables",
    "text": "3.6 Tables\nVariables were adopted from SPARSE 1.0, Darwin Core (DWC) and Humboldt core (HC).\n\n3.6.1 Code books\n\nLicenses\n\nInformation about data licenses including descriptions and links to external sources if available.\n\nCode book table for licensing information.\n\n\n\n\n\n\n\n\nVariable\nDescription\nSource\nType\n\n\n\n\nlicenseID\nPrimary key. Unique identifier.\nBEAST\nINTEGER\n\n\nlicense\nThe legal description giving official permission to do something with the dataset.\nDWC\nTEXT\n\n\nlicenseDescription\nShort verbal definition of the license type.\nSPARSE\nTEXT\n\n\nlicenseURL\nA full URL (web link) to the license type, if available.\nSPARSE\nTEXT\n\n\n\n\nCREATE TABLE IF NOT EXISTS public.\"CB_license\"\n(\n    \"licenseID\" integer NOT NULL,\n    license text COLLATE pg_catalog.\"default\" NOT NULL,\n    \"licenseDescription\" text COLLATE pg_catalog.\"default\" NOT NULL,\n    \"licenseURL\" text COLLATE pg_catalog.\"default\" NOT NULL,\n    CONSTRAINT \"CB_license_PK\" PRIMARY KEY (\"licenseID\")\n)\n\nTABLESPACE pg_default;\n\n\nSampling effort (codes)\nDescriptions and codes for sampling effort types adopted from Humboldt Core.\n\nCode book for sampling effort types.\n\n\n\n\n\n\n\n\nVariable\nDescription\nSource\nType\n\n\n\n\nsamplingEffortID\nPrimary key. Unique identifier.\nBEAST\nINTEGER\n\n\nsamplingEffortProtocol\nA description of or reference (publication or URL) to the methods used to determine the sampling effort.\nHC\n\n\n\nsamplingEffortUnit\nUnits of sampling effort.\nHC\n\n\n\n\n\n\nCREATE TABLE IF NOT EXISTS public.\"CB_sampling_effort\"\n(\n    \"samplingEffortID\" integer NOT NULL,\n    \"samplingEffortProtocol\" text COLLATE pg_catalog.\"default\" NOT NULL,\n    \"samplingEffortUnit\" text COLLATE pg_catalog.\"default\" NOT NULL,\n    CONSTRAINT \"CB_sampling_effort_PK\" PRIMARY KEY (\"samplingEffortID\"),\n    CONSTRAINT \"unique_samplingEffortProtocol\" UNIQUE (\"samplingEffortProtocol\")\n)\n\n\nTaxonomy\nIncludes taxonomic information for the taxa reported in every atlas dataset. We followed BirdLife 2024 for birds and GBIF 2022 for invertebrates.\n\nCode book for taxonomic information.\n\n\n\n\n\n\n\n\nVariable\nDescription\nSource\nType\n\n\n\n\nscientificNameID\nAn identifier for the nomenclatural (not taxonomic) details of a scientific name.\nDWC\nINTEGER\n\n\nscientificName\nBinary latin scientific name. The lowest taxonomic rank included is species. Infraspecific names are reported in the column infraspecificEpithet\nDWC\n\n\n\nscientificNameAuthorship\nThe authorship information for the scientificName formatted according to the conventions of the applicable nomenclaturalCode.\nDWC\n\n\n\nkingdom\nThe full scientific name of the kingdom in which the taxon is classified.\nDWC\n\n\n\nphylum\nThe full scientific name of the phylum or division in which the taxon is classified.\nDWC\n\n\n\nclass\nThe full scientific name of the class in which the taxon is classified.\nDWC\n\n\n\norder\nThe full scientific name of the order in which the taxon is classified.\nDWC\n\n\n\nfamily\nThe full scientific name of the family in which the taxon is classified.\nDWC\n\n\n\ngenus\nThe full scientific name of the genus in which the taxon is classified.\nDWC\n\n\n\nspecificEpithet\nThe name of the first or species epithet of the scientificName.\nDWC\n\n\n\ninfraspecificEpithet\nThe name of the lowest or terminal infraspecific epithet of the scientificName, excluding any rank designation.\nDWC\n\n\n\ntaxonRank\nThe taxonomic rank of the most specific name in the scientificName.\nDWC\n\n\n\n\n\n\nCREATE TABLE IF NOT EXISTS public.\"CB_taxonomy\"\n(\n    \"scientificNameID\" integer NOT NULL DEFAULT nextval('\"CB_taxonomy_scientificNameID_seq\"'::regclass),\n    \"scientificName\" text COLLATE pg_catalog.\"default\" NOT NULL,\n    \"scientificNameAuthorship\" text COLLATE pg_catalog.\"default\",\n    kingdom text COLLATE pg_catalog.\"default\" NOT NULL,\n    phylum text COLLATE pg_catalog.\"default\",\n    class text COLLATE pg_catalog.\"default\",\n    \"order\" text COLLATE pg_catalog.\"default\",\n    family text COLLATE pg_catalog.\"default\",\n    genus text COLLATE pg_catalog.\"default\",\n    \"specificEpithet\" text COLLATE pg_catalog.\"default\",\n    \"infraspecificEpithet\" text COLLATE pg_catalog.\"default\",\n    \"taxonRank\" text COLLATE pg_catalog.\"default\" NOT NULL,\n    \"taxonomicAuthority\" text COLLATE pg_catalog.\"default\" NOT NULL,\n    \"taxonomicSources\" text COLLATE pg_catalog.\"default\",\n    CONSTRAINT \"CB_taxonomy_PK\" PRIMARY KEY (\"scientificNameID\"),\n    CONSTRAINT \"Unique_species_check\" UNIQUE (\"scientificName\", kingdom, phylum, class)\n)\n\nTABLESPACE pg_default;\n\n\nSpecies equivalence table\nMatches taxas provided by the data holders with accepted names according to BirdLife 2024 (birds) and GBIF 2022 (invertebrates).\n\nCode book for equivalences between verbatim organisms identification and accepted taxonomic information.\n\n\n\n\n\n\n\n\nVariable\nDescription\nSource\nType\n\n\n\n\nverbatimIdentificationID\nPart of composite primary key. Unique identifier for verbatim names per dataset.\nBEAST\nINTEGER\n\n\nverbatimIdentification\nA string representing the taxonomic identification written in the original record.\nDWC\n\n\n\ndatasetID\nPart of composite primary key.\n\n\n\n\nidentificationReferences\nA list (concatenated and separated) of references (publication, global unique identifier, URI).\nDWC\n\n\n\nscientificNameID\nInherited from “CB_taxonomy”.\nDWC\n\n\n\n\n\n\nCREATE TABLE IF NOT EXISTS public.\"CB_verbatim_name_equivalence\"\n(\n    \"verbatimIdentificationID\" integer NOT NULL,\n    \"verbatimIdentification\" text COLLATE pg_catalog.\"default\" NOT NULL,\n    \"datasetID\" integer NOT NULL,\n    \"scientificNameID\" integer,\n    CONSTRAINT \"CB_verbatim_name_equivalence_PK\" PRIMARY KEY (\"verbatimIdentificationID\", \"datasetID\"),\n    CONSTRAINT unique_check_verbatim_equivalence UNIQUE (\"verbatimIdentificationID\", \"datasetID\", \"verbatimIdentification\"),\n    CONSTRAINT \"CB_verbatim_name_equivalence_CB_taxonomy_fk\" FOREIGN KEY (\"scientificNameID\")\n        REFERENCES public.\"CB_taxonomy\" (\"scientificNameID\") MATCH SIMPLE\n        ON UPDATE NO ACTION\n        ON DELETE NO ACTION\n        NOT VALID\n)\n\nTABLESPACE pg_default;\n\n\nModels\nHolds information about models used to produce occurrence probability estimations per dataset.\n\nCode book for occupancy models per atlas.\n\n\n\n\n\n\n\n\nVariable\nDescription\nSource\nType\n\n\n\n\nmodelID\nPrimary key. Unique identifier.\nBEAST\nINTEGER\n\n\nmodelName\nDescriptive name of the model used.\nBEAST\n\n\n\npredictorVariables\nList of predictor variables used in the model.\nBEAST\n\n\n\nbibliographicCitation\nBibliographic sources.\nBEAST\n\n\n\n\n\n\nCREATE TABLE IF NOT EXISTS public.\"CB_model\"\n(\n    \"occurrenceModelID\" integer NOT NULL,\n    \"modelName\" text COLLATE pg_catalog.\"default\",\n    \"predictorVariables\" text COLLATE pg_catalog.\"default\",\n    \"bibliographicCitation\" text COLLATE pg_catalog.\"default\",\n    CONSTRAINT \"CB_model_PK\" PRIMARY KEY (\"occurrenceModelID\")\n)\n\nTABLESPACE pg_default;\n\n\n\n3.6.2 Data tables\n\nDatasets\nContains information for data administration purposes including the names of publishers and providers of each atlas, bibliographic citation, and co-authors required and suggested.\n\nDatasets information.\n\n\n\n\n\n\n\n\nVariable\nDescription\nSource\nType\n\n\n\n\ndatasetID\nPrimary key. Unique identifier.\nBEAST\nINTEGER\n\n\ndatasetName\nThe name identifying the data set from which the record was derived. Title of atlas in most cases.\nDWC\n\n\n\ndatasetPublisher\nThe entity (person, organization or institution) making the dataset available.\nHC\n\n\n\ndatasetPublisherContact\nEmail contact to the entity making the dataset available.\nSPARSE\n\n\n\nlicenseID\nAn identifier from the codebook table CB_license defining publication license of the dataset source.\nSPARSE\n\n\n\nrightsHolder\nThe entity (person, organization or institution) that holds the rights to the dateset. Can be the datasetPublisher.\nDWC\n\n\n\nbibliographicCitation\nA bibliographic reference for the resource as a statement indicating how this record should be cited (attributed) when used.\nDWC\n\n\n\ncitationIdentifier\nA reference unique identifer of the associated document. DOI is preferred but a URI or ISBN number is adequate.\nHC\n\n\n\nprovider\nName of the person(s) or institution(s) providing the data.\nBEAST\n\n\n\nshareable\nYES: the dataset can be shared. NO: sharing is forbidden.\nBEAST\n\n\n\ncoauthorshipRequired\nYES: offering co-authorship to selected data providers is mandatory. NO: co-authorship offers are not required.\nBEAST\n\n\n\ncoauthors\nList of mandatory co-authors.\nBEAST\n\n\n\ncoauthorshipSuggested\nList of people within the MOBI team that acquired and processed the data and metadata.\nBEAST\n\n\n\nisSamplingEffortReported\nYES: some form of sampling effort is reported. NO: there is no sampling effort reported.\nBEAST\n\n\n\nisOccurrenceProbabilityAvailable\nYES: occurrence probability was modeled/reported. NO: no occurrence probability reported.\nBEAST\n\n\n\noccurrenceModelID\nInherited from CB_model\nBEAST\n\n\n\nrecordFilterMeaning\nInformation about data quality provided by the data holders. Higher values means more trusted records.\nBEAST\n\n\n\n\n\n\nCREATE TABLE IF NOT EXISTS public.\"MOBI_dataset\"\n(\n    \"datasetID\" integer NOT NULL,\n    \"datasetName\" text COLLATE pg_catalog.\"default\" NOT NULL,\n    \"datasetPublisher\" text COLLATE pg_catalog.\"default\" NOT NULL,\n    \"datasetPublisherContact\" text COLLATE pg_catalog.\"default\" NOT NULL,\n    \"licenseID\" integer NOT NULL,\n    \"rightsHolder\" text COLLATE pg_catalog.\"default\",\n    \"bibliographicCitation\" text COLLATE pg_catalog.\"default\",\n    \"citationIdentifier\" text COLLATE pg_catalog.\"default\",\n    provider text COLLATE pg_catalog.\"default\",\n    shareable text COLLATE pg_catalog.\"default\",\n    \"coauthorshipRequired\" text COLLATE pg_catalog.\"default\",\n    coauthors text COLLATE pg_catalog.\"default\",\n    \"coauthorshipSuggested\" text COLLATE pg_catalog.\"default\",\n    \"isSamplingEffortReported\" text COLLATE pg_catalog.\"default\" NOT NULL,\n    \"isOccurrenceProbabilityAvailable\" text COLLATE pg_catalog.\"default\" NOT NULL,\n    \"occurrenceModelID\" integer,\n    \"recordFilterMeaning\" text COLLATE pg_catalog.\"default\",\n    taxa text COLLATE pg_catalog.\"default\",\n    CONSTRAINT \"MOBI_dataset_PK\" PRIMARY KEY (\"datasetID\"),\n    CONSTRAINT \"MOBI_dataset_CB_licenses_FK\" FOREIGN KEY (\"licenseID\")\n        REFERENCES public.\"CB_license\" (\"licenseID\") MATCH SIMPLE\n        ON UPDATE NO ACTION\n        ON DELETE NO ACTION,\n    CONSTRAINT \"MOBI_dataset_CB_model_FK\" FOREIGN KEY (\"occurrenceModelID\")\n        REFERENCES public.\"CB_model\" (\"occurrenceModelID\") MATCH SIMPLE\n        ON UPDATE NO ACTION\n        ON DELETE NO ACTION\n)\n\nTABLESPACE pg_default;\n\nCreate indexes\n\nCREATE INDEX IF NOT EXISTS idx_mobi_dataset_datasetid\n    ON public.\"MOBI_dataset\" USING btree\n    (\"datasetID\" ASC NULLS LAST)\n    TABLESPACE pg_default;\n\n\nCREATE INDEX IF NOT EXISTS idx_mobi_dataset_licenseid\n    ON public.\"MOBI_dataset\" USING btree\n    (\"licenseID\" ASC NULLS LAST)\n    TABLESPACE pg_default;\n\n\nSites\nContains information about the spatial location of each sampling site.\n\n\n\n\n\n\n\n\n\nVariable\nDescription\nSource\nType\n\n\n\n\nverbatimSiteID\nOriginal site identificator provided by the data owners.\nBEAST\nTEXT\n\n\nverbatimSiteID\nOriginal site identificator provided by the data owners.\nBEAST\n\n\n\ndatasetID\nDataset/atlas identifier. Inherited from MOBI_dataset\nBEAST\n\n\n\nfootPrintSRS\nThe ellipsoid, geodetic datum, or spatial reference system (SRS). Standardized to WGS84 in our database.\nDWC\n\n\n\nverbatimFootprintSRS\nOriginal ellipsoid, geodetic datum, or spatial reference system (SRS) provided by the data owners. Analogous to verbatimSRS in DWC.\nBEAST\n\n\n\ngeometry\nOriginal spatial object re-projected to WGS84.\nBEAST\n\n\n\ncroppedGeometry\nOriginal spatial object re-projected to WGS84 and cropped to landmasses and study area boundaries.\nBEAST\n\n\n\n\n\n: Sites information.\n\nCREATE TABLE IF NOT EXISTS public.\"MOBI_site\"\n(\n    \"verbatimSiteID\" text COLLATE pg_catalog.\"default\" NOT NULL,\n    \"datasetID\" integer NOT NULL,\n    \"footprintSRS\" text COLLATE pg_catalog.\"default\",\n    \"verbatimFootprintSRS\" text COLLATE pg_catalog.\"default\",\n    geometry geometry,\n    \"croppedGeometry\" geometry,    \n    CONSTRAINT \"MOBI_siteFIN_pkey\" PRIMARY KEY (\"verbatimSiteID\", \"datasetID\"),\n    CONSTRAINT fk_site_dataset FOREIGN KEY (\"datasetID\")\n        REFERENCES public.\"MOBI_dataset\" (\"datasetID\") MATCH SIMPLE\n        ON UPDATE NO ACTION\n        ON DELETE NO ACTION\n) PARTITION BY LIST (\"datasetID\");\n\nCreate indexes\n\nCREATE INDEX IF NOT EXISTS idx_mobi_site_croppedgeometry\n    ON public.\"MOBI_site\" USING gist\n    (\"croppedGeometry\");\n\n\nCREATE INDEX IF NOT EXISTS idx_mobi_site_datasetid\n    ON public.\"MOBI_site\" USING btree\n    (\"datasetID\" ASC NULLS LAST);\n\n\nCREATE INDEX IF NOT EXISTS idx_mobi_site_geometry\n    ON public.\"MOBI_site\" USING gist\n    (geometry);\n\n\nCREATE INDEX IF NOT EXISTS idx_mobi_site_verbatimsiteid\n    ON public.\"MOBI_site\" USING btree\n    (\"verbatimSiteID\" COLLATE pg_catalog.\"default\" ASC NULLS LAST)\n    WITH (deduplicate_items=True);\n\n\nScaling resolutions\n\nThis table “translates” between the original cell resolution at the records level and every coarsening (scaling) resolution.\n\n\n\n\n\n\n\n\n\nVariable\nDescription\nSource\nType\n\n\n\n\nverbatimSiteID\nOriginal site identificator provided by the data owners. Inherited from MOBI_site.\nBEAST\nTEXT\n\n\nverbatimSiteID\nOriginal site identificator provided by the data owners. Inherited from MOBI_site.\nBEAST\n\n\n\ndatasetID\nDataset/atlas identifier. Inherited from MOBI_dataset.\nBEAST\n\n\n\nscalingID\nGrid cell spatial resolution. Filled with numbers in a doubling sequence of powers of 2 as follows: 1 (original resolution), 2 (2x2 cells grid), 4 (4x4)…\nBEAST\n\n\n\nsiteID\nNew id assigned to cells in every resolution (scalingID). It allows forming groups of cells, mapping the original ones to the id of the bigger cells encompassing them.\nBEAST\n\n\n\n\n\nCREATE TABLE IF NOT EXISTS public.\"MOBI_scaling_table\"\n(\n    \"verbatimSiteID\" text COLLATE pg_catalog.\"default\" NOT NULL,\n    \"datasetID\" integer NOT NULL,\n    \"scalingID\" integer NOT NULL,\n    \"siteID\" integer,\n    CONSTRAINT \"MOBI_scaling_table_PK\" PRIMARY KEY (\"verbatimSiteID\", \"datasetID\", \"scalingID\"),\n    CONSTRAINT \"NEW_scaling_table_verbatimSiteID_datasetID_fkey\" FOREIGN KEY (\"verbatimSiteID\", \"datasetID\")\n        REFERENCES public.\"MOBI_site_part1\" (\"verbatimSiteID\", \"datasetID\") MATCH SIMPLE\n) PARTITION BY LIST (\"datasetID\");\n\nCreate indexes\n\nCREATE INDEX IF NOT EXISTS idx_mobi_scaling_table_composite_all_but_verbatimsiteid\n    ON public.\"MOBI_scaling_table\" USING btree\n    (\"datasetID\" ASC NULLS LAST, \"scalingID\" ASC NULLS LAST, \"siteID\" ASC NULLS LAST)\n    INCLUDE(\"verbatimSiteID\")\n    WITH (deduplicate_items=True)\n    TABLESPACE pg_default;\n\n\nCREATE INDEX IF NOT EXISTS idx_mobi_scaling_table_verbatimsiteid\n    ON public.\"MOBI_scaling_table\" USING btree\n    (\"verbatimSiteID\" COLLATE pg_catalog.\"default\" ASC NULLS LAST)\n    WITH (deduplicate_items=True)\n    TABLESPACE pg_default;\n\n\nRecords\n\nEvents\nSampling event attributes including 1 or multiple sampling effort values and start and end year of the sampling period per cell.\n\n\n\nEvents information.\n\n\n\n\n\n\n\n\nVariable\nDescription\nSource\nType\n\n\n\n\nverbatimSiteID\nPart of composite primary key. Foreign key inherited from table “site”.\nBEAST\nTEXT\n\n\nverbatimSiteID\nPart of composite primary key. Foreign key inherited from table “site”.\nBEAST\n\n\n\ndatasetID\nPart of composite primary key. Foreign key inherited from table “site”.\nBEAST\n\n\n\nsamplingPeriodID\nPart of composite primary key.\nBEAST\n\n\n\nstartYear\nInitial year of the sampling period in every atlas.\nBEAST\n\n\n\nendYear\nInitial year of the sampling period in every atlas.\nBEAST\n\n\n\nsamplingEffortID\nForeign key inherited from table “CB_sampling_effort”.\nBEAST\n\n\n\nsamplingEffortValue\nThe amount of effort expended for sampling during an Event.\nHC\n\n\n\nsamplingEffort2ID\nForeign key inherited from table “CB_sampling_effort”.\nBEAST\n\n\n\nsamplingEffort2Value\nThe amount of effort expended for sampling during an Event.\nHC\n\n\n\nsamplingEffort3ID\nForeign key inherited from table “CB_sampling_effort”.\nBEAST\n\n\n\nsamplingEffort3Value\nThe amount of effort expended for sampling during an Event.\nHC\n\n\n\n\n\nCREATE TABLE IF NOT EXISTS public.\"MOBI_event\"\n(\n    \"verbatimSiteID\" text COLLATE pg_catalog.\"default\" NOT NULL,\n    \"datasetID\" integer NOT NULL,\n    \"samplingPeriodID\" integer NOT NULL,\n    \"startYear\" integer NOT NULL,\n    \"endYear\" integer NOT NULL,\n    \"samplingEffortID\" integer,\n    \"samplingEffortValue\" numeric,\n    remarks text COLLATE pg_catalog.\"default\",\n    \"samplingEffort2ID\" integer,\n    \"samplingEffort2Value\" numeric,\n    \"samplingEffort3ID\" integer,\n    \"samplingEffort3Value\" numeric,\n    CONSTRAINT \"MOBI_event_PK\" PRIMARY KEY (\"verbatimSiteID\", \"datasetID\", \"samplingPeriodID\"),\n    CONSTRAINT \"MOBI_event2_CB_sampling_effort_FK\" FOREIGN KEY (\"samplingEffort2ID\")\n        REFERENCES public.\"CB_sampling_effort\" (\"samplingEffortID\") MATCH SIMPLE\n        ON UPDATE NO ACTION\n        ON DELETE NO ACTION\n) PARTITION BY LIST (\"datasetID\");\n\nCreate indexes\n\nCREATE INDEX \"idx_event_verbatimSiteID\" ON \"MOBI_event\" (\"verbatimSiteID\");\n\n\nCREATE INDEX \"idx_event_datasetID\" ON \"MOBI_event\" (\"datasetID\");\n\n\nCREATE INDEX \"idx_event_samplingPeriodID\" ON \"MOBI_event\" (\"samplingPeriodID\");\n\n\nCREATE INDEX \"idx_event_samplingEffortID\" ON \"MOBI_event\" (\"samplingEffortID\");\n\n2.  ***Presences table***\n    \n    \n    Standardized original presence records handed over by the data providers.\n\nPresence information.\n\n\n\n\n\n\n\n\nVariable\nDescription\nSource\nType\n\n\n\n\nverbatimIdentificationID\nNumeric identificator of each verbatimIdentification. Foreign key inherited from table “CB_verbatim_name_equivalence”.\nBEAST\nINTEGER\n\n\nverbatimSiteID\nOriginal identificator code for grid cells. Foreign key inherited from table “event”.\nBEAST\n\n\n\ndatasetID\nNumerical identificator of the atlas/dataset. Foreign key inherited from tables “event” and “CB_verbatim_name_equivalence”.\nBEAST\n\n\n\nsamplingPeriodID\nForeign key inherited from table “MOBI_event”.\nBEAST\n\n\n\nrecordFilter\nMaximum evidence of a species inhabiting a site. Filter values used by the data providers were re-coded as numbers from low (1) to high (&gt;1) trust. NULL means no record filter was provided.\nBEAST\n\n\n\n\n\nCREATE TABLE \"MOBI_presence\" (\n    \"verbatimIdentificationID\"  INTEGER NOT NULL,\n    \"verbatimSiteID\"    TEXT NOT NULL,\n    \"datasetID\" INTEGER NOT NULL,\n    \"samplingPeriodID\"  INTEGER NOT NULL,\n    \"recordFilter\" INTEGER,\n    CONSTRAINT \"MOBI_presence_PK\" PRIMARY KEY(\"verbatimIdentificationID\",\"verbatimSiteID\",\"datasetID\",\"samplingPeriodID\"),\n    CONSTRAINT \"MOBI_presence_MOBI_event_FK\" FOREIGN KEY(\"verbatimSiteID\",\"datasetID\",\"samplingPeriodID\") REFERENCES \"MOBI_event\"(\"verbatimSiteID\",\"datasetID\",\"samplingPeriodID\") ON DELETE CASCADE,\n    CONSTRAINT \"MOBI_presence_CB_verbatim_name_equivalence_FK\" FOREIGN KEY(\"verbatimIdentificationID\",\"datasetID\") REFERENCES \"CB_verbatim_name_equivalence\"(\"verbatimIdentificationID\",\"datasetID\")\n    ) PARTITION BY LIST (\"datasetID\");\n\nCreate indexes.\n\nCREATE INDEX \"idx_presence_verbatimIdentificationID\" ON \"MOBI_presence\" (\"verbatimIdentificationID\");\n\n\nCREATE INDEX \"idx_presence_verbatimSiteID\" ON \"MOBI_presence\" (\"verbatimSiteID\");\n\n\nCREATE INDEX \"idx_presence_datasetID\" ON \"MOBI_presence\" (\"datasetID\");\n\n\nCREATE INDEX \"idx_presence_samplingPeriodID\" ON \"MOBI_presence\" (\"samplingPeriodID\");\n\n3.  **Probabilities table**\n\n    \n    Standardized probability records produced by the data providers or MOBI team members.\n\nProbabilities information.\n\n\n\n\n\n\n\n\nVariable\nDescription\nSource\nType\n\n\n\n\npresenceID\nPrimary key. Unique identifier.\nBEAST\nINTEGER\n\n\nverbatimIdentificationID\nForeign key inherited from table “CB_verbatim_name_equivalence”.\nBEAST\n\n\n\nsiteID\nForeign key inherited from table “event”.\nBEAST\n\n\n\nscalingID\nForeign key inherited from table “event”.\nBEAST\n\n\n\ndatasetID\nForeign key inherited from tables “event” and “CB_verbatim_name_equivalence”.\nBEAST\n\n\n\nsamplingPeriodID\nForeign key inherited from table “event”.\nBEAST\n\n\n\nprobability\nOccurrence probability.\nBEAST\n\n\n\nmodelID\nForeign key inherited from table “CB_model”.\nBEAST\n\n\n\n\n\nCREATE TABLE \"MOBI_probability\" (\n    \"verbatimIdentificationID\"  INTEGER NOT NULL,\n    \"verbatimSiteID\"    TEXT NOT NULL,\n    \"datasetID\" INTEGER NOT NULL,\n    \"samplingPeriodID\"  INTEGER NOT NULL,\n    \"probability\" NUMERIC NOT NULL,\n    CONSTRAINT \"MOBI_probability_PK\" PRIMARY KEY(\"verbatimIdentificationID\",\"verbatimSiteID\",\"datasetID\",\"samplingPeriodID\"),\n    CONSTRAINT \"MOBI_probability_CB_verbatim_name_equivalence_FK\" FOREIGN KEY(\"verbatimIdentificationID\",\"datasetID\") REFERENCES \"CB_verbatim_name_equivalence\"(\"verbatimIdentificationID\",\"datasetID\") ON DELETE CASCADE\n    ) PARTITION BY LIST (\"datasetID\");\n\nCreate indexes\n\nCREATE INDEX \"idx_probability_verbatimIdentificationID\" ON \"MOBI_probability\" (\"verbatimIdentificationID\");\n\n\nCREATE INDEX \"idx_probability_verbatimSiteID\" ON \"MOBI_probability\" (\"verbatimSiteID\");\n\n\nCREATE INDEX \"idx_probability_datasetID\" ON \"MOBI_probability\" (\"datasetID\");\n\n\nCREATE INDEX \"idx_probability_samplingPeriodID\" ON \"MOBI_probability\" (\"samplingPeriodID\");",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Creating database</span>"
    ]
  },
  {
    "objectID": "Creating_database.html#close-the-database-connection",
    "href": "Creating_database.html#close-the-database-connection",
    "title": "3  Creating database",
    "section": "3.7 Close the database connection",
    "text": "3.7 Close the database connection\n\ndbDisconnect(con)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Creating database</span>"
    ]
  },
  {
    "objectID": "Creating_database.html#er-diagram",
    "href": "Creating_database.html#er-diagram",
    "title": "3  Creating database",
    "section": "3.8 ER diagram",
    "text": "3.8 ER diagram\n\n\n\n\n\n\n\n\n\n\n\n(a)\n\n\n\n\n\n\n\n\n\n\n\n\n\n(b)\n\n\n\n\n\n\n\nFigure 3.1: Entity relationship (ER) diagram. It Shows from left to right the most dependent tables to the least dependent ones. The key symbol represents a primary key. Multiple key symbols in a table represent composite primary keys. Blue arrows at the right border of each table mark foreign keys inherited from a table upstream. Variable types are shown in capital letters to the right. Bold letters are columns defined as NOT NULL. The links between main tables are shown in Figure 3.1 (a) while the whole ER diagram is in Figure 3.1 (b).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Creating database</span>"
    ]
  },
  {
    "objectID": "Japan.html",
    "href": "Japan.html",
    "title": "4  Birds of Alberta",
    "section": "",
    "text": "4.1 MOBI team roles",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Birds of Alberta</span>"
    ]
  },
  {
    "objectID": "Japan.html#mobi-team-roles",
    "href": "Japan.html#mobi-team-roles",
    "title": "4  Birds of Alberta",
    "section": "",
    "text": "Responsibilities\nName\nDate (MM/YY)\n\n\n\n\nData acquisition\nCarmen Soria\n03/23\n\n\nMetadata preparation\nKateřina Tschernosterová\n\n\n\nData standardization\nKateřina Tschernosterová\nGabriel Ortega\n08/24\n\n\nData processing\nGabriel Ortega\nCarmen Soria",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Birds of Alberta</span>"
    ]
  },
  {
    "objectID": "Japan.html#data-providers-metadata-and-co-authorships",
    "href": "Japan.html#data-providers-metadata-and-co-authorships",
    "title": "4  Birds of Alberta",
    "section": "4.2 Data providers metadata and co-authorships",
    "text": "4.2 Data providers metadata and co-authorships\nAlways check the updated information here\nThe original documents folder including books, publications or email exchanges are here",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Birds of Alberta</span>"
    ]
  },
  {
    "objectID": "Japan.html#data-description",
    "href": "Japan.html#data-description",
    "title": "4  Birds of Alberta",
    "section": "4.3 Data description",
    "text": "4.3 Data description\n\n4.3.1 Sampling methodology\n\n4.3.1.1 Survey Methodology\nEach survey was conducted by 1–2 people in most locations.\nObservations were made at two fixed points for 30 minutes each, followed by a 3 km walk at a speed of approximately 2 km/h.\nThe total survey time per location was about 2.5 hours.\n\n\n4.3.1.2 Data Gaps\nThere are cells in northern Japan (Kuril Islands) without bird data.\n\n\n\n4.3.2 Sampling effort\nThe effort is valid only when using fieldwork data.\n\n\n4.3.3 Licensing and Access\nThe dataset is classified as “restricted” in the database because no explicit license is declared. However, it is publicly accessible without restrictions for general use.\nFor detailed information or specific permissions regarding data usage, contact:\nJapan Bird Research Association: info@bird-research.jp\nM. Ueta: mj-ueta@bird-research.jp\n\n\n4.3.4 Original data folder\n\n\n4.3.5 Grid folder\n\n\n4.3.6 Docs folder\n\n\n4.3.7 Checked data folder",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Birds of Alberta</span>"
    ]
  },
  {
    "objectID": "Japan.html#data-standardization-and-processing-comments",
    "href": "Japan.html#data-standardization-and-processing-comments",
    "title": "4  Birds of Alberta",
    "section": "4.4 Data standardization and processing comments",
    "text": "4.4 Data standardization and processing comments",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Birds of Alberta</span>"
    ]
  },
  {
    "objectID": "Japan.html#libraries",
    "href": "Japan.html#libraries",
    "title": "4  Birds of Alberta",
    "section": "4.5 Libraries",
    "text": "4.5 Libraries\n\npacman::p_load(\n  sf, terra, data.table, tidyverse, tidyterra, tidytable, knitr,\n  tictoc, RPostgres, DBI, dbplyr, parallel,\n  geodata\n)\n\n\n4.5.1 Preparation\n\n# Variables\nseldata &lt;- \"data/4processedAtlases/Birds_atlas_Japan\"\ndatasetID &lt;- 13\nlicenseID &lt;- 1\nverbatimFootprintSRS &lt;- \"epsg:4326\"\n\n# Data processing\ndataset &lt;- readRDS(paste0(seldata, \"_beast_data.rds\")) %&gt;%\n  as.data.table() %&gt;%\n  mutate(questionnaires = recode(questionnaires, `0` = NA, `1` = 2)) %&gt;%\n  mutate(recordFilter = recode(rowSums(across(c(field_surveys, questionnaires)), na.rm = TRUE), `3` = 1)) %&gt;%\n  mutate(recordFilter = ifelse(is.na(field_surveys) & is.na(questionnaires), NA, recordFilter))\n\nspnamesinfo &lt;- read.csv(paste0(seldata, \"_spnames_INFO.csv\")) %&gt;%\n  as.data.table() %&gt;%\n  mutate(cellID = str_split(cellID, pattern = \",\")) %&gt;%\n  unnest(cellID) %&gt;%\n  select(cellID, name_in_data, original_verbatim_name) %&gt;%\n  mutate(cellID = cellID) %&gt;%\n  unique()\n\ngrid &lt;- st_layers(paste0(seldata, \"_grid.gpkg\"))$name %&gt;%\n  sapply(., USE.NAMES = T, simplify = F, function(x) {\n    st_read(paste0(seldata, \"_grid.gpkg\"), layer = x)\n  })\n\ncorrs &lt;- readRDS(paste0(seldata, \"_cells_corr.rds\")) %&gt;%\n  as.data.table() %&gt;%\n  pivot_longer(-cellID, names_to = \"cell_grouping\", values_to = \"cell_label\") %&gt;%\n  mutate(cell_grouping = as.numeric(cell_grouping))\n\nfull_data &lt;- left_join(dataset, corrs, by = c(\"cell_grouping\", \"cell_label\"), relationship = \"many-to-many\") %&gt;%\n  left_join(., filter(spnamesinfo, !is.na(cellID)), by = c(\"cellID\" = \"cellID\", \"verbatim_name\" = \"name_in_data\")) %&gt;%\n  mutate(verbatim_name = ifelse(is.na(original_verbatim_name), verbatim_name, original_verbatim_name)) %&gt;%\n  select(-original_verbatim_name) %&gt;%\n  unique() %&gt;%\n  mutate(\n    datasetID = datasetID,\n    licenseID = licenseID,\n    verbatimIdentificationID = dense_rank(verbatim_name),\n    samplingPeriod = dense_rank(start_year),\n    # Double check original effort columns before running this\n    effort = NA,\n    samp_effort_type = NA\n  ) %&gt;%\n  unique()\n\ngc()\n\n\n\n4.5.2 Database connection\n\nsource(\"scripts/dbcon.R\")\n\n\n\n4.5.3 List tables in database\n\ndbListTables(con) %&gt;%\n  purrr::keep(., ~ grepl(\"^CB|^MOBI\", .)) %&gt;%\n  kable(col.names = \"Tables\")\n\n\n\n4.5.4 Write code books\n\n4.5.4.1 CB_license\n\ntable &lt;- \"CB_license\" ## Table of interest\n\nCheck table colnames\n\ntbl(con, table) %&gt;%\n  as.data.table() %&gt;%\n  colnames() %&gt;%\n  paste(., ' = \"\"', collapse = \",\\n\") %&gt;%\n  cat()\n\nCreate data table\n\ndata_table &lt;- data.table(\n  licenseID = licenseID,\n  license = \"Closed\",\n  licenseDescription = \"Publicly available on a data portal. No license specified.\",\n  licenseURL = \"none\"\n)\n\nWrite into the database\n\ntry({\n  copy_to(con, data_table, table, append = T)\n})\nrm(data_table)\n\nCheck the table\n\ntbl(con, table) %&gt;% kable(align = \"c\")\n\n\n\n4.5.4.2 CB_sampling_effort\n\ntable &lt;- \"CB_sampling_effort\" ## Table of interest\n\nCheck table colnames\n\ntbl(con, table) %&gt;%\n  as.data.table() %&gt;%\n  colnames() %&gt;%\n  paste(., ' = \"\"', collapse = \",\\n\") %&gt;%\n  cat()\n\nCreate data table\n\ndata_table &lt;- data.table(\n  samplingEffortID = \"\",\n  samplingEffortProtocol = \"\",\n  samplingEffortUnit = \"\"\n)\n\nWrite into the database\n\ntry({\n  copy_to(con, data_table, table, append = T)\n})\nrm(data_table)\n\nCheck table.\n\ntbl(con, table) %&gt;% kable(align = \"c\")\n\n\n\n4.5.4.3 CB_model\n\ntable &lt;- \"CB_model\" ## Table of interest\n\nCheck table colnames\n\ntbl(con, table) %&gt;%\n  as.data.table() %&gt;%\n  colnames() %&gt;%\n  paste(., ' = \"\"', collapse = \",\\n\") %&gt;%\n  cat()\n\nCreate data table\n\ndata_table &lt;- data.table(\n  occurrenceModelID = \"\",\n  modelName = \"\",\n  predictorVariables = \"\",\n  bibliographicCitation = \"\"\n)\n\nWrite into the database\n\ntry({\n  copy_to(con, data_table, table, append = T)\n})\nrm(data_table)\n\nCheck table\n\ntbl(con, table) %&gt;% kable(align = \"c\")\n\n\n\n4.5.4.4 CB_taxonomy\n\ntable &lt;- \"CB_taxonomy\" ## Table of interest\n\nCheck table colnames\n\ntbl(con, table) %&gt;%\n  as.data.table() %&gt;%\n  colnames() %&gt;%\n  paste(., ' = \"\"', collapse = \",\\n\") %&gt;%\n  cat()\n\nCreate data table\n\ndata_table &lt;- data.table(\n  scientificNameID = \"\",\n  scientificName = \"\",\n  scientificNameAuthorship = \"\",\n  kingdom = \"\",\n  phylum = \"\",\n  class = \"\",\n  family = \"\",\n  order = \"\",\n  genus = \"\",\n  specificEpitet = \"\",\n  infraspecificEpitet = \"\",\n  taxonRank = \"\"\n)\n\nWrite into the database\n\ntry({\n  copy_to(con, data_table, table, append = T)\n})\nrm(data_table)\n\n\n\n4.5.4.5 CB_verbatim_name_equivalence\n\ntable &lt;- \"CB_verbatim_name_equivalence\" ## Table of interest\n\nCheck table colnames\n\ntbl(con, table) %&gt;%\n  as.data.table() %&gt;%\n  colnames() %&gt;%\n  paste(., ' = \"\"', collapse = \",\\n\") %&gt;%\n  cat()\n\nCreate data table\n\ndata_table &lt;- data.table(\n  verbatimIdentificationID = full_data$verbatimIdentificationID,\n  verbatimIdentification = full_data$verbatim_name,\n  datasetID = full_data$datasetID,\n  identificationReferences = \"\",\n  scientificNameID = NA\n) %&gt;% unique()\n\nWrite into the database\n\ntry({\n  # Remove records where datasetID is the current dataset\n  dbExecute(con, paste0('DELETE FROM \"', table, '\" WHERE \"datasetID\" = ', datasetID))\n\n  # Copy data to the database\n  copy_to(con, data_table, table, append = TRUE)\n})\n\n# Remove the data_table from the environment\nrm(data_table)\n\nCheck table.\n\ntbl(con, sql(paste0('SELECT * FROM \"', table, '\" WHERE \"datasetID\" = ', datasetID))) %&gt;%\n  head() %&gt;%\n  kable(align = \"c\")\n\n\n\n\n4.5.5 Write dataset tables\n\n4.5.5.1 Dataset\n\ntable &lt;- \"MOBI_dataset\" ## Table of interest\n\nCheck table colnames\n\ntbl(con, table) %&gt;%\n  as.data.table() %&gt;%\n  colnames() %&gt;%\n  paste(., ' = \"\"', collapse = \",\\n\") %&gt;%\n  cat()\n\nCreate data table\n\ndata_table &lt;- data.table(\n  datasetID = datasetID,\n  datasetName = \"Japan Breeding Bird Atlas\",\n  datasetPublisher = \"Japan Bird Research Association\",\n  datasetPublisherContact = \"mj-ueta@bird-research.jp | info@bird-research.jp\",\n  licenseID = licenseID,\n  rightsHolder = \"Japan Bird Research Association\",\n  bibliographicCitation = \"Mutsuyuki Ueta, Shingo Uemura, Hayama Seiji, Teppei Ara, Shinichi Takagawa, Noritomo Kawaji, Manabu Kajita, Noboru Nakamura, Saki Tabata, Yuna Uchiyama, 20km mesh bird breeding distribution data collected in the National Bird Breeding Distribution Survey, Bird Research, 2021, Volume 17, p. R5-R9, Publication date 2021/10/25, Online ISSN 1880-1595, Print ISSN 1880-1587, https://doi.org/10.11211/birdresearch.17.R5, https://www.jstage.jst.go.jp/article/birdresearch/17/0/17_R5/_article/-char/ja\",\n  citationIdentifier = \"\",\n  provider = \"Japan Bird Research Association\",\n  shareable = \"NO\",\n  coauthorshipRequired = \"YES\",\n  coauthors = \"Mutsuyuki Ueta - mj-ueta@bird-research.jp\",\n  coauthorshipSuggested = \"Carmen Soria - carmendianasoria@gmail.com | Kateřina Tschernosterová - tschernosterova@fzp.czu.cz | Friederike Wölke - friederike.woelke@gmail.com | Gabriel Ortega - g.ortega.solis@gmail.com\",\n  isSamplingEffortReported = \"NO\",\n  isOccurrenceProbabilityAvailable = \"NO\",\n  recordFilterMeaning = \"NULL = No information, 1 = Field surveys, 2 = Questionnaires\"\n)\n\nWrite into the database\n\ntry({\n  dbExecute(con, paste0('DELETE FROM \"', table, '\" WHERE \"datasetID\" = ', datasetID))\n  copy_to(con, data_table, table, append = T)\n})\nrm(data_table)\n\nCheck table.\n\ntbl(con, sql(paste0('SELECT * FROM \"', table, '\" WHERE \"datasetID\" = ', datasetID))) %&gt;% kable(align = \"c\")\n\n\n\n4.5.5.2 Site\n\ntable &lt;- \"MOBI_site\" ## Table of interest\n\nCreate partition\n\nCREATE TABLE \"MOBI_site_13\" PARTITION OF \"MOBI_site\"\nFOR VALUES IN (13);\n\nCheck table colnames\n\ntbl(con, table) %&gt;%\n  as.data.table() %&gt;%\n  colnames() %&gt;%\n  paste(., ' = \"\"', collapse = \",\\n\") %&gt;%\n  cat()\n\nCreate data table\n\ndata_table &lt;- data.table(\n  siteID = full_data$cell_label,\n  scalingID = full_data$cell_grouping,\n  datasetID = full_data$datasetID,\n  area = full_data$area,\n  croppedArea = full_data$area_cropped,\n  areaUnit = \"km2\",\n  maxLength = NA,\n  northSouthLength = NA,\n  eastWestLength = NA,\n  lengthUnit = \"km\",\n  centroidDecimalLongitude = full_data$cell_long,\n  centroidDecimalLatitude = full_data$cell_lat,\n  samplingRepetitions = full_data$repeated\n) %&gt;% unique()\n\nWrite into the database\n\ntry({\n  # Remove records where datasetID is the current dataset\n  dbExecute(con, paste0('DELETE FROM \"', table, '\" WHERE \"datasetID\" = ', datasetID))\n\n  # Copy data to the database\n  copy_to(con, data_table, table, append = TRUE)\n})\n\n# Remove the data_table from the environment\nrm(data_table)\n\nCheck table.\n\ntbl(\n  con,\n  sql(paste0('SELECT * FROM \"', table, '\" WHERE \"datasetID\" = ', datasetID))\n) %&gt;%\n  head(n = 20) %&gt;%\n  kable(align = \"c\")\n\n\n\n4.5.5.3 Geometry\n\ntable &lt;- \"MOBI_geometry\" ## Table of interest\n\nCreate partition\n\nCREATE TABLE \"MOBI_geometry_13\" PARTITION OF \"MOBI_geometry\"\nFOR VALUES IN (13);\n\nCheck table colnames\n\ntbl(con, table) %&gt;%\n  as.data.table() %&gt;%\n  colnames() %&gt;%\n  paste(., ' = \"\"', collapse = \",\\n\") %&gt;%\n  cat()\n\nCreate data table\n\ndata_table &lt;- grid %&gt;%\n  dplyr::bind_rows() %&gt;%\n  ungroup() %&gt;%\n  rename(\n    siteID = cell_label,\n    scalingID = cell_grouping,\n    geometry = geom\n  ) %&gt;%\n  mutate(\n    siteID = as.integer(siteID),\n    scalingID = as.integer(scalingID),\n    datasetID = as.integer(datasetID),\n    footprintSRS = \"epsg:4326\",\n    verbatimFootprintSRS = verbatimFootprintSRS\n  ) %&gt;%\n  select(\n    ., siteID, scalingID, datasetID,\n    footprintSRS, verbatimFootprintSRS, geometry\n  )\n\ndata_table$geometry &lt;- st_cast(data_table$geometry, \"MULTIPOLYGON\")\n\nWrite into the database\n\ntry({\n  # Remove records where datasetID is the current dataset\n  dbExecute(con, paste0('DELETE FROM \"', table, '\" WHERE \"datasetID\" = ', datasetID))\n\n  # Write records\n  st_write(obj = data_table, dsn = con, layer = table, append = T)\n  # Remove the data_table from the environment\n  # rm(data_table)\n})\n\nCheck table.\n\ntbl(con, sql(paste0('SELECT * FROM \"', table, '\" WHERE \"datasetID\" = ', datasetID))) %&gt;%\n  head() %&gt;%\n  kable(align = \"c\")\n\n\n\n\n4.5.6 Write helper tables\n\n4.5.6.1 Scaling table\nThis intermediate table enables the joins of records data to the different resolutions of sites.\n\ntable &lt;- \"MOBI_scaling_table\" ## Table of interest\n\nCreate partition\n\nCREATE TABLE \"MOBI_scaling_table_13\" PARTITION OF \"MOBI_scaling_table\"\nFOR VALUES IN (13);\n\nCheck table colnames.\n\ntbl(con, table) %&gt;%\n  as.data.table() %&gt;%\n  colnames() %&gt;%\n  paste(., ' = \"\"', collapse = \",\\n\") %&gt;%\n  cat()\n\n\ndata_table &lt;- data.table(\n  siteID = full_data$cell_label,\n  scalingID = full_data$cell_grouping,\n  datasetID = datasetID,\n  verbatimSiteID = full_data$cellID\n) %&gt;% unique()\n\nWrite into database.\n\ntry({\n  # Remove records where datasetID is the current dataset\n  dbExecute(con, paste0('DELETE FROM \"', table, '\" WHERE \"datasetID\" = ', datasetID))\n\n  # Copy data to the database\n  copy_to(con, data_table, table, append = TRUE)\n})\n\n# Remove the data_table from the environment\nrm(data_table)\n\nCheck table.\n\ntbl(con, sql(paste0('SELECT * FROM \"', table, '\" WHERE \"datasetID\" = ', datasetID))) %&gt;%\n  head() %&gt;%\n  kable(align = \"c\")\n\n\n\n\n4.5.7 Write records tables\n\n4.5.7.1 Event\n\ntable &lt;- \"MOBI_event\" ## Table of interest\n\nCreate partition\n\nCREATE TABLE \"MOBI_event_13\" PARTITION OF \"MOBI_event\"\nFOR VALUES IN (13);\n\nCheck table colnames\n\ntbl(con, table) %&gt;%\n  as.data.table() %&gt;%\n  colnames() %&gt;%\n  paste(., ' = \"\"', collapse = \",\\n\") %&gt;%\n  cat()\n\nCreate data table\n\ndata_table &lt;- filter(full_data, cell_grouping == 1) %&gt;%\n  mutate(\n    verbatimSiteID = cellID,\n    datasetID = datasetID,\n    samplingPeriodID = samplingPeriod,\n    startYear = start_year,\n    endYear = end_year,\n    samplingEffortID = samp_effort_type,\n    samplingEffortValue = effort\n  ) %&gt;%\n  select(\n    verbatimSiteID,\n    datasetID,\n    samplingPeriodID,\n    startYear,\n    endYear,\n    samplingEffortID,\n    samplingEffortValue\n  ) %&gt;%\n  unique()\n\n# if (nrow(unique(data_table)) != nrow(eff)) {\n#   stop(\"Stopping execution due to row number mismatch\")\n# } else {\n#   print(\"OK\")\n# }\n\ndata_table &lt;- filter(data_table, !is.na(verbatimSiteID))\n\nWrite into the database\n\ntry({\n  # Remove records where datasetID is the current dataset\n  dbExecute(con, paste0('DELETE FROM \"', table, '\" WHERE \"datasetID\" = ', datasetID))\n\n  # Copy data to the database\n  copy_to(con, data_table, table, append = TRUE)\n})\n\n# Remove the data_table from the environment\nrm(data_table)\n\nCheck table.\n\ntbl(con, sql(paste0('SELECT * FROM \"', table, '\" WHERE \"datasetID\" = ', datasetID))) %&gt;%\n  head() %&gt;%\n  kable(align = \"c\")\n\n\n\n4.5.7.2 Presence\n\ntable &lt;- \"MOBI_presence\" ## Table of interest\n\nCreate partition\n\nCREATE TABLE \"MOBI_presence_13\" PARTITION OF \"MOBI_presence\"\nFOR VALUES IN (13);\n\nCheck table colnames\n\ntbl(con, table) %&gt;%\n  as.data.table() %&gt;%\n  colnames() %&gt;%\n  paste(., ' = \"\"', collapse = \",\\n\") %&gt;%\n  cat()\n\nCreate data table\n\ndata_table &lt;- filter(full_data, cell_grouping == 1) %&gt;%\n  mutate(\n    verbatimIdentificationID = verbatimIdentificationID,\n    verbatimSiteID = cellID,\n    datasetID = datasetID,\n    samplingPeriodID = samplingPeriod\n  ) %&gt;%\n  select(\n    verbatimIdentificationID,\n    verbatimSiteID,\n    datasetID,\n    samplingPeriodID,\n    recordFilter\n  ) %&gt;%\n  unique()\n\nWrite into the database\n\ntry({\n  # Remove records where datasetID is the current dataset\n  dbExecute(con, paste0('DELETE FROM \"', table, '\" WHERE \"datasetID\" = ', datasetID))\n\n  # Copy data to the database\n  copy_to(con, data_table, table, append = TRUE)\n})\n\n# Remove the data_table from the environment\nrm(data_table)\n\nCheck table.\n\ntbl(con, sql(paste0('SELECT * FROM \"', table, '\" WHERE \"datasetID\" = ', datasetID))) %&gt;%\n  head() %&gt;%\n  kable(align = \"c\")\n\n\n\n4.5.7.3 Probability\n\ntable &lt;- \"MOBI_probability\" ## Table of interest\n\nCreate partition\n\nCREATE TABLE \"MOBI_probability_13\" PARTITION OF \"MOBI_probability\"\nFOR VALUES IN (13);\n\nCheck table colnames\n\ntbl(con, table) %&gt;%\n  as.data.table() %&gt;%\n  colnames() %&gt;%\n  paste(., ' = \"\"', collapse = \",\\n\") %&gt;%\n  cat()\n\nCreate data table\n\ndata_table &lt;- data.table(\n  verbatimIdentificationID = \"\",\n  verbatimSiteID = \"\",\n  datasetID = \"\",\n  samplingPeriodID = \"\",\n  probability = \"\"\n)\n\nWrite into the database\n\ntry({\n  # Remove records where datasetID is the current dataset\n  dbExecute(con, paste0('DELETE FROM \"', table, '\" WHERE \"datasetID\" = ', datasetID))\n\n  # Copy data to the database\n  copy_to(con, data_table, table, append = TRUE)\n})\n\n# Remove the data_table from the environment\nrm(data_table)\n\nCheck table.\n\ntbl(con, sql(paste0('SELECT * FROM \"', table, '\" WHERE \"datasetID\" = ', datasetID))) %&gt;%\n  head() %&gt;%\n  kable(align = \"c\")",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Birds of Alberta</span>"
    ]
  },
  {
    "objectID": "Alberta.html",
    "href": "Alberta.html",
    "title": "5  Birds of Alberta",
    "section": "",
    "text": "5.1 MOBI team roles",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Birds of Alberta</span>"
    ]
  },
  {
    "objectID": "Alberta.html#mobi-team-roles",
    "href": "Alberta.html#mobi-team-roles",
    "title": "5  Birds of Alberta",
    "section": "",
    "text": "Responsibilities\nName\nDate (MM/YY)\n\n\n\n\nData acquisition\nCarmen Soria\n08/23\n\n\nMetadata preparation\nKateřina Tschernosterová\n\n\n\nData standardization\nKateřina Tschernosterová\n08/24\n\n\nData processing\nGabriel Ortega\nCarmen Soria",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Birds of Alberta</span>"
    ]
  },
  {
    "objectID": "Alberta.html#data-providers-metadata-and-co-authorships",
    "href": "Alberta.html#data-providers-metadata-and-co-authorships",
    "title": "5  Birds of Alberta",
    "section": "5.2 Data providers metadata and co-authorships",
    "text": "5.2 Data providers metadata and co-authorships\nAlways check the updated information here\nThe original documents folder including books, publications or email exchanges are here",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Birds of Alberta</span>"
    ]
  },
  {
    "objectID": "Alberta.html#data-description",
    "href": "Alberta.html#data-description",
    "title": "5  Birds of Alberta",
    "section": "5.3 Data description",
    "text": "5.3 Data description\n\nObservation data by grid cell, by species and by observation card (year, sampling event and data collector)\nPresence is reported, no data on abundance or absence\nOriginal data detail - Scientific species name, Common species name, Survey area identifier, Decimal latitude and longitude of survey area, Year (month, day) collected, Collector number, Sampling event identifier, Effort in hours (BBA2 only, not for all events), Breeding bird atlas code\nData was downloaded trough NatureCounts website - https://naturecounts.ca/nc/default/explore.jsp#download\n\nDownloaded dataset with BBA1 data - Alberta Breeding Bird Atlas (1987-1992) [NatureCounts (hosted datasets)]\nDownloaded dataset with BBA2 data - Alberta Breeding Bird Atlas (2000-2005) [NatureCounts (hosted datasets)]\nAnother available dataset that was not used - Alberta Bird Records [NatureCounts (hosted datasets)]\n\nNature Alberta (formerly known as Federation of Alberta Naturalists), Birding in Alberta website - https://naturealberta.ca/birding/\nAll the newsletters of the Breeding Bird Atlas of Alberta: Update Project were downloaded from website - https://andrelegris.com/environmental-science/\nNature Alberta should have additional bird records database available on eBird, NatureCounts or on request (Database Administrator) - records should be from the first Breeding Bird Atlas project, from individual naturalists, from the May Species Counts, from the Christmas Birds Count and all other data submitted through the Alberta Birdlist program\nRelated regional websites devoted to birds are listed in BBA2_Newsletter_1 pdf, p.8\n\n\n5.3.1 Sampling methodology\n\nData was collected in sampling squares by volunteer atlasers\nSampling atlas squares are 10 km by 10 km (100 km2), there are 6623 Universal Transverse Mercator (UTM) squares in the province\nThe overall goal of the first atlas project was to survey 25% of the survey squares in the settled area of the province and 10% of the squares in the more remote areas\nBBA1 survey data was collected during the February-August period over five field seasons (1987 to 1991) by 943 volunteer atlasers. These volunteers spent about 40,000 hours in the field, collecting 122,400 records of bird breeding activity. Of the 6623 atlas squares in Alberta, 2206 (33%) received adequate survey coverage\nThe goal of the Atlas Update Project is to survey not only more squares than were surveyed in the initial Atlas but to ensure that all priority squares identified in the first atlas are also surveyed\nBBA2 Remote Areas Program - implemented to increase our understanding of bird populations in the northern regions of Alberta. The program is led by researchers from the University of Alberta, the program will intensively survey specific atlas squares with the goal of analyzing the relationships between bird distribution and abundance, and associated habitats and landscape patterns (BBA2_Newsletter_1 pdf, p.9)\nMore Atlas Grid System related information can be found in BBA2_Newsletter_1 pdf, p.13\nA detailed description of how the atlas surveys are done can be found in the NORAC Atlasser’s Handbook: https://naturecounts.ca/norac/index.jsp?targetpg=handbook\n\n\n\n5.3.2 Sampling effort\n\nIn BBA1 data there is no information on duration of sampling events, therefore sampling effort is reported as number of sampling events per grid cell\nFor BBA2 there is sampling duration in hours reported for some sampling events - but for some events the value of duration hours is negative and for some events the value is missing. The value of sampling event duration can be used, but only with restrictions.\nTherefore sampling effort for BBA2 is also reported as number of sampling events per grid cell\n\n\n\n5.3.3 Original data folder\n\nBirds_Atlas_Alberta_1-2_Column names.txt - text file with the list of original data column names\nBirds_Atlas_Alberta_1_Data.txt - text file with data for BBA1 1984-1989\nBirds_Atlas_Alberta_2_Data.txt - text file with data for BBA2 2000-2005, corrected\nBirds_Atlas_Alberta_2_Data original.txt - text file with original data for BBA2 2000-2005, with several mistakes (listed below in Data standardization part)\n\n\n\n5.3.4 Grid folder\n\nalberta_gridmap.shp\n\n\n\n5.3.5 Docs folder\n\nBirds_Atlas_Alberta_Readme Fixing Data.txt - readme file, text was copied to the section Data standardization and processing comments of this document\nBirds_Atlas_Alberta_2_Newsletter_1.pdf - the newsletters of the Breeding Bird Atlas of Alberta: Update Project (April 2002)\nBirds_Atlas_Alberta_2_Newsletter_2.pdf - the newsletters of the Breeding Bird Atlas of Alberta: Update Project (February 2003)\nBirds_Atlas_Alberta_2_Newsletter_3.pdf - the newsletters of the Breeding Bird Atlas of Alberta: Update Project (July 2003)\nBirds_Atlas_Alberta_2_Newsletter_4.pdf - the newsletters of the Breeding Bird Atlas of Alberta: Update Project (March 2004)\nBirds_Atlas_Alberta_2_Newsletter_5.pdf - the newsletters of the Breeding Bird Atlas of Alberta: Update Project (July 2004)",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Birds of Alberta</span>"
    ]
  },
  {
    "objectID": "Alberta.html#data-standardization-and-processing-comments",
    "href": "Alberta.html#data-standardization-and-processing-comments",
    "title": "5  Birds of Alberta",
    "section": "5.4 Data standardization and processing comments",
    "text": "5.4 Data standardization and processing comments\nREADME done by Carmen Soria - Modifications to Bird_Atlas_Alberta_2_Data.txt (the original is named as Bird_Atlas_Alberta_2_Data original.txt)\nThere were mistakes in the original data file of the second Atlas of Alberta, which have been FIXED\n\nSome rows had misplaced columns. This is because in the txt they had put two localities while keeping the number of tab separations. I fixed that by separating the info of those localities by a space and not a tab. The rows that had this were: 79720, 79721, 79769, 79770, 162864, 162865, 166830, 176022, 184714, 184715, 184716, 186566, 186567, 186568, 199957, 199958, 199959, 199960, 199961, 199963, 199964\nRow 132159 had an issue in which in one cell it said “many’. That made the cell contain info for around 50 rows. Changed ’ to” and it was fixed.\nThere were 1333 rows that didn’t have info from the column locality onward. This is because the text for that locality had #. Deleted the # and it was fixed.\n\n!!! IMPORTANT !!! the sampling effort in hours is not complete",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Birds of Alberta</span>"
    ]
  },
  {
    "objectID": "Alberta.html#libraries",
    "href": "Alberta.html#libraries",
    "title": "5  Birds of Alberta",
    "section": "5.5 Libraries",
    "text": "5.5 Libraries\n\npacman::p_load(\n  sf, terra, tidyverse, tidyterra, knitr,\n  tictoc, RPostgres, DBI, dbplyr, parallel,\n  geodata\n)",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Birds of Alberta</span>"
    ]
  },
  {
    "objectID": "Alberta.html#grid-processing",
    "href": "Alberta.html#grid-processing",
    "title": "5  Birds of Alberta",
    "section": "5.6 Grid processing",
    "text": "5.6 Grid processing\n\nunzip data/Birds_Alberta/Original_data.zip -d /tmp/\n\n\nglimpse(vect(\"/tmp/Original_data/alberta_gridmap.shp\"))\n\n\ngrid &lt;- st_read(\"/tmp/Original_data/alberta_gridmap.shp\") %&gt;%\n  st_make_valid() %&gt;%\n  select(utm_sqr, utm_stn, utm_nrt, utm_zon) %&gt;%\n  rename(cellID = utm_sqr) %&gt;%\n  filter(!is.na(cellID))\n\nlength(grid$cellID) == length(unique(grid$cellID))\n\n\ngrid_grouping &lt;- function(grid, col1, col2, num) {\n  grid &lt;- st_drop_geometry(grid)\n  mincol1 &lt;- min(grid[[col1]])\n  maxcol1 &lt;- max(grid[[col1]])\n  mincol2 &lt;- min(grid[[col2]])\n  maxcol2 &lt;- max(grid[[col2]])\n  breaksA &lt;- seq(mincol1, maxcol1, num)\n  breaksB &lt;- seq(mincol2, maxcol2, num)\n  if (length(breaksA) &gt; 1) {\n    A &lt;- cut(grid[[col1]], breaks = breaksA, right = F)\n  } else {\n    A &lt;- 1\n  }\n  if (length(breaksB) &gt; 1) {\n    B &lt;- cut(grid[[col2]], breaks = breaksB, right = F)\n  } else {\n    B &lt;- 1\n  }\n  res &lt;- paste0(grid$utm_zon, \"_\", A, B)\n  return(res)\n}\n\nCreate labels for rescaling\n\nfor (dist in c(2, 4, 8, 16, 32, 64, 128)) {\n  num &lt;- 10000 * dist\n  grid[[paste0(dist)]] &lt;- grid_grouping(grid, col1 = \"utm_stn\", col2 = \"utm_nrt\", num = num)\n}\n\ngrid$`1` &lt;- dense_rank(grid$cellID)\n\ngrid &lt;- grid %&gt;% mutate(across(matches(\"^\\\\d\"), dense_rank))\n\nst_write(grid, \"/tmp/alberta.gpkg\", delete_dsn = T)\n\nThe grid was manually checked in QGIS to merge small cells with their neighbors. Small or even linear cells occur in borders of UTM zones in the original grid. We also reassigned some cells to groupings in every scale so that they end up mostly aligned and closer to the expected standard sizes per scale. The resulting grid was saved as modified_grid.gpkg.\n\nqgis /tmp/alberta.gpkg\n\nWe have different percentages of overlap between cells and real country borders. Therefore, we should have a way to correct the areas.\n\ngrid &lt;- st_read(\"data/Birds_Alberta/Checked_data/modified_grid.gpkg\") %&gt;%\n  mutate(across(matches(\"^X\\\\d\"), dense_rank))\n\nadm_boundary &lt;- gadm(\"CAN\", path = \"/tmp/\") %&gt;%\n  select(ISO_1) %&gt;%\n  filter(ISO_1 == \"CA-AB\")\n\nint &lt;- terra::intersect(select(vect(grid), cellID), adm_boundary)\n\nint &lt;- group_by(int, cellID) %&gt;% summarise()\n\nint$cropped_area &lt;- expanse(int, unit = \"km\")\n\ngrid &lt;- as.data.frame(int) %&gt;%\n  left_join(grid, ., by = \"cellID\")\n\nCalculate cell area with and without correction by landmasses or country borders.\n\ngrid$cell_area &lt;- expanse(vect(grid), unit = \"km\")\ngrid$cell_area_proportion &lt;- grid$cropped_area / grid$cell_area %&gt;% round(., digits = 2)\n\n\n# Pivot cells to a longer format for easier use in models.\nfinal_grids &lt;- grid %&gt;%\n  pivot_longer(matches(\"^X\\\\d\"),\n    names_to = \"cell_grouping\",\n    values_to = \"cell_label\"\n  ) %&gt;%\n  mutate(cell_grouping = str_remove_all(cell_grouping, \"X\") %&gt;%\n    as.numeric())\n\nfinal_grids &lt;- split(final_grids, final_grids$cell_grouping)\n\nAggregate cells and summarize the area.\n\nfinal_grids &lt;- final_grids %&gt;%\n  lapply(., function(x) {\n    res &lt;- x %&gt;%\n      group_by(cell_grouping, cell_label) %&gt;%\n      summarise(\n        area = sum(cell_area, na.rm = T),\n        area_cropped = sum(cropped_area, na.rm = T)\n      ) %&gt;%\n      ungroup()\n  })\n\nFunctions to add additional variables of cell shapes\n\n# Function to get cell shape attributes\n\nfdistances &lt;- function(x, type = NULL) {\n  x &lt;- vect(x)\n  pol &lt;- as.data.frame(crds(as.points(ext(project(x, \"epsg:4326\")))))\n  if (type == \"ew\") {\n    sw &lt;- pol %&gt;%\n      summarise(x = min(x), y = min(y)) %&gt;%\n      as.matrix()\n    se &lt;- pol %&gt;%\n      summarise(x = max(x), y = min(y)) %&gt;%\n      as.matrix()\n    res &lt;- distance(sw, se, lonlat = T)[[1]] / 1000\n  }\n  if (type == \"ns\") {\n    sw &lt;- pol %&gt;%\n      summarise(x = min(x), y = min(y)) %&gt;%\n      as.matrix()\n    nw &lt;- pol %&gt;%\n      summarise(x = min(x), y = max(y)) %&gt;%\n      as.matrix()\n    res &lt;- distance(sw, nw, lonlat = T)[[1]] / 1000\n  }\n  if (type == \"max\") {\n    res &lt;- distance(pol, lonlat = T) %&gt;% max()\n    res &lt;- res / 1000\n  }\n  res &lt;- as.numeric(res)\n  return(res)\n}\n\nAdd cell max length, distance south-north, and distance east-west.\n\ntic()\n\nadd_cell_lengths &lt;- function(x) {\n  res &lt;- x\n  list &lt;- res %&gt;%\n    select(cell_label)\n  list &lt;- terra::split(list, list$cell_label)\n\n  res$cell_max_length &lt;- lapply(list, function(.x) fdistances(.x, type = \"max\")) %&gt;%\n    do.call(rbind, .) %&gt;%\n    as.numeric()\n\n  res$cell_ns_length &lt;- lapply(list, function(.x) fdistances(.x, type = \"ns\")) %&gt;%\n    do.call(rbind, .) %&gt;%\n    as.numeric()\n\n  res$cell_ew_length &lt;- lapply(list, function(.x) fdistances(.x, type = \"ew\")) %&gt;%\n    do.call(rbind, .) %&gt;%\n    as.numeric()\n\n  res &lt;- st_transform(res, st_crs(x))\n  return(res)\n}\n\n# Create a cluster\ncl &lt;- makeCluster(getOption(\"cl.cores\", detectCores() - 1))\n\n# Load necessary packages on each worker\nclusterEvalQ(cl, {\n  library(dplyr)\n  library(terra)\n  library(sf)\n})\n\n# Export the function to the cluster\nclusterExport(cl, varlist = \"fdistances\")\n\n# Use parSapply with the cluster\nfinal_grids &lt;- parSapply(cl, final_grids, add_cell_lengths, simplify = FALSE, USE.NAMES = TRUE)\n\n# Stop the cluster\nstopCluster(cl)\n\ntoc()\n\n\nplet(vect(final_grids[[2]]))\n\nExport results.\n\ngrid %&gt;%\n  st_drop_geometry() %&gt;%\n  select(matches(\"^cell|^X\")) %&gt;%\n  write_csv(., \"data/Birds_Alberta/Checked_data/grids_correspondence_table.csv\")\n\nfile.remove(\"data/Birds_Alberta/Checked_data/final_grid.gpkg\")\n\nfor (x in 1:length(final_grids)) {\n  st_write(final_grids[[x]], layer = paste0(\"grid_\", x), dsn = \"data/Birds_Alberta/Checked_data/final_grid.gpkg\")\n}",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Birds of Alberta</span>"
    ]
  },
  {
    "objectID": "Alberta.html#data-processing",
    "href": "Alberta.html#data-processing",
    "title": "5  Birds of Alberta",
    "section": "5.7 Data processing",
    "text": "5.7 Data processing\n\nfiles &lt;- c(\"/tmp/Original_data/Birds_Atlas_Alberta_1_Data.txt\", \"/tmp/Original_data/Birds_Atlas_Alberta_2_Data.txt\")\n\ncolumns &lt;- c(\"ScientificName\", \"DecimalLongitude\", \"DecimalLatitude\", \"YearCollected\", \"MonthCollected\", \"DayCollected\", \"SamplingEventIdentifier\", \"CollectorNumber\")\n\ndata &lt;- lapply(files, function(x) {\n  read_delim(x) %&gt;%\n    select(any_of(columns)) %&gt;%\n    unique()\n}) %&gt;%\n  do.call(rbind, .) %&gt;%\n  mutate(index = paste0(DecimalLongitude, \"_\", DecimalLatitude)) %&gt;%\n  rename(verbatim_name = ScientificName) %&gt;%\n  mutate(CollectorNumber = max(CollectorNumber) + 1)\n\nindex &lt;- select(data, index, DecimalLongitude, DecimalLatitude) %&gt;%\n  unique() %&gt;%\n  st_as_sf(., coords = c(\"DecimalLongitude\", \"DecimalLatitude\"), crs = 4326)\n\nindex &lt;- select(grid, cellID) %&gt;%\n  st_join(., index) %&gt;%\n  st_drop_geometry()\n\ndata &lt;- left_join(data, index, by = \"index\") %&gt;%\n  select(-index, -DecimalLongitude, -DecimalLatitude) %&gt;%\n  unique() %&gt;%\n  mutate(\n    start_year = case_when(\n      YearCollected &gt;= 1987 & YearCollected &lt;= 1991 ~ 1987,\n      YearCollected &gt;= 2000 & YearCollected &lt;= 2005 ~ 2000\n    ),\n    end_year = case_when(\n      YearCollected &gt;= 1987 & YearCollected &lt;= 1991 ~ 1991,\n      YearCollected &gt;= 2000 & YearCollected &lt;= 2005 ~ 2005\n    )\n  )\n\nocc &lt;- select(data, cellID, verbatim_name, start_year, end_year) %&gt;% unique()\n\nwrite_csv(occ, \"data/Birds_Alberta/Checked_data/occFin.csv\")\n\neff &lt;- select(data, -verbatim_name) %&gt;%\n  group_by(across(-CollectorNumber)) %&gt;%\n  summarise(effort = n_distinct(CollectorNumber)) %&gt;%\n  ungroup() %&gt;%\n  group_by(cellID, start_year, end_year) %&gt;%\n  summarise(effort = sum(effort)) %&gt;%\n  ungroup()\n\nwrite_csv(eff, \"data/Birds_Alberta/Checked_data/effFin.csv\")\n\nsamp_cells &lt;- select(occ, cellID, start_year) %&gt;%\n  rbind(., select(eff, cellID, start_year)) %&gt;%\n  unique() %&gt;%\n  mutate(\n    start_year = dense_rank(start_year),\n    value = 1\n  ) %&gt;%\n  pivot_wider(\n    names_from = start_year,\n    values_from = value,\n    values_fill = 0\n  ) %&gt;%\n  mutate(repeated = rowSums(select(., matches(\"^\\\\d\")))) %&gt;%\n  select(cellID, repeated)\n\nwrite_csv(samp_cells, \"data/Birds_Alberta/Checked_data/samp_cells.csv\")",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Birds of Alberta</span>"
    ]
  },
  {
    "objectID": "Alberta.html#adding-records-to-the-database",
    "href": "Alberta.html#adding-records-to-the-database",
    "title": "5  Birds of Alberta",
    "section": "5.8 Adding records to the database",
    "text": "5.8 Adding records to the database\n\n5.8.1 Data\nImport the processed data and grid.\n\ndata &lt;- read_csv(\"data/Birds_Alberta/Checked_data/occFin.csv\") %&gt;%\n  mutate(\n    verbatimIdentificationID = dense_rank(verbatim_name),\n    samplingPeriodID = dense_rank(start_year)\n  ) %&gt;%\n  rename() %&gt;%\n  filter(!is.na(cellID))\n\nsp_names &lt;- data %&gt;%\n  select(verbatimIdentificationID, verbatim_name) %&gt;%\n  unique()\n\ncorrs &lt;- read_csv(\"data/Birds_Alberta/Checked_data/grids_correspondence_table.csv\") %&gt;%\n  mutate(across(matches(\"^X\\\\d\"), dense_rank)) %&gt;%\n  select(cellID, matches(\"^X\\\\d\"))\n\neff &lt;- read_csv(\"data/Birds_Alberta/Checked_data/effFin.csv\") %&gt;%\n  mutate(samplingPeriodID = dense_rank(start_year))\n\nscaling_table &lt;- corrs %&gt;%\n  pivot_longer(-cellID, names_to = \"scalingID\", values_to = \"siteID\") %&gt;%\n  mutate(scalingID = str_remove_all(scalingID, \"^X\") %&gt;%\n    as.numeric()) %&gt;%\n  ungroup()\n\nsamp_cells &lt;- read_csv(\"data/Birds_Alberta/Checked_data/samp_cells.csv\") %&gt;%\n  left_join(., corrs, by = \"cellID\") %&gt;%\n  pivot_longer(-c(cellID, repeated), names_to = \"cell_grouping\", values_to = \"cell_label\") %&gt;%\n  mutate(cell_grouping = str_remove_all(cell_grouping, \"^X\") %&gt;%\n    as.numeric()) %&gt;%\n  na.omit() %&gt;%\n  group_by(cell_grouping, cell_label) %&gt;%\n  summarise(repeated = max(repeated)) %&gt;%\n  ungroup()\n\ngrid &lt;- st_layers(\"data/Birds_Alberta/Checked_data/final_grid.gpkg\")$name %&gt;%\n  mclapply(., function(x) {\n    st_read(\"data/Birds_Alberta/Checked_data/final_grid.gpkg\",\n      layer = x, quiet = T\n    )\n  }, mc.cores = 10) %&gt;%\n  do.call(rbind, .) %&gt;%\n  ungroup() %&gt;%\n  st_make_valid() %&gt;%\n  mutate(coords = st_centroid(geom)) %&gt;%\n  mutate(\n    cell_lat = st_coordinates(coords)[, 2],\n    cell_long = st_coordinates(coords)[, 1]\n  )\n\n\ngrid_table &lt;- st_drop_geometry(grid) %&gt;%\n  left_join(., samp_cells)\n\n\n5.8.1.1 Basic double check\n\n# Check that all cellID in data are also in the corrs cellID\nif (length(setdiff(unique(data$cellID), unique(corrs$cellID))) == 0) {\n  print(\"OK\")\n} else {\n  print(\"FAIL\")\n}\n# Check that number of rows in grid and corrs are the same\nnrow(filter(grid, cell_grouping == 1)) == nrow(corrs)\n\n# Check that years and sampling periods are the same in data and eff\nnrow(setdiff(\n  unique(select(data, start_year, samplingPeriodID)),\n  unique(select(eff, start_year, samplingPeriodID))\n))\n\n# Check uniqueness of scaling_table\nnrow(unique(scaling_table)) == nrow(scaling_table)\n\n# Check that all cellID in data are also in the grid (corrs)\nnrow(setdiff(\n  unique(data$cellID),\n  unique(corrs$cellID)\n))\n\n# Check that all cellID in eff are also in the grid (corrs)\nnrow(setdiff(\n  unique(eff$cellID),\n  unique(corrs$cellID)\n))\n\n# RESULTS SHOULD BE: OK, TRUE, 0, TRUE, NULL, NULL\n\n\n\n5.8.1.2 Atlas variables\n\ndatasetID &lt;- 7\neffortID &lt;- 1\nlicenseID &lt;- 1\nshareable &lt;- \"YES\"\nverbatimFootprintSRS &lt;- \"epsg:4326\"\n\nAll cells match between the different dataset files.\n\nfinal_data &lt;- inner_join(data, corrs, by = \"cellID\")\n\n\n\n\n5.8.2 Database connection\nSys.setenv(PGPASSWORD = 'mypassword')\n\nif (exists(\"con\")) {\n  dbDisconnect(con)\n}\n\ncon &lt;- dbConnect(Postgres(),\n  dbname = \"MOBI_atlases_testing\",\n  host = \"localhost\",\n  port = 5432,\n  user = \"atlasadmin\",\n  password = Sys.getenv(\"PGPASSWORD\")\n)\n\nknitr::opts_chunk$set(connection = con)\n\n\n\n5.8.3 List tables in database\n\ndbListTables(con) %&gt;%\n  purrr::keep(., ~ grepl(\"^CB|^MOBI\", .)) %&gt;%\n  kable(col.names = \"Tables\")\n\n\n\n5.8.4 Write code books\n\n5.8.4.1 CB_license\n\ntable &lt;- \"CB_license\" ## Table of interest\n\nCheck table colnames\n\ntbl(con, table) %&gt;%\n  as.data.frame() %&gt;%\n  colnames() %&gt;%\n  paste(., ' = \"\"', collapse = \",\\n\") %&gt;%\n  cat()\n\nCreate data table\n\ndata_table &lt;- data.frame(\n  licenseID = licenseID,\n  license = \"Open\",\n  licenseDescription = \"Publicly available on a data portal\",\n  licenseURL = \"none\"\n)\n\nWrite into the database\n\ntry({\n  copy_to(con, data_table, table, append = T)\n})\nrm(data_table)\n\nCheck the table\n\ntbl(con, table) %&gt;% kable(align = \"c\")\n\n\n\n5.8.4.2 CB_sampling_effort\n\ntable &lt;- \"CB_sampling_effort\" ## Table of interest\n\nCheck table colnames\n\ntbl(con, table) %&gt;%\n  as.data.frame() %&gt;%\n  colnames() %&gt;%\n  paste(., ' = \"\"', collapse = \",\\n\") %&gt;%\n  cat()\n\nCreate data table\n\ndata_table &lt;- data.frame(\n  samplingEffortID = effortID,\n  samplingEffortProtocol = \"Visits per gridcell\",\n  samplingEffortUnit = \"Visits\"\n)\n\nWrite into the database\n\ntry({\n  copy_to(con, data_table, table, append = T)\n})\nrm(data_table)\n\nCheck table.\n\ntbl(con, table) %&gt;% kable(align = \"c\")\n\n\n\n5.8.4.3 CB_model\n\ntable &lt;- \"CB_model\" ## Table of interest\n\nCheck table colnames\n\ntbl(con, table) %&gt;%\n  as.data.frame() %&gt;%\n  colnames() %&gt;%\n  paste(., ' = \"\"', collapse = \",\\n\") %&gt;%\n  cat()\n\nCreate data table\n\ndata_table &lt;- data.frame(\n  occurrenceModelID = \"\",\n  modelName = \"\",\n  predictorVariables = \"\",\n  bibliographicCitation = \"\"\n)\n\nWrite into the database\n\ntry({\n  copy_to(con, data_table, table, append = T)\n})\nrm(data_table)\n\nCheck table\n\ntbl(con, table) %&gt;% kable(align = \"c\")\n\n\n\n5.8.4.4 CB_taxonomy\n\ntable &lt;- \"CB_taxonomy\" ## Table of interest\n\nCheck table colnames\n\ntbl(con, table) %&gt;%\n  as.data.frame() %&gt;%\n  colnames() %&gt;%\n  paste(., ' = \"\"', collapse = \",\\n\") %&gt;%\n  cat()\n\nCreate data table\n\ndata_table &lt;- data.frame(\n  scientificNameID = \"\",\n  scientificName = \"\",\n  scientificNameAuthorship = \"\",\n  kingdom = \"\",\n  phylum = \"\",\n  class = \"\",\n  family = \"\",\n  order = \"\",\n  genus = \"\",\n  specificEpitet = \"\",\n  infraspecificEpitet = \"\",\n  taxonRank = \"\"\n)\n\nWrite into the database\n\ntry({\n  copy_to(con, data_table, table, append = T)\n})\nrm(data_table)\n\n\n\n5.8.4.5 CB_verbatim_name_equivalence\n\ntable &lt;- \"CB_verbatim_name_equivalence\" ## Table of interest\n\nCheck table colnames\n\ntbl(con, table) %&gt;%\n  as.data.frame() %&gt;%\n  colnames() %&gt;%\n  paste(., ' = \"\"', collapse = \",\\n\") %&gt;%\n  cat()\n\nCreate data table\n\ndata_table &lt;- data.frame(\n  verbatimIdentificationID = sp_names$verbatimIdentificationID,\n  verbatimIdentification = sp_names$verbatim_name,\n  datasetID = datasetID,\n  identificationReferences = \"\",\n  scientificNameID = NA\n)\n\nWrite into the database\n\ntry({\n  # Remove records where datasetID is the current dataset\n  dbExecute(con, paste0('DELETE FROM \"', table, '\" WHERE \"datasetID\" = ', datasetID))\n\n  # Copy data to the database\n  copy_to(con, data_table, table, append = TRUE)\n})\n\n# Remove the data_table from the environment\nrm(data_table)\n\nCheck table.\n\ntbl(con, sql(paste0('SELECT * FROM \"', table, '\" WHERE \"datasetID\" = ', datasetID))) %&gt;%\n  head() %&gt;%\n  kable(align = \"c\")\n\n\n\n\n5.8.5 Write dataset tables\n\n5.8.5.1 Dataset\n\ntable &lt;- \"MOBI_dataset\" ## Table of interest\n\nCheck table colnames\n\ntbl(con, table) %&gt;%\n  as.data.frame() %&gt;%\n  colnames() %&gt;%\n  paste(., ' = \"\"', collapse = \",\\n\") %&gt;%\n  cat()\n\nCreate data table\n\ndata_table &lt;- data.frame(\n  datasetID = datasetID,\n  datasetName = \"Alberta Breeding Bird Atlas\",\n  datasetPublisher = \"The Federation of Alberta Naturalists\",\n  datasetPublisherContact = \"info@fanweb.ca/info@naturealberta.ca\",\n  licenseID = licenseID,\n  rightsHolder = \"The Federation of Alberta Naturalists\",\n  bibliographicCitation = \"BBA1 data: Nature Alberta. 2018. Alberta Breeding Bird Atlas (1987-1992). Data accessed from NatureCounts, a node of the Avian Knowledge Network, Birds Canada. Available: https://www.naturecounts.ca/. Accessed: 24/01/24. | BBA2 data: Nature Alberta. 2018. Alberta Breeding Bird Atlas (2000-2005). Data accessed from NatureCounts, a node of the Avian Knowledge Network, Birds Canada. Available: https://www.naturecounts.ca/. Accessed: 24/01/24.\",\n  citationIdentifier = \"\",\n  provider = \"The Federation of Alberta Naturalists\",\n  shareable = \"NO\",\n  coauthorshipRequired = \"NO\",\n  coauthors = \"\",\n  coauthorshipSuggested = \"Carmen Soria - carmendianasoria@gmail.com; Kateřina Tschernosterová - tschernosterova@fzp.czu.cz; Gabriel Ortega - g.ortega.solis@gmail.com\",\n  isSamplingEffortReported = \"YES\",\n  isOccurrenceProbabilityAvailable = \"NO\"\n)\n\nWrite into the database\n\ntry({\n  dbExecute(con, paste0('DELETE FROM \"', table, '\" WHERE \"datasetID\" = ', datasetID))\n  copy_to(con, data_table, table, append = T)\n})\nrm(data_table)\n\nCheck table.\n\ntbl(con, sql(paste0('SELECT * FROM \"', table, '\" WHERE \"datasetID\" = ', datasetID))) %&gt;% kable(align = \"c\")\n\n\n\n5.8.5.2 Site\n\ntable &lt;- \"MOBI_site\" ## Table of interest\n\nCreate partition\n\nCREATE TABLE \"MOBI_site_7\" PARTITION OF \"MOBI_site\"\nFOR VALUES IN (7);\n\nCheck table colnames\n\ntbl(con, table) %&gt;%\n  as.data.frame() %&gt;%\n  colnames() %&gt;%\n  paste(., ' = \"\"', collapse = \",\\n\") %&gt;%\n  cat()\n\nCreate data table\n\ndata_table &lt;- data.frame(\n  siteID = grid_table$cell_label,\n  scalingID = grid_table$cell_grouping,\n  datasetID = datasetID,\n  area = grid_table$area,\n  croppedArea = grid_table$area_cropped,\n  areaUnit = \"km2\",\n  maxLength = grid_table$cell_max_length,\n  northSouthLength = grid_table$cell_ns_length,\n  eastWestLength = grid_table$cell_ew_length,\n  lengthUnit = \"km\",\n  centroidDecimalLongitude = grid_table$cell_long,\n  centroidDecimalLatitude = grid_table$cell_lat,\n  samplingRepetitions = grid_table$repeated\n)\n\nWrite into the database\n\ntry({\n  # Remove records where datasetID is the current dataset\n  dbExecute(con, paste0('DELETE FROM \"', table, '\" WHERE \"datasetID\" = ', datasetID))\n\n  # Copy data to the database\n  copy_to(con, data_table, table, append = TRUE)\n})\n\n# Remove the data_table from the environment\nrm(data_table)\n\nCheck table.\n\ntbl(\n  con,\n  sql(paste0('SELECT * FROM \"', table, '\" WHERE \"datasetID\" = ', datasetID))\n) %&gt;%\n  head(n = 20) %&gt;%\n  kable(align = \"c\")\n\n\n\n5.8.5.3 Geometry\n\ntable &lt;- \"MOBI_geometry\" ## Table of interest\n\nCreate partition\n\nCREATE TABLE \"MOBI_geometry_7\" PARTITION OF \"MOBI_geometry\"\nFOR VALUES IN (7);\n\nCheck table colnames\n\ntbl(con, table) %&gt;%\n  as.data.frame() %&gt;%\n  colnames() %&gt;%\n  paste(., ' = \"\"', collapse = \",\\n\") %&gt;%\n  cat()\n\nCreate data table\n\ndata_table &lt;- grid %&gt;%\n  ungroup() %&gt;%\n  rename(\n    siteID = cell_label,\n    scalingID = cell_grouping,\n    geometry = geom\n  ) %&gt;%\n  mutate(\n    siteID = as.integer(siteID),\n    scalingID = as.integer(scalingID),\n    datasetID = as.integer(datasetID),\n    footprintSRS = \"epsg:4326\",\n    verbatimFootprintSRS = verbatimFootprintSRS\n  ) %&gt;%\n  select(\n    ., siteID, scalingID, datasetID,\n    footprintSRS, verbatimFootprintSRS, geometry\n  )\n\ndata_table$geometry &lt;- st_cast(data_table$geometry, \"MULTIPOLYGON\")\n\nWrite into the database\n\ntry({\n  # Remove records where datasetID is the current dataset\n  dbExecute(con, paste0('DELETE FROM \"', table, '\" WHERE \"datasetID\" = ', datasetID))\n\n  # Write records\n  st_write(obj = data_table, dsn = con, layer = table, append = T)\n  # Remove the data_table from the environment\n  rm(data_table)\n})\n\nCheck table.\n\ntbl(con, sql(paste0('SELECT * FROM \"', table, '\" WHERE \"datasetID\" = ', datasetID))) %&gt;%\n  head() %&gt;%\n  kable(align = \"c\")\n\n\n\n\n5.8.6 Write helper tables\n\n5.8.6.1 Scaling table\nThis intermediate table enables the joins of records data to the different resolutions of sites.\n\ntable &lt;- \"MOBI_scaling_table\" ## Table of interest\n\nCreate partition\n\nCREATE TABLE \"MOBI_scaling_table_7\" PARTITION OF \"MOBI_scaling_table\"\nFOR VALUES IN (7);\n\nCheck table colnames.\n\ntbl(con, table) %&gt;%\n  as.data.frame() %&gt;%\n  colnames() %&gt;%\n  paste(., ' = \"\"', collapse = \",\\n\") %&gt;%\n  cat()\n\n\ndata_table &lt;- data.frame(\n  siteID = scaling_table$siteID,\n  scalingID = scaling_table$scalingID,\n  datasetID = datasetID,\n  verbatimSiteID = scaling_table$cellID\n)\n\nWrite into database.\n\ntry({\n  # Remove records where datasetID is the current dataset\n  dbExecute(con, paste0('DELETE FROM \"', table, '\" WHERE \"datasetID\" = ', datasetID))\n\n  # Copy data to the database\n  copy_to(con, data_table, table, append = TRUE)\n})\n\n# Remove the data_table from the environment\nrm(data_table)\n\nCheck table.\n\ntbl(con, sql(paste0('SELECT * FROM \"', table, '\" WHERE \"datasetID\" = ', datasetID))) %&gt;%\n  head() %&gt;%\n  kable(align = \"c\")\n\n\n\n\n5.8.7 Write records tables\n\n5.8.7.1 Event\n\ntable &lt;- \"MOBI_event\" ## Table of interest\n\nCreate partition\n\nCREATE TABLE \"MOBI_event_7\" PARTITION OF \"MOBI_event\"\nFOR VALUES IN (7);\n\nCheck table colnames\n\ntbl(con, table) %&gt;%\n  as.data.frame() %&gt;%\n  colnames() %&gt;%\n  paste(., ' = \"\"', collapse = \",\\n\") %&gt;%\n  cat()\n\nCreate data table\n\ndata_table &lt;- data.frame(\n  verbatimSiteID = eff$cellID,\n  datasetID = datasetID,\n  samplingPeriodID = eff$samplingPeriodID,\n  startYear = eff$start_year,\n  endYear = eff$end_year,\n  samplingEffortID = effortID,\n  samplingEffortValue = eff$effort\n)\n\nif (nrow(unique(data_table)) != nrow(eff)) {\n  stop(\"Stopping execution due to row number mismatch\")\n} else {\n  print(\"OK\")\n}\n\ndata_table &lt;- filter(data_table, !is.na(verbatimSiteID))\n\nWrite into the database\n\ntry({\n  # Remove records where datasetID is the current dataset\n  dbExecute(con, paste0('DELETE FROM \"', table, '\" WHERE \"datasetID\" = ', datasetID))\n\n  # Copy data to the database\n  copy_to(con, data_table, table, append = TRUE)\n})\n\n# Remove the data_table from the environment\nrm(data_table)\n\nCheck table.\n\ntbl(con, sql(paste0('SELECT * FROM \"', table, '\" WHERE \"datasetID\" = ', datasetID))) %&gt;%\n  head() %&gt;%\n  kable(align = \"c\")\n\n\n\n5.8.7.2 Presence\n\ntable &lt;- \"MOBI_presence\" ## Table of interest\n\nCreate partition\n\nCREATE TABLE \"MOBI_presence_7\" PARTITION OF \"MOBI_presence\"\nFOR VALUES IN (7);\n\nCheck table colnames\n\ntbl(con, table) %&gt;%\n  as.data.frame() %&gt;%\n  colnames() %&gt;%\n  paste(., ' = \"\"', collapse = \",\\n\") %&gt;%\n  cat()\n\nCreate data table\n\ndata_table &lt;- data.frame(\n  verbatimIdentificationID = final_data$verbatimIdentificationID,\n  verbatimSiteID = final_data$cellID,\n  datasetID = datasetID,\n  samplingPeriodID = final_data$samplingPeriodID,\n  recordFilter = NA\n)\n\nWrite into the database\n\ntry({\n  # Remove records where datasetID is the current dataset\n  dbExecute(con, paste0('DELETE FROM \"', table, '\" WHERE \"datasetID\" = ', datasetID))\n\n  # Copy data to the database\n  copy_to(con, data_table, table, append = TRUE)\n})\n\n# Remove the data_table from the environment\nrm(data_table)\n\nCheck table.\n\ntbl(con, sql(paste0('SELECT * FROM \"', table, '\" WHERE \"datasetID\" = ', datasetID))) %&gt;%\n  head() %&gt;%\n  kable(align = \"c\")\n\n\n\n5.8.7.3 Probability\n\ntable &lt;- \"MOBI_probability\" ## Table of interest\n\nCreate partition\n\nCREATE TABLE \"MOBI_probability_7\" PARTITION OF \"MOBI_probability\"\nFOR VALUES IN (7);\n\nCheck table colnames\n\ntbl(con, table) %&gt;%\n  as.data.frame() %&gt;%\n  colnames() %&gt;%\n  paste(., ' = \"\"', collapse = \",\\n\") %&gt;%\n  cat()\n\nCreate data table\n\ndata_table &lt;- data.frame(\n  verbatimIdentificationID = \"\",\n  verbatimSiteID = \"\",\n  datasetID = \"\",\n  samplingPeriodID = \"\",\n  probability = \"\"\n)\n\nWrite into the database\n\ntry({\n  # Remove records where datasetID is the current dataset\n  dbExecute(con, paste0('DELETE FROM \"', table, '\" WHERE \"datasetID\" = ', datasetID))\n\n  # Copy data to the database\n  copy_to(con, data_table, table, append = TRUE)\n})\n\n# Remove the data_table from the environment\nrm(data_table)\n\nCheck table.\n\ntbl(con, sql(paste0('SELECT * FROM \"', table, '\" WHERE \"datasetID\" = ', datasetID))) %&gt;%\n  head() %&gt;%\n  kable(align = \"c\")",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Birds of Alberta</span>"
    ]
  },
  {
    "objectID": "Alberta.html#finish-session",
    "href": "Alberta.html#finish-session",
    "title": "5  Birds of Alberta",
    "section": "5.9 Finish session",
    "text": "5.9 Finish session\n\nsessionInfo()\n\n\n5.9.1 Clean up workspace\n\ndbDisconnect(con)\nrm(list = ls())\ngc()\n.rs.restartR()",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Birds of Alberta</span>"
    ]
  },
  {
    "objectID": "Ontario.html",
    "href": "Ontario.html",
    "title": "6  Birds of Ontario",
    "section": "",
    "text": "6.1 MOBI team roles",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Birds of Ontario</span>"
    ]
  },
  {
    "objectID": "Ontario.html#mobi-team-roles",
    "href": "Ontario.html#mobi-team-roles",
    "title": "6  Birds of Ontario",
    "section": "",
    "text": "Responsibilities\nName\nDate (MM/YY)\n\n\n\n\nData acquisition\n\n08/23\n\n\nMetadata preparation\nKateřina Tschernosterová\n07/24\n\n\nData standardization\nKateřina Tschernosterová\n12/24\n\n\nData processing\nGabriel Ortega",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Birds of Ontario</span>"
    ]
  },
  {
    "objectID": "Ontario.html#data-providers-metadata-and-co-authorships",
    "href": "Ontario.html#data-providers-metadata-and-co-authorships",
    "title": "6  Birds of Ontario",
    "section": "6.2 Data providers metadata and co-authorships",
    "text": "6.2 Data providers metadata and co-authorships\nAlways check the updated information here\nThe original documents folder including books, publications or email exchanges are here",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Birds of Ontario</span>"
    ]
  },
  {
    "objectID": "Ontario.html#data-description",
    "href": "Ontario.html#data-description",
    "title": "6  Birds of Ontario",
    "section": "6.3 Data description",
    "text": "6.3 Data description\n\nObservation data by grid cell, by species and by observation card (year, sampling event and data collector)\nPresence is reported, no data on abundance or absence\nOriginal data detail - Scientific species name, Common species name, Survey area identifier, Decimal latitude and longitude of survey area, Year (month, day) collected, Collector number, Sampling event identifier, Effort in hours (BBA2 only, not for all events), Breeding bird atlas code\nData collection for the Ontario Breeding Bird Atlas 3 began on January 1, 2021 for next 5 years\nData was downloaded trough NatureCounts website - https://naturecounts.ca/nc/default/explore.jsp#download and https://naturecounts.ca/nc/onatlas/main.jsp\n\nDownloaded dataset with BBA1 data - Ontario Breeding Bird Atlas (1981-1985): raw breeding evidence [Ontario Breeding Bird Atlas]\nDownloaded dataset with BBA2 data - Ontario Breeding Bird Atlas (2001-2005): raw breeding evidence [Ontario Breeding Bird Atlas]\nAnother available datasets that were not used - Ontario Breeding Bird Atlas (2001-2005): point count data [Ontario Breeding Bird Atlas] and Ontario Bird Feeder Survey [Project FeederWatch]\nAvailable datasets with BBA3 data (currently in progress) – Ontario Breeding Bird Atlas (2021-2025): checklist data [Ontario Breeding Bird Atlas] and Ontario Breeding Bird Atlas (2021-2025): point count data [Ontario Breeding Bird Atlas]\n\nData request together with available datasets and data release conditions are here - https://www.birdsontario.org/jsp/downloaddata.jsp?lang=EN\nBBA1 website (with online BBA1 book) - https://www.birdsontario.org/jsp/firstatlas.jsp\nBBA1 online book - https://www.birdsontario.org/jsp/atlasbook.jsp?pg=toc\nBBA2 website - https://www.birdsontario.org/atlas-2/\nBBA3 website - https://www.birdsontario.org/about/\n\n\n6.3.1 Sampling methodology\n\nData was collected by volunteer atlasers according to Guide for participants (Birds_Atlas_Ontario_2_Guide)\nThe goal is to provide adequate coverage of every 10-km square in southern Ontario, and of every 100-km block in northern Ontario. Data will be recorded on a 10-km basis wherever possible in the north. (BBA_2_Guide, p.3 and 6)\nThe minimum effort required is 20 hours per square over the 5 years, that should be spent by surveing a square. At the same time, it is important to ensure that all habitats within the square are properly covered. (BBA_2_Guide, p.12)\nAtlassers are also given the option of collecting information on the relative abundance of species in their square by doing Point Counts survey. (BBA_2_Guide, p.3)\nIf Point Counts is done (optional), the time doing them can be included in total hours of coverage (BBA_2_Guide, p.12)\n\n\n\n6.3.2 Sampling effort\n\nSampling duration in hours is reported for both atlases, but for some sampling events the value is missing. Therefore the value of sampling event duration can be used, but only with restrictions.\nTherefore sampling effort for both atlases is also reported as number of sampling events per grid square\nSampling effort was not equally distributed among all squares during the surveys, the number of sampling events is different for each sampling square\nIn the northern part of Ontarion, where travel is more restricted, the maps are probably less complete reflection of the species actually breeding there\nDuring the first atlas, squares in southern Ontario averaged over 50 hours of coverage (BBA_2_Guide, p.12)\nThe source of following data and tables is BBA1 online book, chapter Final coverage - Atlasser Effort, p.21\n\nThe number of atlassers per year\n\n\n\n\n1981\n1982\n1983\n1984\n1985\n\n\n\n\nSouthern Ontario\n379\n643\n706\n629\n722\n\n\nAll of Ontario\n433\n730\n828\n720\n811\n\n\n\nTotal number of atlassers contributing data = 1352\nThe number of field work hours per year\n\n\n\n\n\n\n\n\n\n\n\n\n1981\n1982\n1983\n1984\n1985\n\n\nSouthern Ontario\n11,400\n20,702\n21,894\n23,003\n28,523\n\n\nAll of Ontario\n13,436\n23,446\n26,543\n27,827\n32,627\n\n\nHours per atlasser\n31.0\n32.1\n32.1\n38.6\n40.2\n\n\n\nTotal number of field work hours in Southern Ontario = 105,522\nTotal number of field work hours in Ontario = 123,879\nAverage of field work hours per atlasser over the 5 years period = 92",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Birds of Ontario</span>"
    ]
  },
  {
    "objectID": "Ontario.html#input-data",
    "href": "Ontario.html#input-data",
    "title": "6  Birds of Ontario",
    "section": "6.4 Input data",
    "text": "6.4 Input data\nXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX check with Gabriel\nhelper data folder\nprocedure_Bird_atlas_Ontario_files\nBirds_Atlas_Ontario.Rproj\nfinal_data.rds\nprocedure_Bird_atlas_Ontario.html\nprocedure_Bird_atlas_Ontario.qmd\ntest.R\n\n6.4.1 Original data folder\n\nBirds_Atlas_Ontario_1-2_Column names.txt - text file with list of columns used for raw data\nBirds_Atlas_Ontario_1_Data_raw breeding evidence.txt - raw data for BBA1\nBirds_Atlas_Ontario_2_Data_raw breeding evidence.txt - raw data for BBA2\n\n\n\n6.4.2 Grid folder\nXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX check with Gabriel\n\nnaturecounts_grid.R\nnaturecounts_ontario shapefile\nobba_squares shapefile\n\n\n\n6.4.3 Docs folder\n\nBirds_Atlas_Ontario_1-2_Data policy.html - policy on use and publication of data\nBirds_Atlas_Ontario_2_Guide.pdf - pdf guide for participants (April 2001)\nBirds_Atlas_Ontario_3_Guide.pdf - pdf instructions for general atlassing (April 2021), the third atlas was not published yet, so we did not include information from the guide\n\n\n\n6.4.4 Checked data folder\n\nBird_Atlas_Ontario_1_OriginalData.csv - raw data for BBA1 in csv format\nBird_Atlas_Ontario_1_1981-1985_eff_data.xlsx - standardized effort data for BBA1\nBird_Atlas_Ontario_1_1981-1985_occ_data.xlsx - standardized occurrence data for BBA1\nBird_Atlas_Ontario_2_OriginalData.csv - raw data for BBA2 in csv format\nBird_Atlas_Ontario_2_1998-2005_eff_data.xlsx - standardized effort data for BBA2\nBird_Atlas_Ontario_2_1998-2005_occ_data.xlsx - standardized occurrence data for BBA2\nBird_Atlas_Ontario_CheckedData_working.xlsx - effort and occurrence data standardization, working file\nXX_Birds_of_Ontario_data description.qmd - Quarto document, contains metadata, processing notes and codes, part of BEAST database documentation",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Birds of Ontario</span>"
    ]
  },
  {
    "objectID": "Ontario.html#data-standardization-and-processing-comments",
    "href": "Ontario.html#data-standardization-and-processing-comments",
    "title": "6  Birds of Ontario",
    "section": "6.5 Data standardization and processing comments",
    "text": "6.5 Data standardization and processing comments\n\n!!! IMPORTANT !!! the sampling effort in hours is not complete",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Birds of Ontario</span>"
    ]
  },
  {
    "objectID": "Ontario.html#libraries",
    "href": "Ontario.html#libraries",
    "title": "6  Birds of Ontario",
    "section": "6.6 Libraries",
    "text": "6.6 Libraries\n\npacman::p_load(\n  sf, terra, tidyverse, tidyterra, knitr,\n  tictoc, RPostgres, DBI, dbplyr, parallel,\n  geodata\n)",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Birds of Ontario</span>"
    ]
  },
  {
    "objectID": "Ontario.html#grid-processing",
    "href": "Ontario.html#grid-processing",
    "title": "6  Birds of Ontario",
    "section": "6.7 Grid processing",
    "text": "6.7 Grid processing\n\nrm -rf /tmp/Original_data\nunzip data/Birds_Ontario/Original_data.zip -d /tmp/\n\n\nglimpse(vect(\"/tmp/Original_data/naturecounts_ontario.shp\"))\n\n\ngrid &lt;- st_read(\"/tmp/Original_data/naturecounts_ontario.shp\") %&gt;%\n  st_make_valid() %&gt;%\n  select(utm_sqr, utm_zon, utm_stn, utm_nrt) %&gt;%\n  rename(cellID = utm_sqr)\n\ngrid &lt;- st_read(\"/tmp/Original_data/obba_squares.shp\") %&gt;%\n  select(SQUARE_ID) %&gt;%\n  rename(cellID = SQUARE_ID) %&gt;%\n  st_transform(., 4326) %&gt;%\n  st_centroid() %&gt;%\n  st_join(select(grid, -cellID), .) %&gt;%\n  unique() %&gt;%\n  filter(!is.na(cellID))\n\nlength(grid$cellID) == length(unique(grid$cellID))\n\n\ngrid_grouping &lt;- function(grid, col1, col2, num) {\n  grid &lt;- st_drop_geometry(grid)\n  mincol1 &lt;- min(grid[[col1]])\n  maxcol1 &lt;- max(grid[[col1]])\n  mincol2 &lt;- min(grid[[col2]])\n  maxcol2 &lt;- max(grid[[col2]])\n  breaksA &lt;- seq(mincol1, maxcol1, num)\n  breaksB &lt;- seq(mincol2, maxcol2, num)\n  if (length(breaksA) &gt; 1) {\n    A &lt;- cut(grid[[col1]], breaks = breaksA, right = F)\n  } else {\n    A &lt;- 1\n  }\n  if (length(breaksB) &gt; 1) {\n    B &lt;- cut(grid[[col2]], breaks = breaksB, right = F)\n  } else {\n    B &lt;- 1\n  }\n  res &lt;- paste0(grid$utm_zon, \"_\", A, B)\n  return(res)\n}\n\nCreate labels for rescaling\n\nfor (dist in c(2, 4, 8, 16, 32, 64, 128, 256, 512)) {\n  num &lt;- 10000 * dist\n  grid[[paste0(dist)]] &lt;- grid_grouping(grid, col1 = \"utm_stn\", col2 = \"utm_nrt\", num = num)\n}\n\ngrid$`1` &lt;- dense_rank(grid$cellID)\n\ngrid &lt;- grid %&gt;% mutate(across(matches(\"^\\\\d\"), dense_rank))\n\nst_write(grid, \"/tmp/ontario.gpkg\", delete_dsn = T)\n\nThe grid was manually checked in QGIS to merge small cells with their neighbors. Small or even linear cells occur in borders of UTM zones in the original grid. We also reassigned some cells to groupings in every scale so that they end up mostly aligned and closer to the expected standard sizes per scale. The resulting grid was saved as modified_grid.gpkg.\n\nqgis /tmp/ontario.gpkg\n\nWe have different percentages of overlap between cells and real country borders. Therefore, we should have a way to correct the areas.\n\ngrid &lt;- st_read(\"data/Birds_Ontario/Checked_data/modified_grid.gpkg\") %&gt;%\n  mutate(across(matches(\"^X\\\\d\"), dense_rank))\n\nadm_boundary &lt;- gadm(\"CAN\", path = \"/tmp/\", resolution = 1) %&gt;%\n  select(ISO_1) %&gt;%\n  filter(ISO_1 == \"CA-ON\")\n\nint &lt;- terra::intersect(select(vect(grid), cellID), adm_boundary)\n\nint &lt;- group_by(int, cellID) %&gt;% summarise()\n\nint$cropped_area &lt;- expanse(int, unit = \"km\")\n\ngrid &lt;- as.data.frame(int) %&gt;%\n  left_join(grid, ., by = \"cellID\")\n\nCalculate cell area with and without correction by landmasses or country borders.\n\ngrid$cell_area &lt;- expanse(vect(grid), unit = \"km\")\ngrid$cell_area_proportion &lt;- grid$cropped_area / grid$cell_area %&gt;% round(., digits = 2)\n\nRemove cells without ID (if any)\n\nnoID &lt;- filter(grid, is.na(cellID))\ngrid &lt;- filter(grid, !is.na(cellID))\n\n\n# Pivot cells to a longer format for easier use in models.\nfinal_grids &lt;- grid %&gt;%\n  pivot_longer(matches(\"^X\\\\d\"),\n    names_to = \"cell_grouping\",\n    values_to = \"cell_label\"\n  ) %&gt;%\n  mutate(cell_grouping = str_remove_all(cell_grouping, \"X\") %&gt;%\n    as.numeric())\n\nfinal_grids &lt;- split(final_grids, final_grids$cell_grouping)\n\nAggregate cells and summarize the area.\n\nfinal_grids &lt;- final_grids %&gt;%\n  lapply(., function(x) {\n    res &lt;- x %&gt;%\n      group_by(cell_grouping, cell_label) %&gt;%\n      summarise(\n        area = sum(cell_area, na.rm = T),\n        area_cropped = sum(cropped_area, na.rm = T)\n      ) %&gt;%\n      ungroup()\n  })\n\nFunctions to add additional variables of cell shapes\n\n# Function to get cell shape attributes\n\nfdistances &lt;- function(x, type = NULL) {\n  x &lt;- vect(x)\n  pol &lt;- as.data.frame(crds(as.points(ext(project(x, \"epsg:4326\")))))\n  if (type == \"ew\") {\n    sw &lt;- pol %&gt;%\n      summarise(x = min(x), y = min(y)) %&gt;%\n      as.matrix()\n    se &lt;- pol %&gt;%\n      summarise(x = max(x), y = min(y)) %&gt;%\n      as.matrix()\n    res &lt;- distance(sw, se, lonlat = T)[[1]] / 1000\n  }\n  if (type == \"ns\") {\n    sw &lt;- pol %&gt;%\n      summarise(x = min(x), y = min(y)) %&gt;%\n      as.matrix()\n    nw &lt;- pol %&gt;%\n      summarise(x = min(x), y = max(y)) %&gt;%\n      as.matrix()\n    res &lt;- distance(sw, nw, lonlat = T)[[1]] / 1000\n  }\n  if (type == \"max\") {\n    res &lt;- distance(pol, lonlat = T) %&gt;% max()\n    res &lt;- res / 1000\n  }\n  res &lt;- as.numeric(res)\n  return(res)\n}\n\nAdd cell max length, distance south-north, and distance east-west.\n\ntic()\n\nadd_cell_lengths &lt;- function(x) {\n  res &lt;- x\n  list &lt;- res %&gt;%\n    select(cell_label)\n  list &lt;- terra::split(list, list$cell_label)\n\n  res$cell_max_length &lt;- lapply(list, function(.x) fdistances(.x, type = \"max\")) %&gt;%\n    do.call(rbind, .) %&gt;%\n    as.numeric()\n\n  res$cell_ns_length &lt;- lapply(list, function(.x) fdistances(.x, type = \"ns\")) %&gt;%\n    do.call(rbind, .) %&gt;%\n    as.numeric()\n\n  res$cell_ew_length &lt;- lapply(list, function(.x) fdistances(.x, type = \"ew\")) %&gt;%\n    do.call(rbind, .) %&gt;%\n    as.numeric()\n\n  res &lt;- st_transform(res, st_crs(x))\n  return(res)\n}\n\n# Create a cluster\ncl &lt;- makeCluster(getOption(\"cl.cores\", detectCores() - 5))\n\n# Load necessary packages on each worker\nclusterEvalQ(cl, {\n  library(dplyr)\n  library(terra)\n  library(sf)\n})\n\n# Export the function to the cluster\nclusterExport(cl, varlist = \"fdistances\")\n\n# Use parSapply with the cluster\nfinal_grids &lt;- parSapply(cl, final_grids, add_cell_lengths, simplify = FALSE, USE.NAMES = TRUE)\n\n# Stop the cluster\nstopCluster(cl)\n\ntoc()\n\n\nplet(vect(final_grids[[5]]))\n\nExport results.\n\ngrid %&gt;%\n  st_drop_geometry() %&gt;%\n  select(matches(\"^cell|^X\")) %&gt;%\n  write_csv(., \"data/Birds_Ontario/Checked_data/grids_correspondence_table.csv\")\n\nfile.remove(\"data/Birds_Ontario/Checked_data/final_grid.gpkg\")\n\nfor (x in 1:length(final_grids)) {\n  st_write(final_grids[[x]], layer = paste0(\"grid_\", x), dsn = \"data/Birds_Ontario/Checked_data/final_grid.gpkg\")\n}",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Birds of Ontario</span>"
    ]
  },
  {
    "objectID": "Ontario.html#data-processing",
    "href": "Ontario.html#data-processing",
    "title": "6  Birds of Ontario",
    "section": "6.8 Data processing",
    "text": "6.8 Data processing\n\n# files &lt;- c(\"/tmp/Original_data/Birds_Atlas_Ontario_1_Data_raw\\ breeding\\ evidence.txt\",\"/tmp/Original_data/Birds_Atlas_Ontario_2_Data_raw\\ breeding\\ evidence.txt\")\n#\n# columns &lt;- c(\"ScientificName\", \"Locality\", \"SamplingEventIdentifier\", \"RouteIdentifier\", \"EffortMeasurement1\", \"EffortUnits1\", \"DecimalLongitude\", \"DecimalLatitude\", \"YearCollected\", \"MonthCollected\", \"DayCollected\",\"SamplingEventIdentifier\", \"CollectorNumber\")\n#\n# data &lt;- lapply(files, function(x) read_delim(x) %&gt;%\n#                  select(any_of(columns)) %&gt;%\n#                  unique()) %&gt;% do.call(rbind,.) #%&gt;%\n#   mutate(index = paste0(DecimalLongitude,\"_\",DecimalLatitude)) %&gt;%\n#   rename(verbatim_name = ScientificName) %&gt;%\n#   mutate(CollectorNumber = max(CollectorNumber)+1)\n#\n# View(summarise(data, across(everything(), ~sum(is.na(.)))))\n#\n# index &lt;- select(data, index, DecimalLongitude, DecimalLatitude) %&gt;%\n#   unique() %&gt;%\n#   st_as_sf(., coords = c(\"DecimalLongitude\",\"DecimalLatitude\"), crs = 4326)\n#\n# index &lt;- select(grid, cellID) %&gt;%\n#   st_join(., index) %&gt;%\n#   st_drop_geometry()\n#\n# data &lt;- left_join(data, index, by = \"index\") %&gt;% select(-index,-DecimalLongitude, -DecimalLatitude) %&gt;% unique() %&gt;%\n#   mutate(start_year = case_when(\n#     YearCollected &gt;= 1987 & YearCollected &lt;= 1991 ~ 1987,\n#     YearCollected &gt;= 2000 & YearCollected &lt;= 2005 ~ 2000\n#   ),\n#   end_year = case_when(\n#     YearCollected &gt;= 1987 & YearCollected &lt;= 1991 ~ 1991,\n#     YearCollected &gt;= 2000 & YearCollected &lt;= 2005 ~ 2005\n#   ))\n#\n# occ &lt;- select(data, cellID, verbatim_name, start_year, end_year) %&gt;% unique()\n#\n# write_csv(occ, \"data/Birds_Ontario/Checked_data/occFin.csv\")\n#\n# eff &lt;- select(data, -verbatim_name) %&gt;%\n#   group_by(across(-CollectorNumber)) %&gt;%\n#   summarise(effort = n_distinct(CollectorNumber)) %&gt;%\n#   ungroup() %&gt;%\n#   group_by(cellID, start_year, end_year) %&gt;%\n#   summarise(effort = sum(effort)) %&gt;%\n#   ungroup()\n#\n# write_csv(eff, \"data/Birds_Ontario/Checked_data/effFin.csv\")\n#\n# samp_cells &lt;- select(occ, cellID, start_year) %&gt;%\n#   rbind(., select(eff, cellID, start_year)) %&gt;%\n#   unique() %&gt;%\n#   mutate(start_year = dense_rank(start_year),\n#          value = 1) %&gt;%\n#   pivot_wider(names_from = start_year,\n#               values_from = value,\n#               values_fill = 0) %&gt;%\n#   mutate(repeated = rowSums(select(., matches(\"^\\\\d\")))) %&gt;%\n#   select(cellID, repeated)\n#\n# write_csv(samp_cells, \"data/Birds_Ontario/Checked_data/samp_cells.csv\")",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Birds of Ontario</span>"
    ]
  },
  {
    "objectID": "Ontario.html#adding-records-to-the-database",
    "href": "Ontario.html#adding-records-to-the-database",
    "title": "6  Birds of Ontario",
    "section": "6.9 Adding records to the database",
    "text": "6.9 Adding records to the database\n\n6.9.1 Data\nImport the processed data and grid.\n\nocc_files &lt;- list.files(\"data/Birds_Ontario/Checked_data/\", pattern = \"_occ_data.xlsx\", full.names = T)\n\ndata &lt;- lapply(occ_files, function(x) {\n  readxl::read_xlsx(x) %&gt;%\n    filter(!is.na(cellID))\n}) %&gt;%\n  do.call(rbind, .) %&gt;%\n  mutate(\n    verbatimIdentificationID = dense_rank(verbatim_name),\n    samplingPeriodID = dense_rank(start_year)\n  )\n\nsp_names &lt;- data %&gt;%\n  select(verbatimIdentificationID, verbatim_name) %&gt;%\n  unique()\n\ncorrs &lt;- read_csv(\"data/Birds_Ontario/Checked_data/grids_correspondence_table.csv\") %&gt;%\n  mutate(across(matches(\"^X\\\\d\"), dense_rank)) %&gt;%\n  select(cellID, matches(\"^X\\\\d\"))\n\neff_files &lt;- list.files(\"data/Birds_Ontario/Checked_data/\", pattern = \"_eff_data.xlsx\", full.names = T)\n\neff &lt;- lapply(eff_files, function(x) {\n  readxl::read_xlsx(x) %&gt;%\n    filter(!is.na(cellID))\n}) %&gt;% do.call(rbind, .)\n\neff &lt;- select(data, cellID, start_year, end_year) %&gt;%\n  unique() %&gt;%\n  setdiff(., select(eff, cellID, start_year, end_year)) %&gt;%\n  mutate(effort_1 = NA, effort_1_unit = NA_character_) %&gt;%\n  bind_rows(eff, .) %&gt;%\n  mutate(samplingPeriodID = dense_rank(start_year))\n\nscaling_table &lt;- corrs %&gt;%\n  pivot_longer(-cellID, names_to = \"scalingID\", values_to = \"siteID\") %&gt;%\n  mutate(scalingID = str_remove_all(scalingID, \"^X\") %&gt;%\n    as.numeric()) %&gt;%\n  ungroup()\n\nsamp_cells &lt;- select(data, cellID, start_year) %&gt;%\n  rbind(., select(eff, cellID, start_year)) %&gt;%\n  unique() %&gt;%\n  group_by(cellID) %&gt;%\n  mutate(repeated = n_distinct((start_year))) %&gt;%\n  ungroup() %&gt;%\n  select(!start_year) %&gt;%\n  unique() %&gt;%\n  left_join(., corrs, by = \"cellID\") %&gt;%\n  pivot_longer(-c(cellID, repeated), names_to = \"cell_grouping\", values_to = \"cell_label\") %&gt;%\n  mutate(cell_grouping = str_remove_all(cell_grouping, \"^X\") %&gt;%\n    as.numeric()) %&gt;%\n  na.omit() %&gt;%\n  group_by(cell_grouping, cell_label) %&gt;%\n  summarise(repeated = max(repeated)) %&gt;%\n  ungroup()\n\ngrid &lt;- st_layers(\"data/Birds_Ontario/Checked_data/final_grid.gpkg\")$name %&gt;%\n  mclapply(., function(x) {\n    st_read(\"data/Birds_Ontario/Checked_data/final_grid.gpkg\",\n      layer = x, quiet = T\n    )\n  }, mc.cores = 10) %&gt;%\n  do.call(rbind, .) %&gt;%\n  ungroup() %&gt;%\n  st_make_valid() %&gt;%\n  mutate(coords = st_centroid(geom)) %&gt;%\n  mutate(\n    cell_lat = st_coordinates(coords)[, 2],\n    cell_long = st_coordinates(coords)[, 1]\n  )\n\n\ngrid_table &lt;- st_drop_geometry(grid) %&gt;%\n  left_join(., samp_cells)\n\n\n6.9.1.1 Basic double check\n\n# Check that all cellID in data are also in the corrs cellID\nif (length(setdiff(unique(data$cellID), unique(corrs$cellID))) == 0) {\n  print(\"OK\")\n} else {\n  print(\"FAIL\")\n}\n# Check that number of rows in grid and corrs are the same\nnrow(filter(grid, cell_grouping == 1)) == nrow(corrs)\n\n# Check that years and sampling periods are the same in data and eff\nnrow(setdiff(\n  unique(select(data, start_year, samplingPeriodID)),\n  unique(select(eff, start_year, samplingPeriodID))\n))\n\n# Check uniqueness of scaling_table\nnrow(unique(scaling_table)) == nrow(scaling_table)\n\n# Check that all cellID in data are also in the grid (corrs)\nlength(setdiff(\n  unique(data$cellID),\n  unique(corrs$cellID)\n))\n\n# Check that all cellID in eff are also in the grid (corrs)\nlength(setdiff(\n  unique(eff$cellID),\n  unique(corrs$cellID)\n))\n\n# RESULTS SHOULD BE: OK, TRUE, 0, TRUE, NULL, NULL\n\n\n\n6.9.1.2 Atlas variables\n\ndatasetID &lt;- 18\neffortID &lt;- 1\nlicenseID &lt;- 1\nshareable &lt;- \"YES\"\nverbatimFootprintSRS &lt;- \"epsg:4326\"\n\nAll cells match between the different dataset files.\n\nfinal_data &lt;- inner_join(data, corrs, by = \"cellID\")\nno_join_data &lt;- anti_join(data, corrs, by = \"cellID\")\n\n\n\n\n6.9.2 Database connection\n\nif (exists(\"con\")) {\n  dbDisconnect(con)\n}\n\ncon &lt;- dbConnect(Postgres(),\n  dbname = \"MOBI_atlases_testing\",\n  host = \"localhost\",\n  port = 5432,\n  user = \"atlasadmin\",\n  password = askpass::askpass()\n)\n\nknitr::opts_chunk$set(connection = con)\n\n\n\n6.9.3 List tables in database\n\ndbListTables(con) %&gt;%\n  purrr::keep(., ~ grepl(\"^CB|^MOBI\", .)) %&gt;%\n  kable(col.names = \"Tables\")\n\n\n\n6.9.4 Write code books\n\n6.9.4.1 CB_license\n\ntable &lt;- \"CB_license\" ## Table of interest\n\nCheck table colnames\n\ntbl(con, table) %&gt;%\n  as.data.frame() %&gt;%\n  colnames() %&gt;%\n  paste(., ' = \"\"', collapse = \",\\n\") %&gt;%\n  cat()\n\nCreate data table\n\ndata_table &lt;- data.frame(\n  licenseID = licenseID,\n  license = \"Open\",\n  licenseDescription = \"Publicly available on a data portal\",\n  licenseURL = \"none\"\n)\n\nWrite into the database\n\ntry({\n  copy_to(con, data_table, table, append = T)\n})\nrm(data_table)\n\nCheck the table\n\ntbl(con, table) %&gt;% kable(align = \"c\")\n\n\n\n6.9.4.2 CB_sampling_effort\n\ntable &lt;- \"CB_sampling_effort\" ## Table of interest\n\nCheck table colnames\n\ntbl(con, table) %&gt;%\n  as.data.frame() %&gt;%\n  colnames() %&gt;%\n  paste(., ' = \"\"', collapse = \",\\n\") %&gt;%\n  cat()\n\nCreate data table\n\ndata_table &lt;- data.frame(\n  samplingEffortID = 2,\n  samplingEffortProtocol = \"Sampling events per gridcell\",\n  samplingEffortUnit = \"Sampling events\"\n)\n\nWrite into the database\n\ntry({\n  copy_to(con, data_table, table, append = T)\n})\nrm(data_table)\n\nCheck table.\n\ntbl(con, table) %&gt;% kable(align = \"c\")\n\n\n\n6.9.4.3 CB_model\n\ntable &lt;- \"CB_model\" ## Table of interest\n\nCheck table colnames\n\ntbl(con, table) %&gt;%\n  as.data.frame() %&gt;%\n  colnames() %&gt;%\n  paste(., ' = \"\"', collapse = \",\\n\") %&gt;%\n  cat()\n\nCreate data table\n\ndata_table &lt;- data.frame(\n  occurrenceModelID = \"\",\n  modelName = \"\",\n  predictorVariables = \"\",\n  bibliographicCitation = \"\"\n)\n\nWrite into the database\n\ntry({\n  copy_to(con, data_table, table, append = T)\n})\nrm(data_table)\n\nCheck table\n\ntbl(con, table) %&gt;% kable(align = \"c\")\n\n\n\n6.9.4.4 CB_taxonomy\n\ntable &lt;- \"CB_taxonomy\" ## Table of interest\n\nCheck table colnames\n\ntbl(con, table) %&gt;%\n  as.data.frame() %&gt;%\n  colnames() %&gt;%\n  paste(., ' = \"\"', collapse = \",\\n\") %&gt;%\n  cat()\n\nCreate data table\n\ndata_table &lt;- data.frame(\n  scientificNameID = \"\",\n  scientificName = \"\",\n  scientificNameAuthorship = \"\",\n  kingdom = \"\",\n  phylum = \"\",\n  class = \"\",\n  family = \"\",\n  order = \"\",\n  genus = \"\",\n  specificEpitet = \"\",\n  infraspecificEpitet = \"\",\n  taxonRank = \"\"\n)\n\nWrite into the database\n\ntry({\n  copy_to(con, data_table, table, append = T)\n})\nrm(data_table)\n\n\n\n6.9.4.5 CB_verbatim_name_equivalence\n\ntable &lt;- \"CB_verbatim_name_equivalence\" ## Table of interest\n\nCheck table colnames\n\ntbl(con, table) %&gt;%\n  as.data.frame() %&gt;%\n  colnames() %&gt;%\n  paste(., ' = \"\"', collapse = \",\\n\") %&gt;%\n  cat()\n\nCreate data table\n\ndata_table &lt;- data.frame(\n  verbatimIdentificationID = sp_names$verbatimIdentificationID,\n  verbatimIdentification = sp_names$verbatim_name,\n  datasetID = datasetID,\n  identificationReferences = \"\",\n  scientificNameID = NA\n)\n\nWrite into the database\n\ntry({\n  # Remove records where datasetID is the current dataset\n  dbExecute(con, paste0('DELETE FROM \"', table, '\" WHERE \"datasetID\" = ', datasetID))\n\n  # Copy data to the database\n  copy_to(con, data_table, table, append = TRUE)\n})\n\n# Remove the data_table from the environment\nrm(data_table)\n\nCheck table.\n\ntbl(con, sql(paste0('SELECT * FROM \"', table, '\" WHERE \"datasetID\" = ', datasetID))) %&gt;%\n  head() %&gt;%\n  kable(align = \"c\")\n\n\n\n\n6.9.5 Write dataset tables\n\n6.9.5.1 Dataset\n\ntable &lt;- \"MOBI_dataset\" ## Table of interest\n\nCheck table colnames\n\ntbl(con, table) %&gt;%\n  as.data.frame() %&gt;%\n  colnames() %&gt;%\n  paste(., ' = \"\"', collapse = \",\\n\") %&gt;%\n  cat()\n\nCreate data table\n\ndata_table &lt;- data.frame(\n  datasetID = datasetID,\n  datasetName = \"Ontario Breeding Bird Atlas\",\n  datasetPublisher = \"The Federation of Ontario Naturalists\",\n  datasetPublisherContact = \"info@fanweb.ca/info@natureOntario.ca\",\n  licenseID = licenseID,\n  rightsHolder = \"The Federation of Ontario Naturalists\",\n  bibliographicCitation = \"BBA1 data: Nature Ontario. 2018. Ontario Breeding Bird Atlas (1987-1992). Data accessed from NatureCounts, a node of the Avian Knowledge Network, Birds Canada. Available: https://www.naturecounts.ca/. Accessed: 24/01/24. | BBA2 data: Nature Ontario. 2018. Ontario Breeding Bird Atlas (2000-2005). Data accessed from NatureCounts, a node of the Avian Knowledge Network, Birds Canada. Available: https://www.naturecounts.ca/. Accessed: 24/01/24.\",\n  citationIdentifier = \"\",\n  provider = \"The Federation of Ontario Naturalists\",\n  shareable = \"NO\",\n  coauthorshipRequired = \"NO\",\n  coauthors = \"\",\n  coauthorshipSuggested = \"Carmen Soria - carmendianasoria@gmail.com; Kateřina Tschernosterová - tschernosterova@fzp.czu.cz; Friederike Wölke - wolke@fzp.czu.cz; Gabriel Ortega - g.ortega.solis@gmail.com\",\n  isSamplingEffortReported = \"YES\",\n  isOccurrenceProbabilityAvailable = \"NO\"\n)\n\nWrite into the database\n\ntry({\n  dbExecute(con, paste0('DELETE FROM \"', table, '\" WHERE \"datasetID\" = ', datasetID))\n  copy_to(con, data_table, table, append = T)\n})\nrm(data_table)\n\nCheck table.\n\ntbl(con, sql(paste0('SELECT * FROM \"', table, '\" WHERE \"datasetID\" = ', datasetID))) %&gt;% kable(align = \"c\")\n\n\n\n6.9.5.2 Site\n\ntable &lt;- \"MOBI_site\" ## Table of interest\n\nCreate partition\n\nCREATE TABLE \"MOBI_site_18\" PARTITION OF \"MOBI_site\"\nFOR VALUES IN (18);\n\nCheck table colnames\n\ntbl(con, table) %&gt;%\n  as.data.frame() %&gt;%\n  colnames() %&gt;%\n  paste(., ' = \"\"', collapse = \",\\n\") %&gt;%\n  cat()\n\nCreate data table\n\ndata_table &lt;- data.frame(\n  siteID = grid_table$cell_label,\n  scalingID = grid_table$cell_grouping,\n  datasetID = datasetID,\n  area = grid_table$area,\n  croppedArea = grid_table$area_cropped,\n  areaUnit = \"km2\",\n  maxLength = grid_table$cell_max_length,\n  northSouthLength = grid_table$cell_ns_length,\n  eastWestLength = grid_table$cell_ew_length,\n  lengthUnit = \"km\",\n  centroidDecimalLongitude = grid_table$cell_long,\n  centroidDecimalLatitude = grid_table$cell_lat,\n  samplingRepetitions = grid_table$repeated\n)\n\nWrite into the database\n\ntry({\n  # Remove records where datasetID is the current dataset\n  dbExecute(con, paste0('DELETE FROM \"', table, '\" WHERE \"datasetID\" = ', datasetID))\n\n  # Copy data to the database\n  copy_to(con, data_table, table, append = TRUE)\n})\n\n# Remove the data_table from the environment\nrm(data_table)\n\nCheck table.\n\ntbl(\n  con,\n  sql(paste0('SELECT * FROM \"', table, '\" WHERE \"datasetID\" = ', datasetID))\n) %&gt;%\n  head(n = 20) %&gt;%\n  kable(align = \"c\")\n\n\n\n6.9.5.3 Geometry\n\ntable &lt;- \"MOBI_geometry\" ## Table of interest\n\nCreate partition\n\nCREATE TABLE \"MOBI_geometry_18\" PARTITION OF \"MOBI_geometry\"\nFOR VALUES IN (18);\n\nCheck table colnames\n\ntbl(con, table) %&gt;%\n  as.data.frame() %&gt;%\n  colnames() %&gt;%\n  paste(., ' = \"\"', collapse = \",\\n\") %&gt;%\n  cat()\n\nCreate data table\n\ndata_table &lt;- grid %&gt;%\n  ungroup() %&gt;%\n  rename(\n    siteID = cell_label,\n    scalingID = cell_grouping,\n    geometry = geom\n  ) %&gt;%\n  mutate(\n    siteID = as.integer(siteID),\n    scalingID = as.integer(scalingID),\n    datasetID = as.integer(datasetID),\n    footprintSRS = \"epsg:4326\",\n    verbatimFootprintSRS = verbatimFootprintSRS\n  ) %&gt;%\n  select(\n    ., siteID, scalingID, datasetID,\n    footprintSRS, verbatimFootprintSRS, geometry\n  )\n\ndata_table$geometry &lt;- st_cast(data_table$geometry, \"MULTIPOLYGON\")\n\nWrite into the database\n\ntry({\n  # Remove records where datasetID is the current dataset\n  dbExecute(con, paste0('DELETE FROM \"', table, '\" WHERE \"datasetID\" = ', datasetID))\n\n  # Write records\n  st_write(obj = data_table, dsn = con, layer = table, append = T)\n  # Remove the data_table from the environment\n  rm(data_table)\n})\n\nCheck table.\n\ntbl(con, sql(paste0('SELECT * FROM \"', table, '\" WHERE \"datasetID\" = ', datasetID))) %&gt;%\n  head() %&gt;%\n  kable(align = \"c\")\n\n\n\n\n6.9.6 Write helper tables\n\n6.9.6.1 Scaling table\nThis intermediate table enables the joins of records data to the different resolutions of sites.\n\ntable &lt;- \"MOBI_scaling_table\" ## Table of interest\n\nCreate partition\n\nCREATE TABLE \"MOBI_scaling_table_18\" PARTITION OF \"MOBI_scaling_table\"\nFOR VALUES IN (18);\n\nCheck table colnames.\n\ntbl(con, table) %&gt;%\n  as.data.frame() %&gt;%\n  colnames() %&gt;%\n  paste(., ' = \"\"', collapse = \",\\n\") %&gt;%\n  cat()\n\n\ndata_table &lt;- data.frame(\n  siteID = scaling_table$siteID,\n  scalingID = scaling_table$scalingID,\n  datasetID = datasetID,\n  verbatimSiteID = scaling_table$cellID\n)\n\nWrite into database.\n\ntry({\n  # Remove records where datasetID is the current dataset\n  dbExecute(con, paste0('DELETE FROM \"', table, '\" WHERE \"datasetID\" = ', datasetID))\n\n  # Copy data to the database\n  copy_to(con, data_table, table, append = TRUE)\n})\n\n# Remove the data_table from the environment\nrm(data_table)\n\nCheck table.\n\ntbl(con, sql(paste0('SELECT * FROM \"', table, '\" WHERE \"datasetID\" = ', datasetID))) %&gt;%\n  head() %&gt;%\n  kable(align = \"c\")\n\n\n\n\n6.9.7 Write records tables\n\n6.9.7.1 Event\n\ntable &lt;- \"MOBI_event\" ## Table of interest\n\nCreate partition\n\nCREATE TABLE \"MOBI_event_18\" PARTITION OF \"MOBI_event\"\nFOR VALUES IN (18);\n\nCheck table colnames\n\ntbl(con, table) %&gt;%\n  as.data.frame() %&gt;%\n  colnames() %&gt;%\n  paste(., ' = \"\"', collapse = \",\\n\") %&gt;%\n  cat()\n\nCreate data table\n\ndata_table &lt;- data.frame(\n  verbatimSiteID = eff$cellID,\n  datasetID = datasetID,\n  samplingPeriodID = eff$samplingPeriodID,\n  startYear = eff$start_year,\n  endYear = eff$end_year,\n  samplingEffortID = 2,\n  samplingEffortValue = ifelse(eff$effort_1 == 0, NA,\n    eff$effort_1\n  ),\n  samplingEffort2ID = 4,\n  samplingEffort2Value = ifelse(eff$effort_2 == 0, NA,\n    eff$effort_2\n  )\n)\n\nif (nrow(unique(data_table)) != nrow(eff)) {\n  stop(\"Stopping execution due to row number mismatch\")\n} else {\n  print(\"OK\")\n}\n\ndata_table &lt;- filter(data_table, !is.na(verbatimSiteID))\n\nWrite into the database\n\ntry({\n  # Remove records where datasetID is the current dataset\n  dbExecute(con, paste0('DELETE FROM \"', table, '\" WHERE \"datasetID\" = ', datasetID))\n\n  # Copy data to the database\n  copy_to(con, data_table, table, append = TRUE)\n})\n\n# Remove the data_table from the environment\n# rm(data_table)\n\nCheck table.\n\ntbl(con, sql(paste0('SELECT * FROM \"', table, '\" WHERE \"datasetID\" = ', datasetID))) %&gt;%\n  head() %&gt;%\n  kable(align = \"c\")\n\n\n\n6.9.7.2 Presence\n\ntable &lt;- \"MOBI_presence\" ## Table of interest\n\nCreate partition\n\nCREATE TABLE \"MOBI_presence_18\" PARTITION OF \"MOBI_presence\"\nFOR VALUES IN (18);\n\nCheck table colnames\n\ntbl(con, table) %&gt;%\n  as.data.frame() %&gt;%\n  colnames() %&gt;%\n  paste(., ' = \"\"', collapse = \",\\n\") %&gt;%\n  cat()\n\nCreate data table\n\ndata_table &lt;- data.frame(\n  verbatimIdentificationID = final_data$verbatimIdentificationID,\n  verbatimSiteID = final_data$cellID,\n  datasetID = datasetID,\n  samplingPeriodID = final_data$samplingPeriodID,\n  recordFilter = NA\n)\n\nWrite into the database\n\ntry({\n  # Remove records where datasetID is the current dataset\n  dbExecute(con, paste0('DELETE FROM \"', table, '\" WHERE \"datasetID\" = ', datasetID))\n\n  # Copy data to the database\n  copy_to(con, data_table, table, append = TRUE)\n})\n\n# Remove the data_table from the environment\nrm(data_table)\n\nCheck table.\n\ntbl(con, sql(paste0('SELECT * FROM \"', table, '\" WHERE \"datasetID\" = ', datasetID))) %&gt;%\n  head() %&gt;%\n  kable(align = \"c\")\n\n\n\n6.9.7.3 Probability\n\ntable &lt;- \"MOBI_probability\" ## Table of interest\n\nCreate partition\n\nCREATE TABLE \"MOBI_probability_18\" PARTITION OF \"MOBI_probability\"\nFOR VALUES IN (18);\n\nCheck table colnames\n\ntbl(con, table) %&gt;%\n  as.data.frame() %&gt;%\n  colnames() %&gt;%\n  paste(., ' = \"\"', collapse = \",\\n\") %&gt;%\n  cat()\n\nCreate data table\n\ndata_table &lt;- data.frame(\n  verbatimIdentificationID = \"\",\n  verbatimSiteID = \"\",\n  datasetID = \"\",\n  samplingPeriodID = \"\",\n  probability = \"\"\n)\n\nWrite into the database\n\ntry({\n  # Remove records where datasetID is the current dataset\n  dbExecute(con, paste0('DELETE FROM \"', table, '\" WHERE \"datasetID\" = ', datasetID))\n\n  # Copy data to the database\n  copy_to(con, data_table, table, append = TRUE)\n})\n\n# Remove the data_table from the environment\nrm(data_table)\n\nCheck table.\n\ntbl(con, sql(paste0('SELECT * FROM \"', table, '\" WHERE \"datasetID\" = ', datasetID))) %&gt;%\n  head() %&gt;%\n  kable(align = \"c\")",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Birds of Ontario</span>"
    ]
  },
  {
    "objectID": "Ontario.html#finish-session",
    "href": "Ontario.html#finish-session",
    "title": "6  Birds of Ontario",
    "section": "6.10 Finish session",
    "text": "6.10 Finish session\n\nsessionInfo()\n\n\n6.10.1 Clean up workspace\n\ndbDisconnect(con)\nrm(list = ls())\ngc()\n.rs.restartR()",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Birds of Ontario</span>"
    ]
  },
  {
    "objectID": "Quebec.html",
    "href": "Quebec.html",
    "title": "7  Birds of Quebec",
    "section": "",
    "text": "7.1 MOBI team roles",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Birds of Quebec</span>"
    ]
  },
  {
    "objectID": "Quebec.html#mobi-team-roles",
    "href": "Quebec.html#mobi-team-roles",
    "title": "7  Birds of Quebec",
    "section": "",
    "text": "Responsibilities\nName\nDate (MM/YY)\n\n\n\n\nData acquisition\n\n09/23\n\n\nMetadata preparation\nKateřina Tschernosterová\n07/24\n\n\nData standardization\nKateřina Tschernosterová\n12/24\n\n\nData processing\nGabriel Ortega\n12/24",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Birds of Quebec</span>"
    ]
  },
  {
    "objectID": "Quebec.html#data-providers-metadata-and-co-authorships",
    "href": "Quebec.html#data-providers-metadata-and-co-authorships",
    "title": "7  Birds of Quebec",
    "section": "7.2 Data providers metadata and co-authorships",
    "text": "7.2 Data providers metadata and co-authorships\nAlways check the updated information here\nThe original documents folder including books, publications or email exchanges are here",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Birds of Quebec</span>"
    ]
  },
  {
    "objectID": "Quebec.html#data-description",
    "href": "Quebec.html#data-description",
    "title": "7  Birds of Quebec",
    "section": "7.3 Data description",
    "text": "7.3 Data description\n\nObservation data by grid cell, by species and by observation card (year, sampling event and data collector)\nPresence is reported, no data on abundance or absence\nOriginal data detail - Scientific species name, Common species name, Survey area identifier, Decimal latitude and longitude of survey area, Year (month, day) collected, Collector number, Sampling event identifier, Effort in hours (BBA2 only, not for all events), Breeding bird atlas code\nAtlas data use agreement - https://www.atlas-oiseaux.qc.ca/convention_data_v3_sept_2018_en.jsp\nData was downloaded trough NatureCounts website - https://naturecounts.ca/nc/qcatlas/main.jsp\n\nDownloaded dataset with BBA1 data - Québec Breeding Bird Atlas (1984-1989): raw breeding evidence [Québec Breeding Bird Atlas]\nDownloaded dataset with BBA2 data - Québec Breeding Bird Atlas (2010-2014): raw breeding evidence [Québec Breeding Bird Atlas]\nAnother available datasets that were not used - Québec Breeding Bird Atlas (2010-2014): daily observations [Québec Breeding Bird Atlas]\n\nQuébec Breeding Bird Atlas (2010-2014): point count data [Québec Breeding Bird Atlas]\nQuébec Breeding Bird Atlas (2010-2014): rare species and colonial data [Québec Breeding Bird Atlas]\nQuébec Breeding Bird Atlas (northern project): daily observations [Québec Breeding Bird Atlas]\nQuébec Breeding Bird Atlas (northern project): raw breeding evidence [Québec Breeding Bird Atlas]\nQuébec Breeding Bird Atlas (northern project): point count data [Québec Breeding Bird Atlas]\n\n\n\n\n\nBBA1 - The Breeding Birds of Québec: Atlas of the Breeding Birds of Southern Québec\n\nFrench version was published 1995, English version was published 1996\nBBA1 website: https://www.atlas-oiseaux.qc.ca/1eratlas_en.jsp\nThe Atlas field campaign for the Quebec territory located north of latitude 50°30’ N has not been completed, no data for squares which are north of latitude 50°30’ N\n\nBBA2 - The Second Atlas of Breeding Birds of Southern Quebec\n\nBBA2 website: https://www.atlas-oiseaux.qc.ca/index_en.jsp\nBook was published in April 2019\nYou can view the book online using QuébecOiseaux’s miLibris reader: https://quebecoiseauxkiosk.milibris.com/atlas\nThe Atlas field campaign for the Quebec territory located north of latitude 50°30’ N has been completed, but there are no plans to publish the results in a book\nHowever, the data collected north of latitude 50°30’ N as part of the Atlas campaign are available through NatureCounts - you can consult these on distribution maps or even download them (Atlas of breeding birds of Quebec (northern region)).\n\n\n\n7.3.1 Sampling methodology\n\nData was collected in sampling squares by volunteer atlasers, sampling atlas squares are 10 km by 10 km (100 km2)\nBBA1 book and NatureCounts database contains data only for southern Quebec, northern Quebec data are not available\nBBA2 book contains data only for southern Quebec, but data for northern Quebec are available in NatureCounts database\n\n\n\n7.3.2 Sampling effort\n\nParticipants were encouraged to spend about 20 hours looking for breeding evidence in a square. It is estimated that it takes 16 to 20 hours of observation to find approximately 75% of the bird species in a square (BBA2 pdf, p.13)\nTABLE 3.1 (BBA2 pdf, p.21) – Statistics on atlassers participation in the fieldwork for BBA1 and BBA2 (note: effort in hours is simple sum of hours per event, but some events are missing this information - no data or hours = 0)\n\n\n\n\n\n\n\n\n\nFirst atlas (1984-1989)\nSecond atlas (2010-2014)\n\n\n\n\nNumber of participants\n932\n1,805\n\n\nObservation effort (hours)\n67,587\n97,625\n\n\nNumber of squares with records\n2,462\n4,033\n\n\nNumber of data forms filled out\n9,041\n31,679\n\n\nNumber of records\n202,521\n566,834\n\n\nNumber of point counts\nN/A\n34,502",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Birds of Quebec</span>"
    ]
  },
  {
    "objectID": "Quebec.html#input-data",
    "href": "Quebec.html#input-data",
    "title": "7  Birds of Quebec",
    "section": "7.4 Input data",
    "text": "7.4 Input data\n\n7.4.1 Original data folder\n\nBirds_Atlas_Quebec_1-2_Column names.txt - text file with the list of original data column names\nqcatlas1be_raw_naturecounts_data.txt - text file with data for BBA1 1984-1989\nqcatlas2be_raw_naturecounts_data.txt - text file with data for BBA1 2010-2017\n\n\n\n7.4.2 Grid folder\n\ngrid.kmz - grid map with 10x10 km survey squares grouped into 100 km by 100 km blocks - based on the Universal Transverse Mercator (UTM) grid; covers whole area of Quebec (southern and northern territory)\n\n\n\n7.4.3 Docs folder\n\nBirds_Atlas_Quebec_1-2_Data policy.html - NatureCounts policy on use and publication of atlas data (version May 2018)\nBirds_Atlas_Quebec_2_Guide.pdf - handbook with instructions for volunteer atlasers (April 2001)\nSecond Atlas of the Breeding Birds of Southern Quebec.pdf - Pdf version of atlas for Southern Quebec territories, atlas for North Quebec territories was not printed out.\n\n\n\n7.4.4 Checked data folder\n\nBirds_Atlas_Quebec_1_1984-1989_eff_data.xlsx - standardized effort data\nBirds_Atlas_Quebec_1_1984-1989_occ_data.xlsx - standardized occurrence data\nBirds_Atlas_Quebec_2_OriginalData.csv\nBirds_Atlas_Quebec_2_2010-2017_eff_data.xlsx - standardized effort data\nBirds_Atlas_Quebec_2_2010-2017_occ_data.xlsx - standardized occurrence data\nBirds_Atlas_Quebec_1_OriginalData.csv\nBirds_Atlas_Quebec_2_OriginalData.csv\nBirds_Atlas_Quebec_CheckedData_working.xlsx - effort and occurrence data standardization, working file\nXX_Birds_of_Quebec_data description.qmd - Quarto document, contains metadata, processing notes and codes, part of BEAST database documentation",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Birds of Quebec</span>"
    ]
  },
  {
    "objectID": "Quebec.html#data-standardization-and-processing-comments",
    "href": "Quebec.html#data-standardization-and-processing-comments",
    "title": "7  Birds of Quebec",
    "section": "7.5 Data standardization and processing comments",
    "text": "7.5 Data standardization and processing comments\n\nSampling effort reported in NatureCounts data is not complete - effort in hours is missing or is equal to 0, for some sampling events - therefore sum of hours does not make sense\nWe decided that sampling effort as number of events per sampling square is more reasonable - data was aggregated per event\nBBA1 data are covering only southern Quebec, BBA2 data are covering whole area of Quebec (as mentioned in methodology part)",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Birds of Quebec</span>"
    ]
  },
  {
    "objectID": "Quebec.html#libraries",
    "href": "Quebec.html#libraries",
    "title": "7  Birds of Quebec",
    "section": "7.6 Libraries",
    "text": "7.6 Libraries\n\npacman::p_load(\n  sf, terra, tidyverse, tidyterra, knitr,\n  tictoc, RPostgres, DBI, dbplyr, parallel,\n  geodata\n)",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Birds of Quebec</span>"
    ]
  },
  {
    "objectID": "Quebec.html#grid-processing",
    "href": "Quebec.html#grid-processing",
    "title": "7  Birds of Quebec",
    "section": "7.7 Grid processing",
    "text": "7.7 Grid processing\n\nrm -rf /tmp/Original_data\nunzip data/Birds_Quebec/Original_data.zip -d /tmp/\n\n\nglimpse(vect(\"/tmp/Original_data/grid.kmz\"))\n\n\n# Custom ceiling function\ncustom_ceiling &lt;- function(x) {\n  return(ceiling(x / 5000) * 5000)\n}\n\n# Function to import and modify the grid file on one pass\nread_grid &lt;- function(shpfile) {\n  grid &lt;- st_read(shpfile)\n  grid$row_ID &lt;- paste0(\"ID\", 1:nrow(grid))\n  grid$cellID &lt;- grid$Name\n  grid$utm_zon &lt;- str_extract(grid$Name, \"^\\\\d{2}\")\n  temp &lt;- lapply(unique(grid$utm_zon), function(x) {\n    res &lt;- filter(grid, utm_zon == x) %&gt;%\n      st_transform(., as.numeric(paste0(269, x))) %&gt;%\n      st_centroid() %&gt;%\n      mutate(\n        utm_stn = unlist(map(.$geometry, 1)),\n        utm_nrt = unlist(map(.$geometry, 2)) %&gt;% custom_ceiling(.)\n      ) %&gt;%\n      st_drop_geometry() %&gt;%\n      select(row_ID, utm_stn, utm_nrt)\n  }) %&gt;% do.call(rbind, .)\n\n  grid &lt;- left_join(grid, temp, by = \"row_ID\")\n  return(grid)\n}\n\n# Apply to data grid\ngrid &lt;- read_grid(\"/tmp/Original_data/grid.kmz\") %&gt;% select(row_ID, cellID, utm_stn, utm_nrt, utm_zon)\n\n\ngrid_grouping &lt;- function(grid, col1, col2, num) {\n  grid &lt;- st_drop_geometry(grid)\n  mincol1 &lt;- min(grid[[col1]])\n  maxcol1 &lt;- max(grid[[col1]])\n  mincol2 &lt;- min(grid[[col2]])\n  maxcol2 &lt;- max(grid[[col2]])\n  breaksA &lt;- seq(mincol1, maxcol1, num)\n  breaksB &lt;- seq(mincol2, maxcol2, num)\n  if (length(breaksA) &gt; 1) {\n    A &lt;- cut(grid[[col1]], breaks = breaksA, right = F)\n  } else {\n    A &lt;- 1\n  }\n  if (length(breaksB) &gt; 1) {\n    B &lt;- cut(grid[[col2]], breaks = breaksB, right = F)\n  } else {\n    B &lt;- 1\n  }\n  res &lt;- paste0(grid$utm_zon, \"_\", A, B)\n  return(res)\n}\n\nCreate labels for rescaling\n\nfor (dist in c(2, 4, 8, 16, 32, 64, 128)) {\n  num &lt;- 10000 * dist\n  grid[[paste0(dist)]] &lt;- grid_grouping(grid, col1 = \"utm_stn\", col2 = \"utm_nrt\", num = num)\n}\n\ngrid$`1` &lt;- dense_rank(grid$cellID)\ngrid$`256` &lt;- 1\n\ngrid &lt;- grid %&gt;% mutate(across(matches(\"^\\\\d\"), dense_rank))\n\nst_write(grid, \"/tmp/Quebec.gpkg\", delete_dsn = T)\n\nThe grid was manually checked in QGIS to merge small cells with their neighbors. Small or even linear cells occur in borders of UTM zones in the original grid. We also reassigned some cells to groupings in every scale so that they end up mostly aligned and closer to the expected standard sizes per scale. The resulting grid was saved as modified_grid.gpkg.\n\nqgis /tmp/Quebec.gpkg\n\nWe have different percentages of overlap between cells and real country borders. Therefore, we should have a way to correct the areas.\n\ngrid &lt;- st_read(\"data/Birds_Quebec/Checked_data/modified_grid.gpkg\") %&gt;%\n  mutate(across(matches(\"^X\\\\d\"), dense_rank))\n\nadm_boundary &lt;- gadm(\"CAN\", path = \"/tmp/\", resolution = 1) %&gt;%\n  select(HASC_1) %&gt;%\n  filter(HASC_1 == \"CA.QC\") %&gt;%\n  project(., \"epsg:4326\")\n\nint &lt;- terra::intersect(select(vect(grid), cellID), adm_boundary)\n\nint &lt;- group_by(int, cellID) %&gt;% summarise()\n\nint$cropped_area &lt;- expanse(int, unit = \"km\")\n\ngrid &lt;- as.data.frame(int) %&gt;%\n  left_join(grid, ., by = \"cellID\")\n\nCalculate cell area with and without correction by landmasses or country borders.\n\ngrid$cell_area &lt;- expanse(vect(grid), unit = \"km\")\ngrid$cell_area_proportion &lt;- grid$cropped_area / grid$cell_area %&gt;% round(., digits = 2)\n\nRemove cells without ID (if any)\n\nnoID &lt;- filter(grid, is.na(cellID))\ngrid &lt;- filter(grid, !is.na(cellID))\n\n\n# Pivot cells to a longer format for easier use in models.\nfinal_grids &lt;- grid %&gt;%\n  pivot_longer(matches(\"^X\\\\d\"),\n    names_to = \"cell_grouping\",\n    values_to = \"cell_label\"\n  ) %&gt;%\n  mutate(cell_grouping = str_remove_all(cell_grouping, \"X\") %&gt;%\n    as.numeric())\n\nfinal_grids &lt;- split(final_grids, final_grids$cell_grouping)\n\nAggregate cells and summarize the area.\n\nfinal_grids &lt;- final_grids %&gt;%\n  lapply(., function(x) {\n    res &lt;- x %&gt;%\n      group_by(cell_grouping, cell_label) %&gt;%\n      summarise(\n        area = sum(cell_area, na.rm = T),\n        area_cropped = sum(cropped_area, na.rm = T)\n      ) %&gt;%\n      ungroup()\n  })\n\nFunctions to add additional variables of cell shapes\n\n# Function to get cell shape attributes\n\nfdistances &lt;- function(x, type = NULL) {\n  x &lt;- vect(x)\n  pol &lt;- as.data.frame(crds(as.points(ext(project(x, \"epsg:4326\")))))\n  if (type == \"ew\") {\n    sw &lt;- pol %&gt;%\n      summarise(x = min(x), y = min(y)) %&gt;%\n      as.matrix()\n    se &lt;- pol %&gt;%\n      summarise(x = max(x), y = min(y)) %&gt;%\n      as.matrix()\n    res &lt;- distance(sw, se, lonlat = T)[[1]] / 1000\n  }\n  if (type == \"ns\") {\n    sw &lt;- pol %&gt;%\n      summarise(x = min(x), y = min(y)) %&gt;%\n      as.matrix()\n    nw &lt;- pol %&gt;%\n      summarise(x = min(x), y = max(y)) %&gt;%\n      as.matrix()\n    res &lt;- distance(sw, nw, lonlat = T)[[1]] / 1000\n  }\n  if (type == \"max\") {\n    res &lt;- distance(pol, lonlat = T) %&gt;% max()\n    res &lt;- res / 1000\n  }\n  res &lt;- as.numeric(res)\n  return(res)\n}\n\nAdd cell max length, distance south-north, and distance east-west.\n\ntic()\n\nadd_cell_lengths &lt;- function(x) {\n  res &lt;- x\n  list &lt;- res %&gt;%\n    select(cell_label)\n  list &lt;- terra::split(list, list$cell_label)\n\n  res$cell_max_length &lt;- lapply(list, function(.x) fdistances(.x, type = \"max\")) %&gt;%\n    do.call(rbind, .) %&gt;%\n    as.numeric()\n\n  res$cell_ns_length &lt;- lapply(list, function(.x) fdistances(.x, type = \"ns\")) %&gt;%\n    do.call(rbind, .) %&gt;%\n    as.numeric()\n\n  res$cell_ew_length &lt;- lapply(list, function(.x) fdistances(.x, type = \"ew\")) %&gt;%\n    do.call(rbind, .) %&gt;%\n    as.numeric()\n\n  res &lt;- st_transform(res, st_crs(x))\n  return(res)\n}\n\n# Create a cluster\ncl &lt;- makeCluster(getOption(\"cl.cores\", detectCores() - 5))\n\n# Load necessary packages on each worker\nclusterEvalQ(cl, {\n  library(dplyr)\n  library(terra)\n  library(sf)\n})\n\n# Export the function to the cluster\nclusterExport(cl, varlist = \"fdistances\")\n\n# Use parSapply with the cluster\nfinal_grids &lt;- parSapply(cl, final_grids, add_cell_lengths, simplify = FALSE, USE.NAMES = TRUE)\n\n# Stop the cluster\nstopCluster(cl)\n\ntoc()\n\n\nplet(vect(final_grids[[8]]))\n\nExport results.\n\ngrid %&gt;%\n  st_drop_geometry() %&gt;%\n  select(matches(\"^cell|^X\")) %&gt;%\n  write_csv(., \"data/Birds_Quebec/Checked_data/grids_correspondence_table.csv\")\n\nfile.remove(\"data/Birds_Quebec/Checked_data/final_grid.gpkg\")\n\nfor (x in 1:length(final_grids)) {\n  st_write(final_grids[[x]], layer = paste0(\"grid_\", x), dsn = \"data/Birds_Quebec/Checked_data/final_grid.gpkg\")\n}",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Birds of Quebec</span>"
    ]
  },
  {
    "objectID": "Quebec.html#data-processing",
    "href": "Quebec.html#data-processing",
    "title": "7  Birds of Quebec",
    "section": "7.8 Data processing",
    "text": "7.8 Data processing\n\n# files &lt;- c(\"/tmp/Original_data/Birds_Atlas_Quebec_1_Data_raw\\ breeding\\ evidence.txt\",\"/tmp/Original_data/Birds_Atlas_Quebec_2_Data_raw\\ breeding\\ evidence.txt\")\n#\n# columns &lt;- c(\"ScientificName\", \"Locality\", \"SamplingEventIdentifier\", \"RouteIdentifier\", \"EffortMeasurement1\", \"EffortUnits1\", \"DecimalLongitude\", \"DecimalLatitude\", \"YearCollected\", \"MonthCollected\", \"DayCollected\",\"SamplingEventIdentifier\", \"CollectorNumber\")\n#\n# data &lt;- lapply(files, function(x) read_delim(x) %&gt;%\n#                  select(any_of(columns)) %&gt;%\n#                  unique()) %&gt;% do.call(rbind,.) #%&gt;%\n#   mutate(index = paste0(DecimalLongitude,\"_\",DecimalLatitude)) %&gt;%\n#   rename(verbatim_name = ScientificName) %&gt;%\n#   mutate(CollectorNumber = max(CollectorNumber)+1)\n#\n# View(summarise(data, across(everything(), ~sum(is.na(.)))))\n#\n# index &lt;- select(data, index, DecimalLongitude, DecimalLatitude) %&gt;%\n#   unique() %&gt;%\n#   st_as_sf(., coords = c(\"DecimalLongitude\",\"DecimalLatitude\"), crs = 4326)\n#\n# index &lt;- select(grid, cellID) %&gt;%\n#   st_join(., index) %&gt;%\n#   st_drop_geometry()\n#\n# data &lt;- left_join(data, index, by = \"index\") %&gt;% select(-index,-DecimalLongitude, -DecimalLatitude) %&gt;% unique() %&gt;%\n#   mutate(start_year = case_when(\n#     YearCollected &gt;= 1987 & YearCollected &lt;= 1991 ~ 1987,\n#     YearCollected &gt;= 2000 & YearCollected &lt;= 2005 ~ 2000\n#   ),\n#   end_year = case_when(\n#     YearCollected &gt;= 1987 & YearCollected &lt;= 1991 ~ 1991,\n#     YearCollected &gt;= 2000 & YearCollected &lt;= 2005 ~ 2005\n#   ))\n#\n# occ &lt;- select(data, cellID, verbatim_name, start_year, end_year) %&gt;% unique()\n#\n# write_csv(occ, \"data/Birds_Quebec/Checked_data/occFin.csv\")\n#\n# eff &lt;- select(data, -verbatim_name) %&gt;%\n#   group_by(across(-CollectorNumber)) %&gt;%\n#   summarise(effort = n_distinct(CollectorNumber)) %&gt;%\n#   ungroup() %&gt;%\n#   group_by(cellID, start_year, end_year) %&gt;%\n#   summarise(effort = sum(effort)) %&gt;%\n#   ungroup()\n#\n# write_csv(eff, \"data/Birds_Quebec/Checked_data/effFin.csv\")\n#\n# samp_cells &lt;- select(occ, cellID, start_year) %&gt;%\n#   rbind(., select(eff, cellID, start_year)) %&gt;%\n#   unique() %&gt;%\n#   mutate(start_year = dense_rank(start_year),\n#          value = 1) %&gt;%\n#   pivot_wider(names_from = start_year,\n#               values_from = value,\n#               values_fill = 0) %&gt;%\n#   mutate(repeated = rowSums(select(., matches(\"^\\\\d\")))) %&gt;%\n#   select(cellID, repeated)\n#\n# write_csv(samp_cells, \"data/Birds_Quebec/Checked_data/samp_cells.csv\")",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Birds of Quebec</span>"
    ]
  },
  {
    "objectID": "Quebec.html#adding-records-to-the-database",
    "href": "Quebec.html#adding-records-to-the-database",
    "title": "7  Birds of Quebec",
    "section": "7.9 Adding records to the database",
    "text": "7.9 Adding records to the database\n\n7.9.1 Data\nImport the processed data and grid.\n\nocc_files &lt;- list.files(\"data/Birds_Quebec/Checked_data/\", pattern = \"_occ_data.xlsx\", full.names = T)\n\ndata &lt;- lapply(occ_files, function(x) {\n  readxl::read_xlsx(x) %&gt;%\n    filter(!is.na(cellID))\n}) %&gt;%\n  do.call(rbind, .) %&gt;%\n  mutate(\n    verbatimIdentificationID = dense_rank(verbatim_name),\n    samplingPeriodID = dense_rank(start_year)\n  )\n\nsp_names &lt;- data %&gt;%\n  select(verbatimIdentificationID, verbatim_name) %&gt;%\n  unique()\n\ncorrs &lt;- read_csv(\"data/Birds_Quebec/Checked_data/grids_correspondence_table.csv\") %&gt;%\n  mutate(across(matches(\"^X\\\\d\"), dense_rank)) %&gt;%\n  select(cellID, matches(\"^X\\\\d\"))\n\neff_files &lt;- list.files(\"data/Birds_Quebec/Checked_data/\", pattern = \"_eff_data.xlsx\", full.names = T)\n\neff &lt;- lapply(eff_files, function(x) {\n  readxl::read_xlsx(x) %&gt;%\n    filter(!is.na(cellID))\n}) %&gt;% do.call(rbind, .)\n\neff &lt;- select(data, cellID, start_year, end_year) %&gt;%\n  unique() %&gt;%\n  setdiff(., select(eff, cellID, start_year, end_year)) %&gt;%\n  mutate(effort_1 = NA, effort_1_unit = NA_character_) %&gt;%\n  bind_rows(eff, .) %&gt;%\n  mutate(samplingPeriodID = dense_rank(start_year))\n\nscaling_table &lt;- corrs %&gt;%\n  pivot_longer(-cellID, names_to = \"scalingID\", values_to = \"siteID\") %&gt;%\n  mutate(scalingID = str_remove_all(scalingID, \"^X\") %&gt;%\n    as.numeric()) %&gt;%\n  ungroup()\n\nsamp_cells &lt;- select(data, cellID, start_year) %&gt;%\n  rbind(., select(eff, cellID, start_year)) %&gt;%\n  unique() %&gt;%\n  group_by(cellID) %&gt;%\n  mutate(repeated = n_distinct((start_year))) %&gt;%\n  ungroup() %&gt;%\n  select(!start_year) %&gt;%\n  unique() %&gt;%\n  left_join(., corrs, by = \"cellID\") %&gt;%\n  pivot_longer(-c(cellID, repeated), names_to = \"cell_grouping\", values_to = \"cell_label\") %&gt;%\n  mutate(cell_grouping = str_remove_all(cell_grouping, \"^X\") %&gt;%\n    as.numeric()) %&gt;%\n  na.omit() %&gt;%\n  group_by(cell_grouping, cell_label) %&gt;%\n  summarise(repeated = max(repeated)) %&gt;%\n  ungroup()\n\ngrid &lt;- st_layers(\"data/Birds_Quebec/Checked_data/final_grid.gpkg\")$name %&gt;%\n  mclapply(., function(x) {\n    st_read(\"data/Birds_Quebec/Checked_data/final_grid.gpkg\",\n      layer = x, quiet = T\n    )\n  }, mc.cores = 10) %&gt;%\n  do.call(rbind, .) %&gt;%\n  ungroup() %&gt;%\n  st_make_valid() %&gt;%\n  mutate(coords = st_centroid(geom)) %&gt;%\n  mutate(\n    cell_lat = st_coordinates(coords)[, 2],\n    cell_long = st_coordinates(coords)[, 1]\n  )\n\n\ngrid_table &lt;- st_drop_geometry(grid) %&gt;%\n  left_join(., samp_cells)\n\n\n7.9.1.1 Basic double check\n\n# Check that all cellID in data are also in the corrs cellID\nif (length(setdiff(unique(data$cellID), unique(corrs$cellID))) == 0) {\n  print(\"OK\")\n} else {\n  print(\"FAIL\")\n}\n# Check that number of rows in grid and corrs are the same\nnrow(filter(grid, cell_grouping == 1)) == nrow(corrs)\n\n# Check that years and sampling periods are the same in data and eff\nnrow(setdiff(\n  unique(select(data, start_year, samplingPeriodID)),\n  unique(select(eff, start_year, samplingPeriodID))\n))\n\n# Check uniqueness of scaling_table\nnrow(unique(scaling_table)) == nrow(scaling_table)\n\n# Check that all cellID in data are also in the grid (corrs)\nlength(setdiff(\n  unique(data$cellID),\n  unique(corrs$cellID)\n))\n\n# Check that all cellID in eff are also in the grid (corrs)\nlength(setdiff(\n  unique(eff$cellID),\n  unique(corrs$cellID)\n))\n\n# RESULTS SHOULD BE: OK, TRUE, 0, TRUE, NULL, NULL\n\n\n\n7.9.1.2 Atlas variables\n\ndatasetID &lt;- 20\neffortID &lt;- 2\nlicenseID &lt;- 0\nshareable &lt;- \"NO\"\nverbatimFootprintSRS &lt;- \"epsg:4326\"\n\nAll cells match between the different dataset files.\n\nfinal_data &lt;- inner_join(data, corrs, by = \"cellID\")\nno_join_data &lt;- anti_join(data, corrs, by = \"cellID\")\n\n\n\n\n7.9.2 Database connection\n\nsource(\"scripts/dbcon.R\")\n\n\n\n7.9.3 List tables in database\n\ndbListTables(con) %&gt;%\n  purrr::keep(., ~ grepl(\"^CB|^MOBI\", .)) %&gt;%\n  kable(col.names = \"Tables\")\n\n\n\n7.9.4 Write code books\n\n7.9.4.1 CB_license\n\ntable &lt;- \"CB_license\" ## Table of interest\n\nCheck table colnames\n\ntbl(con, table) %&gt;%\n  as.data.frame() %&gt;%\n  colnames() %&gt;%\n  paste(., ' = \"\"', collapse = \",\\n\") %&gt;%\n  cat()\n\nCreate data table\n\ndata_table &lt;- data.frame(\n  licenseID = licenseID,\n  license = \"Restricted\",\n  licenseDescription = \"Closed data. Special request or purchase required\",\n  licenseURL = \"none\"\n)\n\nWrite into the database\n\ntry({\n  copy_to(con, data_table, table, append = T)\n})\nrm(data_table)\n\nCheck the table\n\ntbl(con, table) %&gt;% kable(align = \"c\")\n\n\n\n7.9.4.2 CB_sampling_effort\n\ntable &lt;- \"CB_sampling_effort\" ## Table of interest\n\nCheck table colnames\n\ntbl(con, table) %&gt;%\n  as.data.frame() %&gt;%\n  colnames() %&gt;%\n  paste(., ' = \"\"', collapse = \",\\n\") %&gt;%\n  cat()\n\nCreate data table\n\ndata_table &lt;- data.frame(\n  samplingEffortID = 2,\n  samplingEffortProtocol = \"Sampling events per gridcell\",\n  samplingEffortUnit = \"Sampling events\"\n)\n\nWrite into the database\n\ntry({\n  copy_to(con, data_table, table, append = T)\n})\nrm(data_table)\n\nCheck table.\n\ntbl(con, table) %&gt;% kable(align = \"c\")\n\n\n\n7.9.4.3 CB_model\n\ntable &lt;- \"CB_model\" ## Table of interest\n\nCheck table colnames\n\ntbl(con, table) %&gt;%\n  as.data.frame() %&gt;%\n  colnames() %&gt;%\n  paste(., ' = \"\"', collapse = \",\\n\") %&gt;%\n  cat()\n\nCreate data table\n\ndata_table &lt;- data.frame(\n  occurrenceModelID = \"\",\n  modelName = \"\",\n  predictorVariables = \"\",\n  bibliographicCitation = \"\"\n)\n\nWrite into the database\n\ntry({\n  copy_to(con, data_table, table, append = T)\n})\nrm(data_table)\n\nCheck table\n\ntbl(con, table) %&gt;% kable(align = \"c\")\n\n\n\n7.9.4.4 CB_taxonomy\n\ntable &lt;- \"CB_taxonomy\" ## Table of interest\n\nCheck table colnames\n\ntbl(con, table) %&gt;%\n  as.data.frame() %&gt;%\n  colnames() %&gt;%\n  paste(., ' = \"\"', collapse = \",\\n\") %&gt;%\n  cat()\n\nCreate data table\n\ndata_table &lt;- data.frame(\n  scientificNameID = \"\",\n  scientificName = \"\",\n  scientificNameAuthorship = \"\",\n  kingdom = \"\",\n  phylum = \"\",\n  class = \"\",\n  family = \"\",\n  order = \"\",\n  genus = \"\",\n  specificEpitet = \"\",\n  infraspecificEpitet = \"\",\n  taxonRank = \"\"\n)\n\nWrite into the database\n\ntry({\n  copy_to(con, data_table, table, append = T)\n})\nrm(data_table)\n\n\n\n7.9.4.5 CB_verbatim_name_equivalence\n\ntable &lt;- \"CB_verbatim_name_equivalence\" ## Table of interest\n\nCheck table colnames\n\ntbl(con, table) %&gt;%\n  as.data.frame() %&gt;%\n  colnames() %&gt;%\n  paste(., ' = \"\"', collapse = \",\\n\") %&gt;%\n  cat()\n\nCreate data table\n\ndata_table &lt;- data.frame(\n  verbatimIdentificationID = sp_names$verbatimIdentificationID,\n  verbatimIdentification = sp_names$verbatim_name,\n  datasetID = datasetID,\n  identificationReferences = \"\",\n  scientificNameID = NA\n)\n\nWrite into the database\n\ntry({\n  # Remove records where datasetID is the current dataset\n  dbExecute(con, paste0('DELETE FROM \"', table, '\" WHERE \"datasetID\" = ', datasetID))\n\n  # Copy data to the database\n  copy_to(con, data_table, table, append = TRUE)\n})\n\n# Remove the data_table from the environment\nrm(data_table)\n\nCheck table.\n\ntbl(con, sql(paste0('SELECT * FROM \"', table, '\" WHERE \"datasetID\" = ', datasetID))) %&gt;%\n  head() %&gt;%\n  kable(align = \"c\")\n\n\n\n\n7.9.5 Write dataset tables\n\n7.9.5.1 Dataset\n\ntable &lt;- \"MOBI_dataset\" ## Table of interest\n\nCheck table colnames\n\ntbl(con, table) %&gt;%\n  as.data.frame() %&gt;%\n  colnames() %&gt;%\n  paste(., ' = \"\"', collapse = \",\\n\") %&gt;%\n  cat()\n\nCreate data table\n\ndata_table &lt;- data.frame(\n  datasetID = datasetID,\n  datasetName = \"Quebec Breeding Bird Atlas\",\n  datasetPublisher = \"Environment Canada's Québec Regional Office\",\n  datasetPublisherContact = \"info@atlas-oiseaux.qc.ca\",\n  licenseID = licenseID,\n  rightsHolder = \"Environment Canada's Québec Regional Office\",\n  bibliographicCitation = \"Québec Breeding Bird Atlas. 2024. Data accessed from NatureCounts, a node of the Avian Knowledge Network, Bird Studies Canada. Available: http://www.naturecounts.ca/. Accessed: 24/01/24.\",\n  citationIdentifier = \"\",\n  provider = \"Environment Canada's Québec Regional Office\",\n  shareable = \"NO\",\n  coauthorshipRequired = \"NO\",\n  coauthors = \"\",\n  coauthorshipSuggested = \"Carmen Soria - carmendianasoria@gmail.com; Kateřina Tschernosterová - tschernosterova@fzp.czu.cz; Friederike Wölke - wolke@fzp.czu.cz; Gabriel Ortega - g.ortega.solis@gmail.com\",\n  isSamplingEffortReported = \"YES\",\n  isOccurrenceProbabilityAvailable = \"NO\"\n)\n\nWrite into the database\n\ntry({\n  dbExecute(con, paste0('DELETE FROM \"', table, '\" WHERE \"datasetID\" = ', datasetID))\n  copy_to(con, data_table, table, append = T)\n})\nrm(data_table)\n\nCheck table.\n\ntbl(con, sql(paste0('SELECT * FROM \"', table, '\" WHERE \"datasetID\" = ', datasetID))) %&gt;% kable(align = \"c\")\n\n\n\n7.9.5.2 Site\n\ntable &lt;- \"MOBI_site\" ## Table of interest\n\nCreate partition\n\nCREATE TABLE \"MOBI_site_20\" PARTITION OF \"MOBI_site\"\nFOR VALUES IN (20);\n\nCheck table colnames\n\ntbl(con, table) %&gt;%\n  as.data.frame() %&gt;%\n  colnames() %&gt;%\n  paste(., ' = \"\"', collapse = \",\\n\") %&gt;%\n  cat()\n\nCreate data table\n\ndata_table &lt;- data.frame(\n  siteID = grid_table$cell_label,\n  scalingID = grid_table$cell_grouping,\n  datasetID = datasetID,\n  area = grid_table$area,\n  croppedArea = grid_table$area_cropped,\n  areaUnit = \"km2\",\n  maxLength = grid_table$cell_max_length,\n  northSouthLength = grid_table$cell_ns_length,\n  eastWestLength = grid_table$cell_ew_length,\n  lengthUnit = \"km\",\n  centroidDecimalLongitude = grid_table$cell_long,\n  centroidDecimalLatitude = grid_table$cell_lat,\n  samplingRepetitions = grid_table$repeated\n)\n\nWrite into the database\n\ntry({\n  # Remove records where datasetID is the current dataset\n  dbExecute(con, paste0('DELETE FROM \"', table, '\" WHERE \"datasetID\" = ', datasetID))\n\n  # Copy data to the database\n  copy_to(con, data_table, table, append = TRUE)\n})\n\n# Remove the data_table from the environment\nrm(data_table)\n\nCheck table.\n\ntbl(\n  con,\n  sql(paste0('SELECT * FROM \"', table, '\" WHERE \"datasetID\" = ', datasetID))\n) %&gt;%\n  head(n = 20) %&gt;%\n  kable(align = \"c\")\n\n\n\n7.9.5.3 Geometry\n\ntable &lt;- \"MOBI_geometry\" ## Table of interest\n\nCreate partition\n\nCREATE TABLE \"MOBI_geometry_20\" PARTITION OF \"MOBI_geometry\"\nFOR VALUES IN (20);\n\nCheck table colnames\n\ntbl(con, table) %&gt;%\n  as.data.frame() %&gt;%\n  colnames() %&gt;%\n  paste(., ' = \"\"', collapse = \",\\n\") %&gt;%\n  cat()\n\nCreate data table\n\ndata_table &lt;- grid %&gt;%\n  ungroup() %&gt;%\n  rename(\n    siteID = cell_label,\n    scalingID = cell_grouping,\n    geometry = geom\n  ) %&gt;%\n  mutate(\n    siteID = as.integer(siteID),\n    scalingID = as.integer(scalingID),\n    datasetID = as.integer(datasetID),\n    footprintSRS = \"epsg:4326\",\n    verbatimFootprintSRS = verbatimFootprintSRS\n  ) %&gt;%\n  select(\n    ., siteID, scalingID, datasetID,\n    footprintSRS, verbatimFootprintSRS, geometry\n  )\n\ndata_table$geometry &lt;- st_cast(data_table$geometry, \"MULTIPOLYGON\")\n\nWrite into the database\n\ntry({\n  # Remove records where datasetID is the current dataset\n  dbExecute(con, paste0('DELETE FROM \"', table, '\" WHERE \"datasetID\" = ', datasetID))\n\n  # Write records\n  st_write(obj = data_table, dsn = con, layer = table, append = T)\n  # Remove the data_table from the environment\n  rm(data_table)\n})\n\nCheck table.\n\ntbl(con, sql(paste0('SELECT * FROM \"', table, '\" WHERE \"datasetID\" = ', datasetID))) %&gt;%\n  head() %&gt;%\n  kable(align = \"c\")\n\n\n\n\n7.9.6 Write helper tables\n\n7.9.6.1 Scaling table\nThis intermediate table enables the joins of records data to the different resolutions of sites.\n\ntable &lt;- \"MOBI_scaling_table\" ## Table of interest\n\nCreate partition\n\nCREATE TABLE \"MOBI_scaling_table_20\" PARTITION OF \"MOBI_scaling_table\"\nFOR VALUES IN (20);\n\nCheck table colnames.\n\ntbl(con, table) %&gt;%\n  as.data.frame() %&gt;%\n  colnames() %&gt;%\n  paste(., ' = \"\"', collapse = \",\\n\") %&gt;%\n  cat()\n\n\ndata_table &lt;- data.frame(\n  siteID = scaling_table$siteID,\n  scalingID = scaling_table$scalingID,\n  datasetID = datasetID,\n  verbatimSiteID = scaling_table$cellID\n)\n\nWrite into database.\n\ntry({\n  # Remove records where datasetID is the current dataset\n  dbExecute(con, paste0('DELETE FROM \"', table, '\" WHERE \"datasetID\" = ', datasetID))\n\n  # Copy data to the database\n  copy_to(con, data_table, table, append = TRUE)\n})\n\n# Remove the data_table from the environment\nrm(data_table)\n\nCheck table.\n\ntbl(con, sql(paste0('SELECT * FROM \"', table, '\" WHERE \"datasetID\" = ', datasetID))) %&gt;%\n  head() %&gt;%\n  kable(align = \"c\")\n\n\n\n\n7.9.7 Write records tables\n\n7.9.7.1 Event\n\ntable &lt;- \"MOBI_event\" ## Table of interest\n\nCreate partition\n\nCREATE TABLE \"MOBI_event_20\" PARTITION OF \"MOBI_event\"\nFOR VALUES IN (20);\n\nCheck table colnames\n\ntbl(con, table) %&gt;%\n  as.data.frame() %&gt;%\n  colnames() %&gt;%\n  paste(., ' = \"\"', collapse = \",\\n\") %&gt;%\n  cat()\n\nCreate data table\n\ndata_table &lt;- data.frame(\n  verbatimSiteID = eff$cellID,\n  datasetID = datasetID,\n  samplingPeriodID = eff$samplingPeriodID,\n  startYear = eff$start_year,\n  endYear = eff$end_year, samplingEffortID = 2,\n  samplingEffortValue = ifelse(eff$effort_1 == 0, NA,\n    eff$effort_1\n  ),\n  samplingEffort2ID = 4,\n  samplingEffort2Value = ifelse(eff$effort_2 == 0, NA,\n    eff$effort_2\n  )\n)\n\nif (nrow(unique(data_table)) != nrow(eff)) {\n  stop(\"Stopping execution due to row number mismatch\")\n} else {\n  print(\"OK\")\n}\n\ndata_table &lt;- filter(data_table, !is.na(verbatimSiteID))\n\nWrite into the database\n\ntry({\n  # Remove records where datasetID is the current dataset\n  dbExecute(con, paste0('DELETE FROM \"', table, '\" WHERE \"datasetID\" = ', datasetID))\n\n  # Copy data to the database\n  copy_to(con, data_table, table, append = TRUE)\n})\n\n# Remove the data_table from the environment\nrm(data_table)\n\nCheck table.\n\ntbl(con, sql(paste0('SELECT * FROM \"', table, '\" WHERE \"datasetID\" = ', datasetID))) %&gt;%\n  head() %&gt;%\n  kable(align = \"c\")\n\n\n\n7.9.7.2 Presence\n\ntable &lt;- \"MOBI_presence\" ## Table of interest\n\nCreate partition\n\nCREATE TABLE \"MOBI_presence_20\" PARTITION OF \"MOBI_presence\"\nFOR VALUES IN (20);\n\nCheck table colnames\n\ntbl(con, table) %&gt;%\n  as.data.frame() %&gt;%\n  colnames() %&gt;%\n  paste(., ' = \"\"', collapse = \",\\n\") %&gt;%\n  cat()\n\nCreate data table\n\ndata_table &lt;- data.frame(\n  verbatimIdentificationID = final_data$verbatimIdentificationID,\n  verbatimSiteID = final_data$cellID,\n  datasetID = datasetID,\n  samplingPeriodID = final_data$samplingPeriodID,\n  recordFilter = NA\n)\n\nWrite into the database\n\ntry({\n  # Remove records where datasetID is the current dataset\n  dbExecute(con, paste0('DELETE FROM \"', table, '\" WHERE \"datasetID\" = ', datasetID))\n\n  # Copy data to the database\n  copy_to(con, data_table, table, append = TRUE)\n})\n\n# Remove the data_table from the environment\nrm(data_table)\n\nCheck table.\n\ntbl(con, sql(paste0('SELECT * FROM \"', table, '\" WHERE \"datasetID\" = ', datasetID))) %&gt;%\n  head() %&gt;%\n  kable(align = \"c\")\n\n\n\n7.9.7.3 Probability\n\ntable &lt;- \"MOBI_probability\" ## Table of interest\n\nCreate partition\n\nCREATE TABLE \"MOBI_probability_20\" PARTITION OF \"MOBI_probability\"\nFOR VALUES IN (20);\n\nCheck table colnames\n\ntbl(con, table) %&gt;%\n  as.data.frame() %&gt;%\n  colnames() %&gt;%\n  paste(., ' = \"\"', collapse = \",\\n\") %&gt;%\n  cat()\n\nCreate data table\n\ndata_table &lt;- data.frame(\n  verbatimIdentificationID = \"\",\n  verbatimSiteID = \"\",\n  datasetID = \"\",\n  samplingPeriodID = \"\",\n  probability = \"\"\n)\n\nWrite into the database\n\ntry({\n  # Remove records where datasetID is the current dataset\n  dbExecute(con, paste0('DELETE FROM \"', table, '\" WHERE \"datasetID\" = ', datasetID))\n\n  # Copy data to the database\n  copy_to(con, data_table, table, append = TRUE)\n})\n\n# Remove the data_table from the environment\nrm(data_table)\n\nCheck table.\n\ntbl(con, sql(paste0('SELECT * FROM \"', table, '\" WHERE \"datasetID\" = ', datasetID))) %&gt;%\n  head() %&gt;%\n  kable(align = \"c\")",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Birds of Quebec</span>"
    ]
  },
  {
    "objectID": "Quebec.html#finish-session",
    "href": "Quebec.html#finish-session",
    "title": "7  Birds of Quebec",
    "section": "7.10 Finish session",
    "text": "7.10 Finish session\n\nsessionInfo()\n\n\n7.10.1 Clean up workspace\n\ndbDisconnect(con)\nrm(list = ls())\ngc()\n.rs.restartR()",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Birds of Quebec</span>"
    ]
  },
  {
    "objectID": "The_Maritimes.html",
    "href": "The_Maritimes.html",
    "title": "8  Birds of The Maritimes",
    "section": "",
    "text": "8.1 MOBI team roles",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Birds of The Maritimes</span>"
    ]
  },
  {
    "objectID": "The_Maritimes.html#mobi-team-roles",
    "href": "The_Maritimes.html#mobi-team-roles",
    "title": "8  Birds of The Maritimes",
    "section": "",
    "text": "Responsibilities\nName\nDate (MM/YY)\n\n\n\n\nData acquisition\n\n08/23\n\n\nMetadata preparation\nKateřina Tschernosterová\n\n\n\nData standardization\nKateřina Tschernosterová\n07/24\n\n\nData processing\nGabriel Ortega",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Birds of The Maritimes</span>"
    ]
  },
  {
    "objectID": "The_Maritimes.html#data-providers",
    "href": "The_Maritimes.html#data-providers",
    "title": "8  Birds of The Maritimes",
    "section": "8.2 Data providers",
    "text": "8.2 Data providers\nLlNK TO THE SPREADSHEET - for later - link this document with the Atlas status table for automatic updating of information (avoid mistakes or updates only in one of this sources)",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Birds of The Maritimes</span>"
    ]
  },
  {
    "objectID": "The_Maritimes.html#data-description",
    "href": "The_Maritimes.html#data-description",
    "title": "8  Birds of The Maritimes",
    "section": "8.3 Data description",
    "text": "8.3 Data description\n\nObservation data by grid cell, by species and by observation card (sampling event and data collector)\nPresence is reported, no data on abundance or absence\nOriginal data detail - Scientific species name, Common species name, Survey area identifier, Decimal latitude and longitude of survey area, Year collected, Collector number, Sampling event identifier, Effort in hours (BBA1 only, not for all events), Breeding bird atlas code\nThe Maritimes region includes provinces New Brunswick, Nova Scotia and Prince Edward Island\nData was downloaded trough NatureCounts website - https://naturecounts.ca/nc/default/explore.jsp#download\n\nDownloaded dataset with BBA1 data - Maritimes Breeding Bird Atlas (1986-1990): raw breeding evidence [Maritimes Breeding Bird Atlas]\nDownloaded dataset with BBA2 data - Maritimes Breeding Bird Atlas (2006-2010): raw breeding evidence [Maritimes Breeding Bird Atlas]\nAnother available dataset that was not used - Maritimes Breeding Bird Atlas (2006-2010): point count data [Maritimes Breeding Bird Atlas]\n\nBBA1 website - https://www.mba-aom.ca/first-atlas/\nBBA2 website - https://www.mba-aom.ca/\nBBA2 online book - https://www.mba-aom.ca/jsp/toc.jsp\n\n\n8.3.1 Sampling methodology\n\nData was collected in sampling squares by volunteer atlasers\nFor both atlases, the basic sampling unit was a 10 km by 10 km (100 km2) square from the Universal Transverse Mercator (UTM) grid.\nThe UTM coordinates of the squares were almost identical in the first and second atlases, but they shifted slightly because the UTM reference parameters changed between atlases. For the first atlas, the North American Datum of 1927 (NAD27) was used, whereas for the second atlas the North American Datum of 1983 (NAD83) was used. (BBA2 pdf, p. 35)\n\n\n\n8.3.2 Sampling effort\n\nSampling square was considered fully surveyed, or “complete,” once it received 20 hours of cumulative survey effort or when a substantial number of species was detected in the square. (BBA2 pdf, p. 37)\nFor BB1 is reported sampling duration (effort) in hours for some sampling events - but for some events the value of effort in hours is equal to 0 and for some events the value is missing. The value of sampling event duration is not complete, so it can be used only with restrictions. Sum of hours does not make sense.\nTherefore sampling effort for BBA1 is also reported as number of sampling events per sampling square\nIn BBA2 data there is no information on duration of sampling events, therefore sampling effort is reported only as number of sampling events per sampling square",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Birds of The Maritimes</span>"
    ]
  },
  {
    "objectID": "The_Maritimes.html#input-data",
    "href": "The_Maritimes.html#input-data",
    "title": "8  Birds of The Maritimes",
    "section": "8.4 Input Data",
    "text": "8.4 Input Data\n\n8.4.1 Original data folder\n\nBirds_Atlas_The Maritimes_1_Column names.txt - text file with the list of original data column names\nBirds_Atlas_The Maritimes_1_OriginalData.csv - csv file with raw observation data for BBA1 1986-1990\nBirds_Atlas_The Maritimes_2_OriginalData.csv - csv file with raw observation data for BBA2 2006-2010\n\n\n\n8.4.2 Grid folder\nXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX check with Gabriel\n\nBirds_Atlas_The Maritimes_1-2_Maps grid shp download script.R\nBirds_Atlas_The Maritimes maps.Rproj\nmaritimes_gridmap shapefile\n\n\n\n8.4.3 Docs folder\n\nBirds_Atlas_The Maritimes_2_Documentation.pdf - Breeding Bird Atlas project final report\nBirds_Atlas_The Maritimes_2_Guide.pdf - handbook with instructions for volunteer atlasers\nBirds_Atlas_The Maritimes_1-2_Data policy.html - NatureCounts policy on use and publication of atlas data\nFirst Breeding Birds Atlas of the Maritimes Provinces, 1992.pdf - Pdf version of atlas\nSecond Atlas of Breeding Birds of the Maritime Provinces, 2015 - Folder with pdf version of atlas divided into 17 pdf parts\n\n\n\n8.4.4 Checked data folder\n\nBirds_Atlas_TheMaritimes_CheckedData_working.xlsx - effort and occurrence data standardization, working file\nBirds_Atlas_TheMaritimes_1_1986-1990_occ_data.xlsx - standardized occurrence data\nBirds_Atlas_TheMaritimes_1_1986-1990_eff_data.xlsx - standardized effort data\nBirds_Atlas_TheMaritimes_2_2006-2010_occ_data.xlsx - standardized occurrence data\nBirds_Atlas_TheMaritimes_2_2006-2010_eff_data.xlsx - standardized effort data\nXX_Birds_of_The_Maritimes_data description.qmd - Quarto document, contains metadata, processing notes and codes, part of BEAST database documentation",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Birds of The Maritimes</span>"
    ]
  },
  {
    "objectID": "The_Maritimes.html#data-standardization-and-processing-comments",
    "href": "The_Maritimes.html#data-standardization-and-processing-comments",
    "title": "8  Birds of The Maritimes",
    "section": "8.5 Data standardization and processing comments",
    "text": "8.5 Data standardization and processing comments\n\n!!! IMPORTANT !!! the sampling effort in hours for BBA1 is not complete",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Birds of The Maritimes</span>"
    ]
  },
  {
    "objectID": "The_Maritimes.html#libraries",
    "href": "The_Maritimes.html#libraries",
    "title": "8  Birds of The Maritimes",
    "section": "8.6 Libraries",
    "text": "8.6 Libraries\n\npacman::p_load(\n  sf, terra, tidyverse, tidyterra, knitr,\n  tictoc, RPostgres, DBI, dbplyr, parallel,\n  geodata\n)",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Birds of The Maritimes</span>"
    ]
  },
  {
    "objectID": "The_Maritimes.html#grid-processing",
    "href": "The_Maritimes.html#grid-processing",
    "title": "8  Birds of The Maritimes",
    "section": "8.7 Grid processing",
    "text": "8.7 Grid processing\n\nrm -rf /tmp/Original_data\nunzip data/Birds_The_Maritimes/Original_data.zip -d /tmp/\n\n\nglimpse(vect(\"/tmp/Original_data/maritimes_gridmap.shp\"))\n\nThere were two cells whose BLOCK id was NA. One was in the sea and the other covering lake Oneida.\n\ngrid &lt;- st_read(\"/tmp/Original_data/maritimes_gridmap.shp\") %&gt;%\n  select(utm_sqr, utm_stn, utm_nrt, utm_zon) %&gt;%\n  rename(cellID = utm_sqr) %&gt;%\n  mutate(cellID = str_c(str_sub(cellID, 1, 2), str_sub(cellID, 4))) %&gt;%\n  unique()\n\n\ngrid_grouping &lt;- function(grid, col1, col2, num) {\n  grid &lt;- st_drop_geometry(grid)\n  mincol1 &lt;- min(grid[[col1]])\n  maxcol1 &lt;- max(grid[[col1]])\n  mincol2 &lt;- min(grid[[col2]])\n  maxcol2 &lt;- max(grid[[col2]])\n  breaksA &lt;- seq(mincol1, maxcol1, num)\n  breaksB &lt;- seq(mincol2, maxcol2, num)\n  if (length(breaksA) &gt; 1) {\n    A &lt;- cut(grid[[col1]], breaks = breaksA, right = F)\n  } else {\n    A &lt;- 1\n  }\n  if (length(breaksB) &gt; 1) {\n    B &lt;- cut(grid[[col2]], breaks = breaksB, right = F)\n  } else {\n    B &lt;- 1\n  }\n  res &lt;- paste0(grid$utm_zon, \"_\", A, B)\n  return(res)\n}\n\nCreate labels for rescaling\n\nfor (dist in c(2, 4, 8, 16, 32, 64)) {\n  num &lt;- 10000 * dist\n  grid[[paste0(dist)]] &lt;- grid_grouping(grid, col1 = \"utm_stn\", col2 = \"utm_nrt\", num = num)\n}\n\ngrid$`1` &lt;- dense_rank(grid$cellID)\ngrid$`128` &lt;- 1\n\ngrid &lt;- grid %&gt;% mutate(across(matches(\"^\\\\d\"), dense_rank))\n\nst_write(grid, \"/tmp/The_Maritimes.gpkg\", delete_dsn = T)\n\n\nqgis /tmp/The_Maritimes.gpkg\n\nWe have different percentages of overlap between cells and real country borders. Therefore, we should have a way to correct the areas.\n\ngrid &lt;- st_read(\"data/Birds_The_Maritimes/Checked_data/modified_grid.gpkg\") %&gt;%\n  mutate(across(matches(\"^X\\\\d\"), dense_rank))\n\nadm_boundary &lt;- gadm(\"CAN\", path = \"/tmp/\", resolution = 1) %&gt;%\n  select(ISO_1) %&gt;%\n  filter(ISO_1 %in% c(\"CA-NB\", \"CA-NS\", \"CA-PE\")) %&gt;%\n  project(., \"epsg:4326\")\n\nint &lt;- terra::intersect(select(vect(grid), cellID), adm_boundary)\n\nint &lt;- group_by(int, cellID) %&gt;% summarise()\n\nint$cropped_area &lt;- expanse(int, unit = \"km\")\n\ngrid &lt;- as.data.frame(int) %&gt;%\n  left_join(grid, ., by = \"cellID\")\n\nCalculate cell area with and without correction by landmasses or country borders.\n\ngrid$cell_area &lt;- expanse(vect(grid), unit = \"km\")\ngrid$cell_area_proportion &lt;- grid$cropped_area / grid$cell_area %&gt;% round(., digits = 2)\n\nRemove cells without ID (if any)\n\nnoID &lt;- filter(grid, is.na(cellID))\ngrid &lt;- filter(grid, !is.na(cellID))\n\n\n# Pivot cells to a longer format for easier use in models.\nfinal_grids &lt;- grid %&gt;%\n  pivot_longer(matches(\"^X\\\\d\"),\n    names_to = \"cell_grouping\",\n    values_to = \"cell_label\"\n  ) %&gt;%\n  mutate(cell_grouping = str_remove_all(cell_grouping, \"X\") %&gt;%\n    as.numeric())\n\nfinal_grids &lt;- split(final_grids, final_grids$cell_grouping)\n\nAggregate cells and summarize the area.\n\nfinal_grids &lt;- final_grids %&gt;%\n  lapply(., function(x) {\n    res &lt;- x %&gt;%\n      group_by(cell_grouping, cell_label) %&gt;%\n      summarise(\n        area = sum(cell_area, na.rm = T),\n        area_cropped = sum(cropped_area, na.rm = T)\n      ) %&gt;%\n      ungroup()\n  })\n\nFunctions to add additional variables of cell shapes\n\n# Function to get cell shape attributes\n\nfdistances &lt;- function(x, type = NULL) {\n  x &lt;- vect(x)\n  pol &lt;- as.data.frame(crds(as.points(ext(project(x, \"epsg:4326\")))))\n  if (type == \"ew\") {\n    sw &lt;- pol %&gt;%\n      summarise(x = min(x), y = min(y)) %&gt;%\n      as.matrix()\n    se &lt;- pol %&gt;%\n      summarise(x = max(x), y = min(y)) %&gt;%\n      as.matrix()\n    res &lt;- distance(sw, se, lonlat = T)[[1]] / 1000\n  }\n  if (type == \"ns\") {\n    sw &lt;- pol %&gt;%\n      summarise(x = min(x), y = min(y)) %&gt;%\n      as.matrix()\n    nw &lt;- pol %&gt;%\n      summarise(x = min(x), y = max(y)) %&gt;%\n      as.matrix()\n    res &lt;- distance(sw, nw, lonlat = T)[[1]] / 1000\n  }\n  if (type == \"max\") {\n    res &lt;- distance(pol, lonlat = T) %&gt;% max()\n    res &lt;- res / 1000\n  }\n  res &lt;- as.numeric(res)\n  return(res)\n}\n\nAdd cell max length, distance south-north, and distance east-west.\n\ntic()\n\nadd_cell_lengths &lt;- function(x) {\n  res &lt;- x\n  list &lt;- res %&gt;%\n    select(cell_label)\n  list &lt;- terra::split(list, list$cell_label)\n\n  res$cell_max_length &lt;- lapply(list, function(.x) fdistances(.x, type = \"max\")) %&gt;%\n    do.call(rbind, .) %&gt;%\n    as.numeric()\n\n  res$cell_ns_length &lt;- lapply(list, function(.x) fdistances(.x, type = \"ns\")) %&gt;%\n    do.call(rbind, .) %&gt;%\n    as.numeric()\n\n  res$cell_ew_length &lt;- lapply(list, function(.x) fdistances(.x, type = \"ew\")) %&gt;%\n    do.call(rbind, .) %&gt;%\n    as.numeric()\n\n  res &lt;- st_transform(res, st_crs(x))\n  return(res)\n}\n\n# Create a cluster\ncl &lt;- makeCluster(getOption(\"cl.cores\", detectCores() - 5))\n\n# Load necessary packages on each worker\nclusterEvalQ(cl, {\n  library(dplyr)\n  library(terra)\n  library(sf)\n})\n\n# Export the function to the cluster\nclusterExport(cl, varlist = \"fdistances\")\n\n# Use parSapply with the cluster\nfinal_grids &lt;- parSapply(cl, final_grids, add_cell_lengths, simplify = FALSE, USE.NAMES = TRUE)\n\n# Stop the cluster\nstopCluster(cl)\n\ntoc()\n\n\nplet(vect(final_grids[[6]]))\n\nExport results.\n\ngrid %&gt;%\n  st_drop_geometry() %&gt;%\n  select(matches(\"^cell|^X\")) %&gt;%\n  write_csv(., \"data/Birds_The_Maritimes/Checked_data/grids_correspondence_table.csv\")\n\nfile.remove(\"data/Birds_The_Maritimes/Checked_data/final_grid.gpkg\")\n\nfor (x in 1:length(final_grids)) {\n  st_write(final_grids[[x]], layer = paste0(\"grid_\", x), dsn = \"data/Birds_The_Maritimes/Checked_data/final_grid.gpkg\")\n}",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Birds of The Maritimes</span>"
    ]
  },
  {
    "objectID": "The_Maritimes.html#data-processing",
    "href": "The_Maritimes.html#data-processing",
    "title": "8  Birds of The Maritimes",
    "section": "8.8 Data processing",
    "text": "8.8 Data processing\n\n# files &lt;- c(\"/tmp/Original_data/Birds_Atlas_The_Maritimes_1_Data_raw\\ breeding\\ evidence.txt\",\"/tmp/Original_data/Birds_Atlas_The_Maritimes_2_Data_raw\\ breeding\\ evidence.txt\")\n#\n# columns &lt;- c(\"ScientificName\", \"Locality\", \"SamplingEventIdentifier\", \"RouteIdentifier\", \"EffortMeasurement1\", \"EffortUnits1\", \"DecimalLongitude\", \"DecimalLatitude\", \"YearCollected\", \"MonthCollected\", \"DayCollected\",\"SamplingEventIdentifier\", \"CollectorNumber\")\n#\n# data &lt;- lapply(files, function(x) read_delim(x) %&gt;%\n#                  select(any_of(columns)) %&gt;%\n#                  unique()) %&gt;% do.call(rbind,.) #%&gt;%\n#   mutate(index = paste0(DecimalLongitude,\"_\",DecimalLatitude)) %&gt;%\n#   rename(verbatim_name = ScientificName) %&gt;%\n#   mutate(CollectorNumber = max(CollectorNumber)+1)\n#\n# View(summarise(data, across(everything(), ~sum(is.na(.)))))\n#\n# index &lt;- select(data, index, DecimalLongitude, DecimalLatitude) %&gt;%\n#   unique() %&gt;%\n#   st_as_sf(., coords = c(\"DecimalLongitude\",\"DecimalLatitude\"), crs = 4326)\n#\n# index &lt;- select(grid, cellID) %&gt;%\n#   st_join(., index) %&gt;%\n#   st_drop_geometry()\n#\n# data &lt;- left_join(data, index, by = \"index\") %&gt;% select(-index,-DecimalLongitude, -DecimalLatitude) %&gt;% unique() %&gt;%\n#   mutate(start_year = case_when(\n#     YearCollected &gt;= 1987 & YearCollected &lt;= 1991 ~ 1987,\n#     YearCollected &gt;= 2000 & YearCollected &lt;= 2005 ~ 2000\n#   ),\n#   end_year = case_when(\n#     YearCollected &gt;= 1987 & YearCollected &lt;= 1991 ~ 1991,\n#     YearCollected &gt;= 2000 & YearCollected &lt;= 2005 ~ 2005\n#   ))\n#\n# occ &lt;- select(data, cellID, verbatim_name, start_year, end_year) %&gt;% unique()\n#\n# write_csv(occ, \"data/Birds_The_Maritimes/Checked_data/occFin.csv\")\n#\n# eff &lt;- select(data, -verbatim_name) %&gt;%\n#   group_by(across(-CollectorNumber)) %&gt;%\n#   summarise(effort = n_distinct(CollectorNumber)) %&gt;%\n#   ungroup() %&gt;%\n#   group_by(cellID, start_year, end_year) %&gt;%\n#   summarise(effort = sum(effort)) %&gt;%\n#   ungroup()\n#\n# write_csv(eff, \"data/Birds_The_Maritimes/Checked_data/effFin.csv\")\n#\n# samp_cells &lt;- select(occ, cellID, start_year) %&gt;%\n#   rbind(., select(eff, cellID, start_year)) %&gt;%\n#   unique() %&gt;%\n#   mutate(start_year = dense_rank(start_year),\n#          value = 1) %&gt;%\n#   pivot_wider(names_from = start_year,\n#               values_from = value,\n#               values_fill = 0) %&gt;%\n#   mutate(repeated = rowSums(select(., matches(\"^\\\\d\")))) %&gt;%\n#   select(cellID, repeated)\n#\n# write_csv(samp_cells, \"data/Birds_The_Maritimes/Checked_data/samp_cells.csv\")",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Birds of The Maritimes</span>"
    ]
  },
  {
    "objectID": "The_Maritimes.html#adding-records-to-the-database",
    "href": "The_Maritimes.html#adding-records-to-the-database",
    "title": "8  Birds of The Maritimes",
    "section": "8.9 Adding records to the database",
    "text": "8.9 Adding records to the database\n\n8.9.1 Data\nImport the processed data and grid.\n\nocc_files &lt;- list.files(\"data/Birds_The_Maritimes/Checked_data/\", pattern = \"_occ_data.xlsx\", full.names = T)\n\ndata &lt;- lapply(occ_files, function(x) {\n  readxl::read_xlsx(x) %&gt;%\n    filter(!is.na(cellID))\n}) %&gt;%\n  do.call(rbind, .) %&gt;%\n  mutate(\n    verbatimIdentificationID = dense_rank(verbatim_name),\n    samplingPeriodID = dense_rank(start_year)\n  )\n\nsp_names &lt;- data %&gt;%\n  select(verbatimIdentificationID, verbatim_name) %&gt;%\n  unique()\n\ncorrs &lt;- read_csv(\"data/Birds_The_Maritimes/Checked_data/grids_correspondence_table.csv\") %&gt;%\n  mutate(across(matches(\"^X\\\\d\"), dense_rank)) %&gt;%\n  select(cellID, matches(\"^X\\\\d\"))\n\neff_files &lt;- list.files(\"data/Birds_The_Maritimes/Checked_data/\", pattern = \"_eff_data.xlsx\", full.names = T)\n\neff &lt;- lapply(eff_files, function(x) {\n  df &lt;- readxl::read_xlsx(x) %&gt;%\n    filter(!is.na(cellID))\n  if (\"effort_1\" %in% colnames(df)) {\n    colnames(df)[colnames(df) == \"effort_1\"] &lt;- \"effort\"\n    colnames(df)[colnames(df) == \"effort_1_unit\"] &lt;- \"effort_unit\"\n  }\n  return(df)\n}) %&gt;% data.table::rbindlist(fill = TRUE)\n\n\neff &lt;- select(data, cellID, start_year, end_year) %&gt;%\n  unique() %&gt;%\n  setdiff(., select(eff, cellID, start_year, end_year)) %&gt;%\n  mutate(effort = 1, effort_unit = \"n_events\") %&gt;%\n  bind_rows(eff, .) %&gt;%\n  mutate(samplingPeriodID = dense_rank(start_year))\n\nscaling_table &lt;- corrs %&gt;%\n  pivot_longer(-cellID, names_to = \"scalingID\", values_to = \"siteID\") %&gt;%\n  mutate(scalingID = str_remove_all(scalingID, \"^X\") %&gt;%\n    as.numeric()) %&gt;%\n  ungroup()\n\nsamp_cells &lt;- select(data, cellID, start_year) %&gt;%\n  rbind(., select(eff, cellID, start_year)) %&gt;%\n  unique() %&gt;%\n  group_by(cellID) %&gt;%\n  mutate(repeated = n_distinct((start_year))) %&gt;%\n  ungroup() %&gt;%\n  select(!start_year) %&gt;%\n  unique() %&gt;%\n  left_join(., corrs, by = \"cellID\") %&gt;%\n  pivot_longer(-c(cellID, repeated), names_to = \"cell_grouping\", values_to = \"cell_label\") %&gt;%\n  mutate(cell_grouping = str_remove_all(cell_grouping, \"^X\") %&gt;%\n    as.numeric()) %&gt;%\n  na.omit() %&gt;%\n  group_by(cell_grouping, cell_label) %&gt;%\n  summarise(repeated = max(repeated, na.rm = T)) %&gt;%\n  ungroup()\n\ngrid &lt;- st_layers(\"data/Birds_The_Maritimes/Checked_data/final_grid.gpkg\")$name %&gt;%\n  mclapply(., function(x) {\n    st_read(\"data/Birds_The_Maritimes/Checked_data/final_grid.gpkg\",\n      layer = x, quiet = T\n    )\n  }, mc.cores = 10) %&gt;%\n  do.call(rbind, .) %&gt;%\n  ungroup() %&gt;%\n  st_make_valid() %&gt;%\n  mutate(coords = st_centroid(geom)) %&gt;%\n  mutate(\n    cell_lat = st_coordinates(coords)[, 2],\n    cell_long = st_coordinates(coords)[, 1]\n  )\n\n\ngrid_table &lt;- st_drop_geometry(grid) %&gt;%\n  left_join(., samp_cells)\n\n\n8.9.1.1 Basic double check\n\n# Check that all cellID in data are also in the corrs cellID\nif (length(setdiff(unique(data$cellID), unique(corrs$cellID))) == 0) {\n  print(\"OK\")\n} else {\n  print(\"FAIL\")\n}\n# Check that number of rows in grid and corrs are the same\nnrow(filter(grid, cell_grouping == 1)) &lt;= nrow(corrs)\n\n# Check that years and sampling periods are the same in data and eff\nnrow(setdiff(\n  unique(select(data, start_year, samplingPeriodID)),\n  unique(select(eff, start_year, samplingPeriodID))\n))\n\n# Check uniqueness of scaling_table\nnrow(unique(scaling_table)) == nrow(scaling_table)\n\n# Check that all cellID in data are also in the grid (corrs)\nlength(setdiff(\n  unique(data$cellID),\n  unique(corrs$cellID)\n))\n\n# Check that all cellID in eff are also in the grid (corrs)\nlength(setdiff(\n  unique(eff$cellID),\n  unique(corrs$cellID)\n))\n\n# RESULTS SHOULD BE: OK, TRUE, 0, TRUE, NULL, NULL\n\n\n\n8.9.1.2 Atlas variables\n\ndatasetID &lt;- 23\neffortID &lt;- 2\nlicenseID &lt;- 0\nshareable &lt;- \"NO\"\nverbatimFootprintSRS &lt;- \"epsg:4326\"\n\nAll cells match between the different dataset files.\n\nfinal_data &lt;- inner_join(data, corrs, by = \"cellID\")\nno_join_data &lt;- anti_join(data, corrs, by = \"cellID\")\n\n\n\n\n8.9.2 Database connection\n\nsource(\"scripts/dbcon.R\")\n\n\n\n8.9.3 List tables in database\n\ndbListTables(con) %&gt;%\n  purrr::keep(., ~ grepl(\"^CB|^MOBI\", .)) %&gt;%\n  kable(col.names = \"Tables\")\n\n\n\n8.9.4 Write code books\n\n8.9.4.1 CB_license\n\ntable &lt;- \"CB_license\" ## Table of interest\n\nCheck table colnames\n\ntbl(con, table) %&gt;%\n  as.data.frame() %&gt;%\n  colnames() %&gt;%\n  paste(., ' = \"\"', collapse = \",\\n\") %&gt;%\n  cat()\n\nCreate data table\n\ndata_table &lt;- data.frame(\n  licenseID = licenseID,\n  license = \"Restricted\",\n  licenseDescription = \"Closed data. Special request or purchase required\",\n  licenseURL = \"none\"\n)\n\nWrite into the database\n\ntry({\n  copy_to(con, data_table, table, append = T)\n})\nrm(data_table)\n\nCheck the table\n\ntbl(con, table) %&gt;% kable(align = \"c\")\n\n\n\n8.9.4.2 CB_sampling_effort\n\ntable &lt;- \"CB_sampling_effort\" ## Table of interest\n\nCheck table colnames\n\ntbl(con, table) %&gt;%\n  as.data.frame() %&gt;%\n  colnames() %&gt;%\n  paste(., ' = \"\"', collapse = \",\\n\") %&gt;%\n  cat()\n\nCreate data table\n\ndata_table &lt;- data.frame(\n  samplingEffortID = 2,\n  samplingEffortProtocol = \"Sampling events per gridcell\",\n  samplingEffortUnit = \"Sampling events\"\n)\n\nWrite into the database\n\ntry({\n  copy_to(con, data_table, table, append = T)\n})\nrm(data_table)\n\nCheck table.\n\ntbl(con, table) %&gt;% kable(align = \"c\")\n\n\n\n8.9.4.3 CB_model\n\ntable &lt;- \"CB_model\" ## Table of interest\n\nCheck table colnames\n\ntbl(con, table) %&gt;%\n  as.data.frame() %&gt;%\n  colnames() %&gt;%\n  paste(., ' = \"\"', collapse = \",\\n\") %&gt;%\n  cat()\n\nCreate data table\n\ndata_table &lt;- data.frame(\n  occurrenceModelID = \"\",\n  modelName = \"\",\n  predictorVariables = \"\",\n  bibliographicCitation = \"\"\n)\n\nWrite into the database\n\ntry({\n  copy_to(con, data_table, table, append = T)\n})\nrm(data_table)\n\nCheck table\n\ntbl(con, table) %&gt;% kable(align = \"c\")\n\n\n\n8.9.4.4 CB_taxonomy\n\ntable &lt;- \"CB_taxonomy\" ## Table of interest\n\nCheck table colnames\n\ntbl(con, table) %&gt;%\n  as.data.frame() %&gt;%\n  colnames() %&gt;%\n  paste(., ' = \"\"', collapse = \",\\n\") %&gt;%\n  cat()\n\nCreate data table\n\ndata_table &lt;- data.frame(\n  scientificNameID = \"\",\n  scientificName = \"\",\n  scientificNameAuthorship = \"\",\n  kingdom = \"\",\n  phylum = \"\",\n  class = \"\",\n  family = \"\",\n  order = \"\",\n  genus = \"\",\n  specificEpitet = \"\",\n  infraspecificEpitet = \"\",\n  taxonRank = \"\"\n)\n\nWrite into the database\n\ntry({\n  copy_to(con, data_table, table, append = T)\n})\nrm(data_table)\n\n\n\n8.9.4.5 CB_verbatim_name_equivalence\n\ntable &lt;- \"CB_verbatim_name_equivalence\" ## Table of interest\n\nCheck table colnames\n\ntbl(con, table) %&gt;%\n  as.data.frame() %&gt;%\n  colnames() %&gt;%\n  paste(., ' = \"\"', collapse = \",\\n\") %&gt;%\n  cat()\n\nCreate data table\n\ndata_table &lt;- data.frame(\n  verbatimIdentificationID = sp_names$verbatimIdentificationID,\n  verbatimIdentification = sp_names$verbatim_name,\n  datasetID = datasetID,\n  identificationReferences = \"\",\n  scientificNameID = NA\n)\n\nWrite into the database\n\ntry({\n  # Remove records where datasetID is the current dataset\n  dbExecute(con, paste0('DELETE FROM \"', table, '\" WHERE \"datasetID\" = ', datasetID))\n\n  # Copy data to the database\n  copy_to(con, data_table, table, append = TRUE)\n})\n\n# Remove the data_table from the environment\nrm(data_table)\n\nCheck table.\n\ntbl(con, sql(paste0('SELECT * FROM \"', table, '\" WHERE \"datasetID\" = ', datasetID))) %&gt;%\n  head() %&gt;%\n  kable(align = \"c\")\n\n\n\n\n8.9.5 Write dataset tables\n\n8.9.5.1 Dataset\n\ntable &lt;- \"MOBI_dataset\" ## Table of interest\n\nCheck table colnames\n\ntbl(con, table) %&gt;%\n  as.data.frame() %&gt;%\n  colnames() %&gt;%\n  paste(., ' = \"\"', collapse = \",\\n\") %&gt;%\n  cat()\n\nCreate data table\n\ndata_table &lt;- data.frame(\n  datasetID = datasetID,\n  datasetName = \"Bird atlas The Maritimes\",\n  datasetPublisher = \"Bird Studies Canada\",\n  datasetPublisherContact = \"mba-aom@birdscanada.org\",\n  licenseID = licenseID,\n  rightsHolder = \"Bird Studies Canada\",\n  bibliographicCitation = \"BBA1 and BBA2 data: Bird Studies Canada, Environment Canada - Canadian Wildlife Service, New Brunswick Department of Natural Resources, Nova Scotia Department of Natural Resources, Prince Edward Island Department of Agriculture and Forestry. 2012. Maritimes Breeding Bird Atlas Database. Data accessed from the Maritimes Breeding Bird Atlas website and/or NatureCounts, a node of the Avian Knowledge Network, Bird Studies Canada. Available: http://www.naturecounts.ca/. Accessed: 24/01/24.\",\n  citationIdentifier = \"\",\n  provider = \"Bird Studies Canada\",\n  shareable = \"NO\",\n  coauthorshipRequired = \"NO\",\n  coauthors = \"\",\n  coauthorshipSuggested = \"Carmen Soria - carmendianasoria@gmail.com; Kateřina Tschernosterová - tschernosterova@fzp.czu.cz; Gabriel Ortega - g.ortega.solis@gmail.com\",\n  isSamplingEffortReported = \"YES\",\n  isOccurrenceProbabilityAvailable = \"NO\"\n)\n\nWrite into the database\n\ntry({\n  dbExecute(con, paste0('DELETE FROM \"', table, '\" WHERE \"datasetID\" = ', datasetID))\n  copy_to(con, data_table, table, append = T)\n})\nrm(data_table)\n\nCheck table.\n\ntbl(con, sql(paste0('SELECT * FROM \"', table, '\" WHERE \"datasetID\" = ', datasetID))) %&gt;% kable(align = \"c\")\n\n\n\n8.9.5.2 Site\n\ntable &lt;- \"MOBI_site\" ## Table of interest\n\nCreate partition\n\nCREATE TABLE \"MOBI_site_23\" PARTITION OF \"MOBI_site\"\nFOR VALUES IN (23);\n\nCheck table colnames\n\ntbl(con, table) %&gt;%\n  as.data.frame() %&gt;%\n  colnames() %&gt;%\n  paste(., ' = \"\"', collapse = \",\\n\") %&gt;%\n  cat()\n\nCreate data table\n\ndata_table &lt;- data.frame(\n  siteID = grid_table$cell_label,\n  scalingID = grid_table$cell_grouping,\n  datasetID = datasetID,\n  area = grid_table$area,\n  croppedArea = grid_table$area_cropped,\n  areaUnit = \"km2\",\n  maxLength = grid_table$cell_max_length,\n  northSouthLength = grid_table$cell_ns_length,\n  eastWestLength = grid_table$cell_ew_length,\n  lengthUnit = \"km\",\n  centroidDecimalLongitude = grid_table$cell_long,\n  centroidDecimalLatitude = grid_table$cell_lat,\n  samplingRepetitions = grid_table$repeated\n)\n\nWrite into the database\n\ntry({\n  # Remove records where datasetID is the current dataset\n  dbExecute(con, paste0('DELETE FROM \"', table, '\" WHERE \"datasetID\" = ', datasetID))\n\n  # Copy data to the database\n  copy_to(con, data_table, table, append = TRUE)\n})\n\n# Remove the data_table from the environment\nrm(data_table)\n\nCheck table.\n\ntbl(\n  con,\n  sql(paste0('SELECT * FROM \"', table, '\" WHERE \"datasetID\" = ', datasetID))\n) %&gt;%\n  head(n = 20) %&gt;%\n  kable(align = \"c\")\n\n\n\n8.9.5.3 Geometry\n\ntable &lt;- \"MOBI_geometry\" ## Table of interest\n\nCreate partition\n\nCREATE TABLE \"MOBI_geometry_23\" PARTITION OF \"MOBI_geometry\"\nFOR VALUES IN (23);\n\nCheck table colnames\n\ntbl(con, table) %&gt;%\n  as.data.frame() %&gt;%\n  colnames() %&gt;%\n  paste(., ' = \"\"', collapse = \",\\n\") %&gt;%\n  cat()\n\nCreate data table\n\ndata_table &lt;- grid %&gt;%\n  ungroup() %&gt;%\n  rename(\n    siteID = cell_label,\n    scalingID = cell_grouping,\n    geometry = geom\n  ) %&gt;%\n  mutate(\n    siteID = as.integer(siteID),\n    scalingID = as.integer(scalingID),\n    datasetID = as.integer(datasetID),\n    footprintSRS = \"epsg:4326\",\n    verbatimFootprintSRS = verbatimFootprintSRS\n  ) %&gt;%\n  select(\n    ., siteID, scalingID, datasetID,\n    footprintSRS, verbatimFootprintSRS, geometry\n  )\n\ndata_table$geometry &lt;- st_cast(data_table$geometry, \"MULTIPOLYGON\")\n\nWrite into the database\n\ntry({\n  # Remove records where datasetID is the current dataset\n  dbExecute(con, paste0('DELETE FROM \"', table, '\" WHERE \"datasetID\" = ', datasetID))\n\n  # Write records\n  st_write(obj = data_table, dsn = con, layer = table, append = T)\n  # Remove the data_table from the environment\n  rm(data_table)\n})\n\nCheck table.\n\ntbl(con, sql(paste0('SELECT * FROM \"', table, '\" WHERE \"datasetID\" = ', datasetID))) %&gt;%\n  head() %&gt;%\n  kable(align = \"c\")\n\n\n\n\n8.9.6 Write helper tables\n\n8.9.6.1 Scaling table\nThis intermediate table enables the joins of records data to the different resolutions of sites.\n\ntable &lt;- \"MOBI_scaling_table\" ## Table of interest\n\nCreate partition\n\nCREATE TABLE \"MOBI_scaling_table_23\" PARTITION OF \"MOBI_scaling_table\"\nFOR VALUES IN (23);\n\nCheck table colnames.\n\ntbl(con, table) %&gt;%\n  as.data.frame() %&gt;%\n  colnames() %&gt;%\n  paste(., ' = \"\"', collapse = \",\\n\") %&gt;%\n  cat()\n\n\ndata_table &lt;- data.frame(\n  siteID = scaling_table$siteID,\n  scalingID = scaling_table$scalingID,\n  datasetID = datasetID,\n  verbatimSiteID = scaling_table$cellID\n)\n\nWrite into database.\n\ntry({\n  # Remove records where datasetID is the current dataset\n  dbExecute(con, paste0('DELETE FROM \"', table, '\" WHERE \"datasetID\" = ', datasetID))\n\n  # Copy data to the database\n  copy_to(con, data_table, table, append = TRUE)\n})\n\n# Remove the data_table from the environment\nrm(data_table)\n\nCheck table.\n\ntbl(con, sql(paste0('SELECT * FROM \"', table, '\" WHERE \"datasetID\" = ', datasetID))) %&gt;%\n  head() %&gt;%\n  kable(align = \"c\")\n\n\n\n\n8.9.7 Write records tables\n\n8.9.7.1 Event\n\ntable &lt;- \"MOBI_event\" ## Table of interest\n\nCreate partition\n\nCREATE TABLE \"MOBI_event_23\" PARTITION OF \"MOBI_event\"\nFOR VALUES IN (23);\n\nCheck table colnames\n\ntbl(con, table) %&gt;%\n  as.data.frame() %&gt;%\n  colnames() %&gt;%\n  paste(., ' = \"\"', collapse = \",\\n\") %&gt;%\n  cat()\n\nCreate data table\n\ndata_table &lt;- data.frame(\n  verbatimSiteID = eff$cellID,\n  datasetID = datasetID,\n  samplingPeriodID = eff$samplingPeriodID,\n  startYear = eff$start_year,\n  endYear = eff$end_year,\n  samplingEffortID = effortID,\n  samplingEffortValue = eff$effort,\n  samplingEffort2ID = 4,\n  samplingEffort2Value = eff$effort_2\n)\n\nif (nrow(unique(data_table)) != nrow(eff)) {\n  stop(\"Stopping execution due to row number mismatch\")\n} else {\n  print(\"OK\")\n}\n\ndata_table &lt;- filter(data_table, !is.na(verbatimSiteID))\n\nWrite into the database\n\ntry({\n  # Remove records where datasetID is the current dataset\n  dbExecute(con, paste0('DELETE FROM \"', table, '\" WHERE \"datasetID\" = ', datasetID))\n\n  # Copy data to the database\n  copy_to(con, data_table, table, append = TRUE)\n})\n\n# Remove the data_table from the environment\nrm(data_table)\n\nCheck table.\n\ntbl(con, sql(paste0('SELECT * FROM \"', table, '\" WHERE \"datasetID\" = ', datasetID))) %&gt;%\n  head() %&gt;%\n  kable(align = \"c\")\n\n\n\n8.9.7.2 Presence\n\ntable &lt;- \"MOBI_presence\" ## Table of interest\n\nCreate partition\n\nCREATE TABLE \"MOBI_presence_23\" PARTITION OF \"MOBI_presence\"\nFOR VALUES IN (23);\n\nCheck table colnames\n\ntbl(con, table) %&gt;%\n  as.data.frame() %&gt;%\n  colnames() %&gt;%\n  paste(., ' = \"\"', collapse = \",\\n\") %&gt;%\n  cat()\n\nCreate data table\n\ndata_table &lt;- data.frame(\n  verbatimIdentificationID = final_data$verbatimIdentificationID,\n  verbatimSiteID = final_data$cellID,\n  datasetID = datasetID,\n  samplingPeriodID = final_data$samplingPeriodID,\n  recordFilter = NA\n)\n\nWrite into the database\n\ntry({\n  # Remove records where datasetID is the current dataset\n  dbExecute(con, paste0('DELETE FROM \"', table, '\" WHERE \"datasetID\" = ', datasetID))\n\n  # Copy data to the database\n  copy_to(con, data_table, table, append = TRUE)\n})\n\n# Remove the data_table from the environment\nrm(data_table)\n\nCheck table.\n\ntbl(con, sql(paste0('SELECT * FROM \"', table, '\" WHERE \"datasetID\" = ', datasetID))) %&gt;%\n  head() %&gt;%\n  kable(align = \"c\")\n\n\n\n8.9.7.3 Probability\n\ntable &lt;- \"MOBI_probability\" ## Table of interest\n\nCreate partition\n\nCREATE TABLE \"MOBI_probability_23\" PARTITION OF \"MOBI_probability\"\nFOR VALUES IN (23);\n\nCheck table colnames\n\ntbl(con, table) %&gt;%\n  as.data.frame() %&gt;%\n  colnames() %&gt;%\n  paste(., ' = \"\"', collapse = \",\\n\") %&gt;%\n  cat()\n\nCreate data table\n\ndata_table &lt;- data.frame(\n  verbatimIdentificationID = \"\",\n  verbatimSiteID = \"\",\n  datasetID = \"\",\n  samplingPeriodID = \"\",\n  probability = \"\"\n)\n\nWrite into the database\n\ntry({\n  # Remove records where datasetID is the current dataset\n  dbExecute(con, paste0('DELETE FROM \"', table, '\" WHERE \"datasetID\" = ', datasetID))\n\n  # Copy data to the database\n  copy_to(con, data_table, table, append = TRUE)\n})\n\n# Remove the data_table from the environment\nrm(data_table)\n\nCheck table.\n\ntbl(con, sql(paste0('SELECT * FROM \"', table, '\" WHERE \"datasetID\" = ', datasetID))) %&gt;%\n  head() %&gt;%\n  kable(align = \"c\")",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Birds of The Maritimes</span>"
    ]
  },
  {
    "objectID": "The_Maritimes.html#finish-session",
    "href": "The_Maritimes.html#finish-session",
    "title": "8  Birds of The Maritimes",
    "section": "8.10 Finish session",
    "text": "8.10 Finish session\n\nsessionInfo()\n\n\n8.10.1 Clean up workspace\n\ndbDisconnect(con)\nrm(list = ls())\ngc()\n.rs.restartR()",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Birds of The Maritimes</span>"
    ]
  },
  {
    "objectID": "EBBA.html",
    "href": "EBBA.html",
    "title": "9  European Breeding Birds Atlas",
    "section": "",
    "text": "9.1 MOBI team roles",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>European Breeding Birds Atlas</span>"
    ]
  },
  {
    "objectID": "EBBA.html#mobi-team-roles",
    "href": "EBBA.html#mobi-team-roles",
    "title": "9  European Breeding Birds Atlas",
    "section": "",
    "text": "Name\nResponsibilities\n\n\n\n\nCarmen Soria, Petr Keil\nData acquisition\n\n\nKateřina Tschernosterová\nMetadata preparation\n\n\nGabriel Ortega\nData processing",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>European Breeding Birds Atlas</span>"
    ]
  },
  {
    "objectID": "EBBA.html#data-standardizationprocessing-comments",
    "href": "EBBA.html#data-standardizationprocessing-comments",
    "title": "9  European Breeding Birds Atlas",
    "section": "9.2 Data standardization/processing comments",
    "text": "9.2 Data standardization/processing comments\n\nThere are NAs in the effort column in both sampling periods.\nNAs are located in southern Ukraine and Ihlas Selvagens (Portugal).\nEffort is a qualitative estimation of habitat survey completeness ranging from 1 to 5.\nThe effort was prepared for every resolution as the median of effort in every group of cells.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>European Breeding Birds Atlas</span>"
    ]
  },
  {
    "objectID": "EBBA.html#data-description",
    "href": "EBBA.html#data-description",
    "title": "9  European Breeding Birds Atlas",
    "section": "9.3 Data description",
    "text": "9.3 Data description\nThis dataset corresponds to the first and second edition of the European Breeding Birds Atlas.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>European Breeding Birds Atlas</span>"
    ]
  },
  {
    "objectID": "EBBA.html#libraries",
    "href": "EBBA.html#libraries",
    "title": "9  European Breeding Birds Atlas",
    "section": "9.4 Libraries",
    "text": "9.4 Libraries\n\npacman::p_load(\n  sf, terra, tidyverse, tidyterra, knitr,\n  tictoc, RSQLite, DBI, dbplyr, parallel\n)",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>European Breeding Birds Atlas</span>"
    ]
  },
  {
    "objectID": "EBBA.html#grid-preparation",
    "href": "EBBA.html#grid-preparation",
    "title": "9  European Breeding Birds Atlas",
    "section": "9.5 Grid preparation",
    "text": "9.5 Grid preparation\nThis grid was derived from the original EBBA grid, but manually prepared in QGIS to match different cell resolutions. Since the original grid spans more than one UTM zone, it was not possible to keep the cells squared as in other grids.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>European Breeding Birds Atlas</span>"
    ]
  },
  {
    "objectID": "EBBA.html#import-the-processed-grid",
    "href": "EBBA.html#import-the-processed-grid",
    "title": "9  European Breeding Birds Atlas",
    "section": "9.6 Import the processed grid",
    "text": "9.6 Import the processed grid\n\ngrid &lt;- vect(\"data/EBBA/modified_grid.gpkg\") %&gt;% mutate(across(matches(\"^X\"), dense_rank))\ncrs(grid)\n\n\n9.6.1 Calculate cell area\nGet the landmass of Europe\n\ntempCRS &lt;- crs(grid)\next &lt;- project(grid, \"epsg:4326\") %&gt;% ext()\n\nadm_boundary &lt;- rnaturalearth::ne_countries(\n  continent = c(\"europe\", \"asia\"),\n  returnclass = \"sv\", scale = \"large\"\n) %&gt;%\n  crop(., ext)\n\nminor_islands &lt;- rnaturalearth::ne_download(\n  type = \"minor_islands\",\n  category = \"physical\", scale = \"large\",\n  destdir = \"/tmp/EBBA/\", returnclass = \"sv\"\n) %&gt;%\n  crop(., ext)\n\nadm_boundary &lt;- rbind(adm_boundary, minor_islands) %&gt;%\n  buffer(., width = 1000) %&gt;%\n  project(., tempCRS) %&gt;%\n  aggregate()\n\nmap &lt;- plet(adm_boundary) %&gt;%\n  plet(grid, map = .)\nmap\n\nrm(minor_islands)\n\nIntersect the grid with the landmass of Europe\n\nint &lt;- terra::intersect(select(grid, cellID), adm_boundary)\nint &lt;- group_by(int, cellID) %&gt;% summarise()\nint$cropped_area &lt;- expanse(int, unit = \"km\")\ngrid &lt;- as.data.frame(int) %&gt;%\n  left_join(grid, ., by = \"cellID\")\n\nCalculate cell areas with and without correction by landmasses or country borders\n\ngrid$cell_area &lt;- expanse(grid, unit = \"km\")\ngrid$cell_area_proportion &lt;- grid$cropped_area / grid$cell_area %&gt;% round(., digits = 2)\n\n\n\n9.6.2 Check cell areas\n\nhist(grid$cell_area)\n\n\ngrid &lt;- read_csv(\"data/EBBA/samp_cells.csv\") %&gt;%\n  select(cellID, starts_with(\"T\")) %&gt;%\n  left_join(grid, ., by = \"cellID\") %&gt;%\n  mutate(across(starts_with(\"T\"), ~ if_else(is.na(.x), 0, .x)))\n\n\n# Pivot cells to a longer format for easier use in models.\nfinal_grids &lt;- grid %&gt;%\n  as_sf() %&gt;%\n  pivot_longer(matches(\"^X\\\\d+\\\\b\"),\n    names_to = \"cell_grouping\",\n    values_to = \"cell_label\"\n  ) %&gt;%\n  mutate(cell_grouping = str_extract(cell_grouping, \"\\\\d+\") %&gt;%\n    as.numeric())\n\nfinal_grids &lt;- split(final_grids, final_grids$cell_grouping)\n\nAggregate cells and summarize the area. Areas with an “s” at the end are “the area sampled in every atlasing period”. It is not the truly sampled area but a correction according to the sampled cells informed in each time period.\n\n# Define the function to process each grid\nsummarise_grid_cells &lt;- function(x) {\n  res &lt;- x %&gt;%\n    select(matches(\"cell_*|cropp*|T\\\\d\")) %&gt;%\n    group_by(cell_grouping, cell_label) %&gt;%\n    summarise(\n      area = sum(cell_area, na.rm = TRUE),\n      area1s = sum(T1 * cell_area, na.rm = TRUE),\n      area2s = sum(T2 * cell_area, na.rm = TRUE),\n      area_cropped = sum(cropped_area, na.rm = TRUE)\n    ) %&gt;%\n    ungroup() %&gt;%\n    mutate(\n      cell_perimeter_km = as.numeric(units::set_units(st_length(st_cast(st_make_valid(.), \"MULTILINESTRING\")), \"km\"))\n    )\n  return(res)\n}\n\ncl &lt;- makeCluster(getOption(\"cl.cores\", 10))\n\n# Load necessary packages on each worker\nclusterEvalQ(cl, {\n  library(tidyverse)\n  library(terra)\n  library(sf)\n})\n\nfinal_grids &lt;- parSapply(cl, final_grids, summarise_grid_cells, simplify = FALSE, USE.NAMES = TRUE)\n\nstopCluster(cl)\n\nFunctions to add additional variables of cell shapes\n\n# Function to get cell shape attributes\n\nfdistances &lt;- function(x, type = NULL) {\n  x &lt;- vect(x)\n  pol &lt;- as.data.frame(crds(as.points(ext(project(x, \"epsg:4326\")))))\n  if (type == \"ew\") {\n    sw &lt;- pol %&gt;%\n      summarise(x = min(x), y = min(y)) %&gt;%\n      as.matrix()\n    se &lt;- pol %&gt;%\n      summarise(x = max(x), y = min(y)) %&gt;%\n      as.matrix()\n    res &lt;- distance(sw, se, lonlat = T)[[1]] / 1000\n  }\n  if (type == \"ns\") {\n    sw &lt;- pol %&gt;%\n      summarise(x = min(x), y = min(y)) %&gt;%\n      as.matrix()\n    nw &lt;- pol %&gt;%\n      summarise(x = min(x), y = max(y)) %&gt;%\n      as.matrix()\n    res &lt;- distance(sw, nw, lonlat = T)[[1]] / 1000\n  }\n  if (type == \"max\") {\n    res &lt;- distance(pol, lonlat = T) %&gt;% max()\n    res &lt;- res / 1000\n  }\n  res &lt;- as.numeric(res)\n  return(res)\n}\n\nAdd cell max length, distance south-north, and distance east-west.\n\ntic()\n\nadd_cell_lengths &lt;- function(x) {\n  res &lt;- x\n  list &lt;- res %&gt;%\n    select(cell_label)\n  list &lt;- terra::split(list, list$cell_label)\n\n  res$cell_max_length &lt;- lapply(list, function(.x) fdistances(.x, type = \"max\")) %&gt;%\n    do.call(rbind, .) %&gt;%\n    as.numeric()\n\n  res$cell_ns_length &lt;- lapply(list, function(.x) fdistances(.x, type = \"ns\")) %&gt;%\n    do.call(rbind, .) %&gt;%\n    as.numeric()\n\n  res$cell_ew_length &lt;- lapply(list, function(.x) fdistances(.x, type = \"ew\")) %&gt;%\n    do.call(rbind, .) %&gt;%\n    as.numeric()\n\n  res &lt;- st_transform(res, st_crs(x))\n  return(res)\n}\n\n# Create a cluster\ncl &lt;- makeCluster(getOption(\"cl.cores\", 10))\n\n# Load necessary packages on each worker\nclusterEvalQ(cl, {\n  library(dplyr)\n  library(terra)\n  library(sf)\n})\n\n# Export the function to the cluster\nclusterExport(cl, varlist = \"fdistances\")\n\n# Use parSapply with the cluster\nfinal_grids &lt;- parSapply(cl, final_grids, add_cell_lengths, simplify = FALSE, USE.NAMES = TRUE)\n\n# Stop the cluster\nstopCluster(cl)\n\ntoc()\n\nGet longitude and latitude coordinates of each cell.\n\nfinal_grids &lt;- lapply(final_grids, function(x) {\n  x &lt;- vect(x)\n  x &lt;- project(x, \"epsg:4326\")\n  res &lt;- centroids(x) %&gt;%\n    geom() %&gt;%\n    bind_spat_cols(x, .)\n  res &lt;- rename(res, cell_lat = y, cell_long = x)\n  res &lt;- select(res, -geom, -part, -hole)\n  return(res)\n})\n\nPlot grids\n\n# for (x in final_grids) {\n#   plot(x)\n# }",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>European Breeding Birds Atlas</span>"
    ]
  },
  {
    "objectID": "EBBA.html#export-grids",
    "href": "EBBA.html#export-grids",
    "title": "9  European Breeding Birds Atlas",
    "section": "9.7 Export grids",
    "text": "9.7 Export grids\n\nwide_out_grid &lt;- \"data/EBBA/grids_correspondence_table.csv\"\nfile.remove(wide_out_grid)\n\ngrid %&gt;%\n  st_drop_geometry() %&gt;%\n  select(matches(\"cellID|^X\\\\d\")) %&gt;%\n  as.data.frame() %&gt;%\n  write_csv(., wide_out_grid)\n\n\nout_grid &lt;- \"data/EBBA/final_grids.gpkg\"\nfile.remove(out_grid)\n\n# Define the grid layers you want to write\ngrid_layers &lt;- c(1, 2, 4, 8, 16, 32, 64, 128)\n\n# Loop through each grid layer and write to the output\nfor (layer in grid_layers) {\n  st_write(st_as_sf(final_grids[[as.character(layer)]]), out_grid, layer = paste0(\"cell\", layer, \"grid\"))\n}",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>European Breeding Birds Atlas</span>"
    ]
  },
  {
    "objectID": "EBBA.html#adding-records-to-the-database",
    "href": "EBBA.html#adding-records-to-the-database",
    "title": "9  European Breeding Birds Atlas",
    "section": "9.8 Adding records to the database",
    "text": "9.8 Adding records to the database\n\n9.8.1 Data\nImport the processed data and grid.\n\n# Function to split, sort and rejoin every string in a vector\nsplitSort &lt;- function(vector, splpat, joinpat) {\n  res &lt;- sapply(vector, function(x) {\n    if (is.na(x)) {\n      return(NA)\n    } else {\n      split &lt;- stringr::str_split_1(x, pattern = splpat)\n      order &lt;- stringr::str_sort(split, decreasing = T)\n      paste &lt;- paste0(order, collapse = joinpat)\n      return(paste)\n    }\n  })\n}\n\n# Import raw data\ndata &lt;- list(\"data/EBBA/data1.csv\", \"data/EBBA/data2.csv\") %&gt;%\n  lapply(., function(file) read_csv(file)) %&gt;%\n  do.call(rbind, .) %&gt;%\n  mutate(\n    verbatimIdentificationID = dense_rank(verbatim_name),\n    samplingPeriodID = dense_rank(start_year),\n    composite_cells = str_detect(cellID, \"-\"),\n    cellID = splitSort(cellID, \"-\", \"-\")\n  )\n\n# Import change data\nchange &lt;- read_csv(\"data/EBBA/prepared_change.csv\", col_select = -1) %&gt;%\n  mutate(\n    composite_cells = str_detect(cellID, \"-\"),\n    cellID = splitSort(cellID, \"-\", \"-\")\n  )\n\ndata &lt;- left_join(data, change)\nno_join &lt;- anti_join(change, data)\n\nsp_names &lt;- data %&gt;%\n  select(verbatimIdentificationID, verbatim_name) %&gt;%\n  unique()\n\neff &lt;- read_csv(\"data/EBBA/effort.csv\", col_select = -1) %&gt;%\n  mutate(samplingPeriodID = dense_rank(start_year)) %&gt;%\n  group_by(across(-effort)) %&gt;%\n  summarise(effort = max(effort))\n\ncorrs &lt;- read_csv(\"data/EBBA/grids_correspondence_table.csv\")\n\nscaling_table &lt;- corrs %&gt;%\n  pivot_longer(-cellID, names_to = \"scalingID\", values_to = \"siteID\") %&gt;%\n  mutate(scalingID = str_remove_all(scalingID, \"^X\") %&gt;%\n    as.numeric())\n\ngrid &lt;- st_layers(\"data/EBBA/final_grids.gpkg\")$name %&gt;%\n  mclapply(., function(x) {\n    st_read(\"data/EBBA/final_grids.gpkg\",\n      layer = x, quiet = T\n    )\n  }, mc.cores = 10) %&gt;%\n  do.call(rbind, .)\n\ngrid_table &lt;- st_drop_geometry(grid)\n\n\n9.8.1.1 Basic double check\n\n# Check that all cellID in data are also in the corrs cellID\nif (length(setdiff(unique(data$cellID), unique(corrs$cellID))) == 0) {\n  print(\"OK\")\n} else {\n  print(\"FAIL\")\n}\n# Check that number of rows in grid and corrs are the same\nnrow(filter(grid, cell_grouping == 1)) == nrow(corrs)\n\n# Check that years and sampling periods are the same in data and eff\nnrow(setdiff(\n  unique(select(data, start_year, samplingPeriodID)),\n  unique(select(eff, start_year, samplingPeriodID))\n))\n\n# Check uniqueness of scaling_table\nnrow(unique(scaling_table)) == nrow(scaling_table)\n\n# RESULTS SHOULD BE: OK, TRUE, 0, TRUE\n\n\n\n9.8.1.2 Atlas variables\n\ndatasetID &lt;- 26\neffortID &lt;- 2\nlicenseID &lt;- 0\nshareable &lt;- 0\nverbatimFootprintSRS &lt;- \"epsg:3035\"\n\nThe previous step indicates that there are cells not joined to the grid. Such cells correspond to locations in the sea or outside the countries border.\n\nfinal_data &lt;- inner_join(data, corrs, by = \"cellID\")\nno_gridcell_data &lt;- anti_join(data, corrs, by = \"cellID\")\n\n\n\n\n9.8.2 Database connection\n\nif (exists(\"con\")) {\n  dbDisconnect(con)\n}\n\ncon &lt;- dbConnect(RSQLite::SQLite(),\n  dbname = \"MOBI_rep_atlases.sqlite\"\n)\n\n# Enable SpatiaLite extension\ndbExecute(con, \"SELECT load_extension('mod_spatialite')\")\n\nknitr::opts_chunk$set(connection = con)\n\n\n\n9.8.3 List tables in database\n\ndbListTables(con) %&gt;%\n  purrr::keep(., ~ grepl(\"^CB|^MOBI\", .)) %&gt;%\n  kable(col.names = \"Tables\")\n\n\n\n9.8.4 Write code books\n\n9.8.4.1 CB_license\n\ntable &lt;- \"CB_license\" ## Table of interest\n\nCheck table colnames\n\ntbl(con, table) %&gt;%\n  as.data.frame() %&gt;%\n  colnames() %&gt;%\n  paste(., ' = \"\"', collapse = \",\\n\") %&gt;%\n  cat()\n\nCreate data table\n\ndata_table &lt;- data.frame(\n  licenseID = licenseID,\n  license = \"Restricted\",\n  licenseDescription = \"Closed data. Special request or purchase required\",\n  licenseURL = \"none\"\n)\n\nWrite into the database\n\ntry({\n  copy_to(con, data_table, table, append = T)\n})\nrm(data_table)\n\nCheck the table\n\ntbl(con, table) %&gt;% kable(align = \"c\")\n\n\n\n9.8.4.2 CB_sampling_effort\n\ntable &lt;- \"CB_sampling_effort\" ## Table of interest\n\nCheck table colnames\n\ntbl(con, table) %&gt;%\n  as.data.frame() %&gt;%\n  colnames() %&gt;%\n  paste(., ' = \"\"', collapse = \",\\n\") %&gt;%\n  cat()\n\nCreate data table\n\ndata_table &lt;- data.frame(\n  samplingEffortID = effortID,\n  samplingEffortProtocol = \"Habitats survey completeness\",\n  samplingEffortUnit = \"Survey completeness\"\n)\n\nWrite into the database\n\ntry({\n  copy_to(con, data_table, table, append = T)\n})\nrm(data_table)\n\nCheck table.\n\ntbl(con, table) %&gt;% kable(align = \"c\")\n\n\n\n9.8.4.3 CB_model\n\ntable &lt;- \"CB_model\" ## Table of interest\n\nCheck table colnames\n\ntbl(con, table) %&gt;%\n  as.data.frame() %&gt;%\n  colnames() %&gt;%\n  paste(., ' = \"\"', collapse = \",\\n\") %&gt;%\n  cat()\n\nCreate data table\n\ndata_table &lt;- data.frame(\n  occurrenceModelID = \"\",\n  modelName = \"\",\n  predictorVariables = \"\",\n  bibliographicCitation = \"\"\n)\n\nWrite into the database\n\ntry({\n  copy_to(con, data_table, table, append = T)\n})\nrm(data_table)\n\nCheck table\n\ntbl(con, table) %&gt;% kable(align = \"c\")\n\n\n\n9.8.4.4 CB_taxonomy\n\ntable &lt;- \"CB_taxonomy\" ## Table of interest\n\nCheck table colnames\n\ntbl(con, table) %&gt;%\n  as.data.frame() %&gt;%\n  colnames() %&gt;%\n  paste(., ' = \"\"', collapse = \",\\n\") %&gt;%\n  cat()\n\nCreate data table\n\ndata_table &lt;- data.frame(\n  scientificNameID = \"\",\n  scientificName = \"\",\n  scientificNameAuthorship = \"\",\n  kingdom = \"\",\n  phylum = \"\",\n  class = \"\",\n  family = \"\",\n  order = \"\",\n  genus = \"\",\n  specificEpitet = \"\",\n  infraspecificEpitet = \"\",\n  taxonRank = \"\"\n)\n\nWrite into the database\n\ntry({\n  copy_to(con, data_table, table, append = T)\n})\nrm(data_table)\n\n\n\n9.8.4.5 CB_verbatim_name_equivalence\n\ntable &lt;- \"CB_verbatim_name_equivalence\" ## Table of interest\n\nCheck table colnames\n\ntbl(con, table) %&gt;%\n  as.data.frame() %&gt;%\n  colnames() %&gt;%\n  paste(., ' = \"\"', collapse = \",\\n\") %&gt;%\n  cat()\n\nCreate data table\n\ndata_table &lt;- data.frame(\n  verbatimIdentificationID = sp_names$verbatimIdentificationID,\n  verbatimIdentification = sp_names$verbatim_name,\n  datasetID = datasetID,\n  identificationReferences = \"\",\n  scientificNameID = 0\n)\n\nWrite into the database\n\ntry({\n  # Remove records where datasetID is the current dataset\n  dbExecute(con, paste(\"DELETE FROM\", table, \"WHERE datasetID =\", datasetID))\n\n  # Copy data to the database\n  copy_to(con, data_table, table, append = TRUE)\n})\n\n# Remove the data_table from the environment\nrm(data_table)\n\nCheck table.\n\ntbl(con, sql(paste(\"SELECT * FROM\", table, \"WHERE datasetID =\", datasetID))) %&gt;% kable(align = \"c\")\n\n\n\n\n9.8.5 Write dataset tables\n\n9.8.5.1 Dataset\n\ntable &lt;- \"MOBI_dataset\" ## Table of interest\n\nCheck table colnames\n\ntbl(con, table) %&gt;%\n  as.data.frame() %&gt;%\n  colnames() %&gt;%\n  paste(., ' = \"\"', collapse = \",\\n\") %&gt;%\n  cat()\n\nCreate data table\n\ndata_table &lt;- data.frame(\n  datasetID = datasetID,\n  datasetName = \"European Breeding Birds Atlas\",\n  datasetPublisher = \"European Bird Census Council\",\n  datasetPublisherContact = \"Sergi Herrando (vice-chair, European Bird Census Council) - ornitologia@ornitologia.org, s.herrando@creaf.uab.cat\",\n  licenseID = licenseID,\n  rightsHolder = \"European Bird Census Council\",\n  bibliographicCitation = \"EBBA1 book: Hagemeijer, W.J.M. & Blair, M.J. (1997). The EBCC Atlas of European Breeding Birds: Their Distribution and Abundance. T. & A.D. Poyser, London.\nEBBA1 dataset/web: Hagemeyer W, Blair M, Loos W (2016). EBCC Atlas of European Breeding Birds. Version 1.3. European Bird Census Council (EBCC). Occurrence dataset https://doi.org/10.15468/adtfvf accessed via GBIF.org on 2024-04-09.\nEBBA2 book: Keller, V., Herrando, S., Voříšek, P., Franch, M., Kipson, M., Milanesi, P., Martí, D., Anton, M., Klvaňová, A., Kalyakin, M.V., Bauer, H.-G. & Foppen, R.P.B. (2020). European Breeding Bird Atlas 2: Distribution, Abundance and Change. European Bird Census Council & Lynx Edicions, Barcelona.\nEBBA2 web: EBCC (2022). European Breeding Bird Atlas 2 website. European Bird Census Council. Accessed from: http://ebba2.info (Day/Month/Year).\",\n  citationIdentifier = \"\",\n  provider = \"European Bird Census Council\",\n  shareable = \"NO\",\n  coauthorshipRequired = \"YES\",\n  coauthors = \"Sergi Herrando  - ornitologia@ornitologia.org; Petr Voříšek - Vorisek@ebcc.info; Verena Keller -  verena.keller@vogelwarte.ch\",\n  coauthorshipSuggested = \"Carmen Soria - carmendianasoria@gmail.com; Kateřina Tschernosterová - tschernosterova@fzp.czu.cz; Friederike Wölke - wolke@fzp.czu.cz; Gabriel Ortega - g.ortega.solis@gmail.com\",\n  isSamplingEffortReported = \"YES\",\n  isOccurrenceProbabilityAvailable = \"NO\",\n  occurrenceModelID = \"\",\n  recordFilterMeaning = \"Trusted occurrences selected to evaluate changes in species distributions between atlasing periods.\"\n)\n\nWrite into the database\n\ntry({\n  dbExecute(con, paste(\"DELETE FROM\", table, \"WHERE datasetID =\", datasetID))\n  copy_to(con, data_table, table, append = T)\n})\nrm(data_table)\n\nCheck table.\n\ntbl(con, sql(paste(\"SELECT * FROM\", table, \"WHERE datasetID =\", datasetID))) %&gt;% kable(align = \"c\")\n\n\n\n9.8.5.2 Site\n\ntable &lt;- \"MOBI_site\" ## Table of interest\n\nCheck table colnames\n\ntbl(con, table) %&gt;%\n  as.data.frame() %&gt;%\n  colnames() %&gt;%\n  paste(., ' = \"\"', collapse = \",\\n\") %&gt;%\n  cat()\n\nCreate data table\n\ndata_table &lt;- data.frame(\n  siteID = grid_table$cell_label,\n  scalingID = grid_table$cell_grouping,\n  datasetID = datasetID,\n  area = grid_table$area,\n  croppedArea = grid_table$area_cropped,\n  areaUnit = \"km2\",\n  maxLength = grid_table$cell_max_length,\n  northSouthLength = grid_table$cell_ns_length,\n  eastWestLength = grid_table$cell_ew_length,\n  lengthUnit = \"km\",\n  centroidDecimalLongitude = grid_table$cell_long,\n  centroidDecimalLatitude = grid_table$cell_lat\n)\n\nWrite into the database\n\ntry({\n  # Remove records where datasetID is the current dataset\n  dbExecute(con, paste(\"DELETE FROM\", table, \"WHERE datasetID =\", datasetID))\n\n  # Copy data to the database\n  copy_to(con, data_table, table, append = TRUE)\n})\n\n# Remove the data_table from the environment\nrm(data_table)\n\nCheck table.\n\ntbl(\n  con,\n  sql(paste(\"SELECT * FROM\", table, \"WHERE datasetID =\", datasetID))\n) %&gt;%\n  head(n = 20) %&gt;%\n  kable(align = \"c\")\n\n\n\n9.8.5.3 Geometry\n\ntable &lt;- \"MOBI_geometry\" ## Table of interest\n\nCheck table colnames\n\ntbl(con, table) %&gt;%\n  as.data.frame() %&gt;%\n  colnames() %&gt;%\n  paste(., ' = \"\"', collapse = \",\\n\") %&gt;%\n  cat()\n\nCreate data table\n\ndata_table &lt;- grid %&gt;%\n  rename(\n    siteID = cell_label,\n    scalingID = cell_grouping,\n    geometry = geom\n  ) %&gt;%\n  mutate(\n    siteID = as.integer(siteID),\n    scalingID = as.integer(scalingID),\n    datasetID = as.integer(datasetID),\n    footprintSRS = \"epsg:4326\",\n    verbatimFootprintSRS = verbatimFootprintSRS\n  ) %&gt;%\n  select(\n    ., siteID, scalingID, datasetID,\n    footprintSRS, verbatimFootprintSRS, geometry\n  )\n\ndata_table$geometry &lt;- st_cast(data_table$geometry, \"MULTIPOLYGON\")\n\nst_write(data_table, \"/tmp/grid.gpkg\", delete_dsn = T)\n\nWrite into the database\n\ntry({\n  # Remove records where datasetID is the current dataset\n  dbExecute(con, paste(\"DELETE FROM\", table, \"WHERE datasetID =\", datasetID))\n\n  # Remove the data_table from the environment\n  rm(data_table)\n})\n\n\nogr2ogr -update -append -f SQLite -dsco SPATIALITE=YES -nln MOBI_geometry MOBI_rep_atlases.sqlite /tmp/grid.gpkg\n\nCheck table.\n\ntbl(\n  con,\n  sql(paste(\"SELECT * FROM\", table, \"WHERE datasetID =\", datasetID))\n) %&gt;%\n  head(n = 20) %&gt;%\n  kable(align = \"c\")\n\n\n\n\n9.8.6 Write helper tables\n\n9.8.6.1 Scaling table\nThis intermediate table enables the joins of records data to the different resolutions of sites.\n\ntable &lt;- \"MOBI_scaling_table\" ## Table of interest\n\nCheck table colnames.\n\ntbl(con, table) %&gt;%\n  as.data.frame() %&gt;%\n  colnames() %&gt;%\n  paste(., ' = \"\"', collapse = \",\\n\") %&gt;%\n  cat()\n\n\ndata_table &lt;- data.frame(\n  siteID = scaling_table$siteID,\n  scalingID = scaling_table$scalingID,\n  datasetID = datasetID,\n  verbatimSiteID = scaling_table$cellID\n)\n\nWrite into database.\n\ntry({\n  # Remove records where datasetID is the current dataset\n  dbExecute(con, paste(\"DELETE FROM\", table, \"WHERE datasetID =\", datasetID))\n\n  # Copy data to the database\n  copy_to(con, data_table, table, append = TRUE)\n})\n\n# Remove the data_table from the environment\nrm(data_table)\n\nCheck table.\n\ntbl(\n  con,\n  sql(paste(\"SELECT * FROM\", table, \"WHERE datasetID =\", datasetID))\n) %&gt;%\n  head(n = 20) %&gt;%\n  kable(align = \"c\")\n\n\n\n\n9.8.7 Write records tables\n\n9.8.7.1 Event\n\ntable &lt;- \"MOBI_event\" ## Table of interest\n\nCheck table colnames\n\ntbl(con, table) %&gt;%\n  as.data.frame() %&gt;%\n  colnames() %&gt;%\n  paste(., ' = \"\"', collapse = \",\\n\") %&gt;%\n  cat()\n\nCreate data table\n\ndata_table &lt;- data.frame(\n  verbatimSiteID = eff$cellID,\n  datasetID = datasetID,\n  samplingPeriodID = eff$samplingPeriodID,\n  startYear = eff$start_year,\n  endYear = eff$end_year,\n  samplingEffortID = effortID,\n  samplingEffortValue = eff$effort\n)\n\nif (nrow(unique(data_table)) != nrow(eff)) {\n  stop(\"Stopping execution due to row number mismatch\")\n} else {\n  print(\"OK\")\n}\n\nWrite into the database\n\ntry({\n  # Remove records where datasetID is the current dataset\n  dbExecute(con, paste(\"DELETE FROM\", table, \"WHERE datasetID =\", datasetID))\n\n  # Copy data to the database\n  copy_to(con, data_table, table, append = TRUE)\n})\n\n# Remove the data_table from the environment\nrm(data_table)\n\nCheck table.\n\ntbl(\n  con,\n  sql(paste(\"SELECT * FROM\", table, \"WHERE datasetID =\", datasetID))\n) %&gt;%\n  head(n = 20) %&gt;%\n  kable(align = \"c\")\n\n\n\n9.8.7.2 Presence\n\ntable &lt;- \"MOBI_presence\" ## Table of interest\n\nCheck table colnames\n\ntbl(con, table) %&gt;%\n  as.data.frame() %&gt;%\n  colnames() %&gt;%\n  paste(., ' = \"\"', collapse = \",\\n\") %&gt;%\n  cat()\n\nCreate data table\n\ndata_table &lt;- data.frame(\n  verbatimIdentificationID = final_data$verbatimIdentificationID,\n  verbatimSiteID = final_data$cellID,\n  datasetID = datasetID,\n  samplingPeriodID = final_data$samplingPeriodID\n)\n\nWrite into the database\n\ntry({\n  # Remove records where datasetID is the current dataset\n  dbExecute(con, paste(\"DELETE FROM\", table, \"WHERE datasetID =\", datasetID))\n\n  # Copy data to the database\n  copy_to(con, data_table, table, append = TRUE)\n})\n\n# Remove the data_table from the environment\nrm(data_table)\n\nCheck table.\n\ntbl(\n  con,\n  sql(paste(\"SELECT * FROM\", table, \"WHERE datasetID =\", datasetID))\n) %&gt;%\n  head(n = 20) %&gt;%\n  kable(align = \"c\")\n\n\n\n9.8.7.3 Probability\n\ntable &lt;- \"MOBI_probability\" ## Table of interest\n\nCheck table colnames\n\ntbl(con, table) %&gt;%\n  as.data.frame() %&gt;%\n  colnames() %&gt;%\n  paste(., ' = \"\"', collapse = \",\\n\") %&gt;%\n  cat()\n\nCreate data table\n\ndata_table &lt;- data.frame(\n  verbatimIdentificationID = \"\",\n  verbatimSiteID = \"\",\n  datasetID = \"\",\n  samplingPeriodID = \"\",\n  probability = \"\"\n)\n\nWrite into the database\n\ntry({\n  # Remove records where datasetID is the current dataset\n  dbExecute(con, paste(\"DELETE FROM\", table, \"WHERE datasetID =\", datasetID))\n\n  # Copy data to the database\n  copy_to(con, data_table, table, append = TRUE)\n})\n\n# Remove the data_table from the environment\nrm(data_table)\n\nCheck table.\n\ntbl(\n  con,\n  sql(paste(\"SELECT * FROM\", table, \"WHERE datasetID =\", datasetID))\n) %&gt;%\n  head(n = 20) %&gt;%\n  kable(align = \"c\")",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>European Breeding Birds Atlas</span>"
    ]
  },
  {
    "objectID": "EBBA.html#finish-session",
    "href": "EBBA.html#finish-session",
    "title": "9  European Breeding Birds Atlas",
    "section": "9.9 Finish session",
    "text": "9.9 Finish session\n\nsessionInfo()\n\n\n9.9.1 Clean up workspace\n\ndbDisconnect(con)\nrm(list = ls())\ngc()\n.rs.restartR()",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>European Breeding Birds Atlas</span>"
    ]
  }
]